# Cours : Serveur Haute Performance
## Optimisations appliquÃ©es sur le projet NWS Watermark

---

## ğŸ“‹ Table des matiÃ¨res

1. [Architecture du projet](#architecture)
2. [io.Pipe â€” Streaming sans consommer la RAM](#iopipe)
3. [http.Client partagÃ© â€” RÃ©utilisation des connexions TCP](#httpclient)
4. [Worker Pool â€” Gestion intelligente du CPU](#workerpool)
5. [sync.Pool â€” Recyclage de la mÃ©moire](#syncpool)
6. [Chargement unique des ressources](#chargement-unique)
7. [Compression Gzip â€” RÃ©duction de la bande passante](#gzip)
8. [Redis â€” Cache en mÃ©moire RAM](#redis)
9. [MinIO â€” Stockage objet persistant](#minio)
10. [RÃ©sumÃ© des gains de performance](#rÃ©sumÃ©)

---

<a name="architecture"></a>
## 1. Architecture du projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Navigateur    â”‚  Front-end React (port 5173)
â”‚    (client)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /upload (multipart/form-data)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            API Gateway (port 3000)      â”‚
â”‚                                         â”‚
â”‚  â‘  Lecture image                        â”‚
â”‚  â‘¡ SHA256                               â”‚
â”‚  â‘¢ Redis.Get â”€â”€â–º HIT â†’ rÃ©pond           â”‚
â”‚  â‘¢ Redis.Get â”€â”€â–º MISS                   â”‚
â”‚  â‘£ MinIO.Put(original/)  â† sauvegarde  â”‚
â”‚  â‘¤ Optimizer â”€â”€â–º OK â†’ â‘¥Redis â‘¦RÃ©pond  â”‚
â”‚  â‘¤ Optimizer â”€â”€â–º KO â†’ MinIO.Get retry  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ io.Pipe          â”‚ PutObject / GetObject
       â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Optimizer   â”‚  â”‚        MinIO         â”‚
â”‚  (port 3001) â”‚  â”‚     (port 9000)      â”‚
â”‚  â€¢ Resize    â”‚  â”‚  bucket: watermarks  â”‚
â”‚  â€¢ Watermark â”‚  â”‚  â”œâ”€ original/<hash>  â”‚
â”‚  â€¢ JPEG      â”‚  â”‚  Console: port 9001  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²
       â”‚ Redis.Get / Redis.Set
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Redis     â”‚
â”‚  (port 6379) â”‚
â”‚  Cache RAM   â”‚
â”‚  TTL : 24h   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Principe clÃ© :** Chaque service est **indÃ©pendant** avec son propre `go.mod`. Cela permet de :
- Scaler chaque service sÃ©parÃ©ment
- RedÃ©marrer un service sans affecter les autres
- DÃ©ployer des mises Ã  jour isolÃ©es

---

<a name="iopipe"></a>
## 2. io.Pipe â€” Streaming sans consommer la RAM

### ğŸ¯ Le problÃ¨me

Quand un client envoie une image de 10 MB, l'approche naÃ¯ve serait :

```go
// âŒ MAUVAISE APPROCHE
data, _ := io.ReadAll(file)  // charge les 10 MB en RAM
// envoie data Ã  l'optimizer
```

**ConsÃ©quence :** Si 100 utilisateurs uploadent en mÃªme temps des images de 10 MB :
```
100 utilisateurs Ã— 10 MB = 1 GB de RAM consommÃ©e
```

Le serveur s'Ã©croule ğŸ’¥

---

### âœ… La solution : io.Pipe

`io.Pipe()` crÃ©e un **tuyau virtuel** qui connecte un lecteur et un Ã©crivain.

```go
pr, pw := io.Pipe()
```

- **`pr`** (PipeReader) : le bout oÃ¹ on **lit** les donnÃ©es
- **`pw`** (PipeWriter) : le bout oÃ¹ on **Ã©crit** les donnÃ©es

**Analogie :** C'est comme un tuyau d'eau :
- L'eau (les donnÃ©es) entre d'un cÃ´tÃ©
- Elle ressort de l'autre cÃ´tÃ©
- **Aucune eau n'est stockÃ©e dans le tuyau**

---

### ğŸ”„ Comment Ã§a fonctionne

```go
pr, pw := io.Pipe()

// Goroutine 1 : Ã‰crit les donnÃ©es dans le pipe
go func() {
    defer pw.Close()
    io.Copy(pw, file)  // Copie l'image dans le pipe (chunk par chunk)
}()

// Goroutine 2 : Lit depuis le pipe et envoie Ã  l'optimizer
resp, err := httpClient.Post(optimizerURL, contentType, pr)
```

**Flux de donnÃ©es :**
```
Client (navigateur)
    â”‚
    â”‚ envoie 10 MB
    â–¼
API reÃ§oit chunk 1 (8 KB) â”€â”€â–º Ã©crit dans pw â”€â”€â–º pr lit â”€â”€â–º envoie Ã  optimizer
API reÃ§oit chunk 2 (8 KB) â”€â”€â–º Ã©crit dans pw â”€â”€â–º pr lit â”€â”€â–º envoie Ã  optimizer
API reÃ§oit chunk 3 (8 KB) â”€â”€â–º Ã©crit dans pw â”€â”€â–º pr lit â”€â”€â–º envoie Ã  optimizer
...
```

**RÃ©sultat :** On ne stocke jamais les 10 MB entiers en RAM ! Seulement de petits morceaux (chunks de 8-32 KB).

---

### âš ï¸ Trade-off dans notre implÃ©mentation

Dans ce projet, `io.Pipe` est utilisÃ© **entre l'API et l'optimizer**, mais l'API fait quand mÃªme un `io.ReadAll` en amont :

```go
// api/main.go
data, _ := io.ReadAll(file)  // Charge l'image en RAM...
hash := sha256.Sum256(data)  // ...pour calculer le hash SHA256
```

**Pourquoi ?** Pour interroger le cache Redis, il faut d'abord connaÃ®tre le hash SHA256 de l'image â€” ce qui nÃ©cessite d'avoir tout le contenu en mÃ©moire.

```
Client â†’ API â†’ io.ReadAll (charge 10 MB en RAM)
             â†’ SHA256 â†’ Redis.Get(hash)
             â†’ si CACHE MISS : io.Pipe â†’ Optimizer
             â†’ si CACHE HIT  : rÃ©pond directement (sans Pipe)
```

**ConsÃ©quence :** Le `io.Pipe` n'Ã©limine pas la copie RAM cÃ´tÃ© API â€” il Ã©vite une **deuxiÃ¨me copie** lors du forward vers l'optimizer.

Le vrai gain de `io.Pipe` reste important : sans lui, on ferait `bytes.NewBuffer(data)` pour reconstruire un body HTTP, ce qui doublerait la consommation RAM. Avec `io.Pipe`, on relit directement depuis `data` dÃ©jÃ  en mÃ©moire sans duplication.

> Si on voulait un streaming pur sans `ReadAll`, il faudrait renoncer au cache Redis (impossible de calculer le hash sans lire tout le contenu), ou utiliser une autre stratÃ©gie de cache (ex: basÃ©e sur le nom + taille du fichier, moins fiable).

---

### ğŸ“Š Comparaison

| Approche | RAM utilisÃ©e pour 1 image de 10 MB | RAM pour 100 images simultanÃ©es |
|----------|-------------------------------------|----------------------------------|
| Sans Pipe | 10 MB Ã— 2 (double copie) | 2000 MB (2 GB) ğŸ’€ |
| Avec Pipe | 10 MB (1 seule copie) | 1000 MB âœ… |
| Streaming pur (sans cache) | ~32 KB | ~3.2 MB âœ…âœ… |

**Gain dans notre cas :** **2x moins de RAM** grÃ¢ce au Pipe (Ã©vite la double copie)

---

<a name="httpclient"></a>
## 3. http.Client partagÃ© â€” RÃ©utilisation des connexions TCP

### ğŸ¯ Le problÃ¨me

Chaque fois qu'on utilise `http.Post()`, Go crÃ©e un **nouveau client HTTP**.

```go
// âŒ MAUVAISE APPROCHE (dans une boucle de requÃªtes)
for i := 0; i < 1000; i++ {
    http.Post(url, contentType, body)  // Nouveau client Ã  chaque fois
}
```

**Qu'est-ce qui se passe en coulisses ?**

Chaque appel fait :
1. **DNS lookup** : RÃ©soudre `optimizer:3001` â†’ `172.18.0.3`
2. **TCP handshake** : 3 aller-retours rÃ©seau (SYN, SYN-ACK, ACK)
3. **Envoyer la requÃªte HTTP**
4. **Fermer la connexion TCP** (FIN, ACK, FIN, ACK)

```
RequÃªte 1 : DNS + TCP open + HTTP + TCP close = ~50ms
RequÃªte 2 : DNS + TCP open + HTTP + TCP close = ~50ms
RequÃªte 3 : DNS + TCP open + HTTP + TCP close = ~50ms
...
```

**Pour 1000 requÃªtes :** 50 secondes perdues juste en ouverture/fermeture de connexions ğŸ˜±

---

### âœ… La solution : Client HTTP partagÃ©

On crÃ©e **un seul client** rÃ©utilisÃ© pour toutes les requÃªtes.

```go
var httpClient = &http.Client{
    Timeout: 30 * time.Second,
}

// Dans le handler
resp, err := httpClient.Post(url, contentType, pr)
```

**HTTP Keep-Alive :** Le client maintient la connexion TCP ouverte entre les requÃªtes.

```
RequÃªte 1 : DNS + TCP open + HTTP           = ~25ms
RequÃªte 2 :                   HTTP           = ~2ms  (rÃ©utilise la connexion)
RequÃªte 3 :                   HTTP           = ~2ms
RequÃªte 4 :                   HTTP           = ~2ms
...
```

---

### â±ï¸ Pourquoi le Timeout ?

Sans timeout, une requÃªte peut bloquer **indÃ©finiment** :

```go
// âŒ SANS TIMEOUT
client := &http.Client{}
resp, _ := client.Get("http://serveur-tres-lent.com")
// Si le serveur ne rÃ©pond jamais, la goroutine est bloquÃ©e POUR TOUJOURS
```

**ConsÃ©quence :** Fuite de goroutines â†’ consommation de RAM infinie.

Avec le timeout :
```go
// âœ… AVEC TIMEOUT
client := &http.Client{Timeout: 30 * time.Second}
resp, err := client.Get("http://serveur-tres-lent.com")
// AprÃ¨s 30s, err = "context deadline exceeded"
```

---

### ğŸ“Š Comparaison

| Approche | Temps pour 1000 requÃªtes | Connexions TCP crÃ©Ã©es |
|----------|--------------------------|----------------------|
| Sans client partagÃ© | ~50 secondes | 1000 |
| Avec client partagÃ© | ~4 secondes | 1 (rÃ©utilisÃ©e) |

**Gain :** **12x plus rapide**

---

<a name="workerpool"></a>
## 4. Worker Pool â€” Gestion intelligente du CPU

### ğŸ¯ Le problÃ¨me

Quand 1000 utilisateurs uploadent des images en mÃªme temps, sans contrÃ´le, le serveur crÃ©e **1000 goroutines** qui traitent toutes les images **simultanÃ©ment**.

```
Image 1  â”€â”€â–º Goroutine 1 â”€â”€â–º CPU (resize + watermark)
Image 2  â”€â”€â–º Goroutine 2 â”€â”€â–º CPU (resize + watermark)
Image 3  â”€â”€â–º Goroutine 3 â”€â”€â–º CPU (resize + watermark)
...
Image 1000 â”€â”€â–º Goroutine 1000 â”€â”€â–º CPU (resize + watermark)
```

**ProblÃ¨me :** Un CPU Ã  8 cÅ“urs ne peut faire que **8 opÃ©rations vraiment en parallÃ¨le**.

Les 992 autres goroutines se battent pour du temps CPU â†’ **context switching** constant â†’ tout ralentit.

**Analogie :** C'est comme une cuisine avec 8 plaques de cuisson et 1000 cuisiniers qui essaient tous de cuisiner en mÃªme temps. Chaos total ğŸ”¥

---

### âœ… La solution : SÃ©maphore avec un canal

On limite le nombre de traitements simultanÃ©s au nombre de **cÅ“urs CPU**.

```go
// CrÃ©ation du sÃ©maphore (taille = nombre de cÅ“urs)
var sem = make(chan struct{}, runtime.NumCPU())

func handleOptimize(w http.ResponseWriter, r *http.Request) {
    sem <- struct{}{}        // Prend un slot (bloque s'ils sont tous pris)
    defer func() { <-sem }() // LibÃ¨re le slot Ã  la fin

    // Traitement de l'image (resize, watermark, encode)
    // ...
}
```

---

### ğŸ” Explication dÃ©taillÃ©e

#### Qu'est-ce qu'un canal en Go ?

Un **canal** (`chan`) est comme une file d'attente avec une capacitÃ© limitÃ©e.

```go
sem := make(chan struct{}, 4)  // Canal de capacitÃ© 4
```

Visualisation :
```
sem = [_, _, _, _]  // 4 slots vides
```

---

#### Que se passe-t-il quand on fait `sem <- struct{}{}`  ?

On **envoie** une valeur dans le canal = on prend un slot.

```go
sem <- struct{}{}  // Prend le 1er slot
```

Ã‰tat du canal :
```
sem = [X, _, _, _]  // 1 slot occupÃ©, 3 libres
```

Si tous les slots sont pris :
```
sem = [X, X, X, X]  // Tous les slots occupÃ©s
sem <- struct{}{}   // â¸ï¸ BLOQUE ici jusqu'Ã  ce qu'un slot se libÃ¨re
```

---

#### Que se passe-t-il quand on fait `<-sem` ?

On **lit** une valeur du canal = on libÃ¨re un slot.

```go
<-sem  // LibÃ¨re 1 slot
```

Ã‰tat du canal :
```
sem = [X, X, X, _]  // 1 slot libÃ©rÃ©
```

La goroutine qui Ã©tait bloquÃ©e peut maintenant continuer !

---

#### Pourquoi `struct{}` et pas `int` ?

```go
// âŒ Version avec int
var sem = make(chan int, 8)
sem <- 1  // Envoie un entier (occupe 8 bytes en mÃ©moire)
```

```go
// âœ… Version avec struct{}
var sem = make(chan struct{}, 8)
sem <- struct{}{}  // Envoie une struct vide (occupe 0 byte !)
```

`struct{}` est le seul type en Go qui a une **taille mÃ©moire de 0 byte**.

On ne veut pas transmettre de donnÃ©es, juste **signaler** qu'un slot est pris/libÃ©rÃ©.

**Ã‰conomie :** Sur 1 million de requÃªtes, cela Ã©vite de gaspiller 8 MB de RAM inutilement.

---

### ğŸ¬ Exemple concret avec 8 cÅ“urs

```
CPU : 8 cÅ“urs disponibles
sem = make(chan struct{}, 8)

RequÃªte 1  arrive â†’ sem <- struct{}{} â†’ slot 1 pris â†’ traitement dÃ©marre
RequÃªte 2  arrive â†’ sem <- struct{}{} â†’ slot 2 pris â†’ traitement dÃ©marre
RequÃªte 3  arrive â†’ sem <- struct{}{} â†’ slot 3 pris â†’ traitement dÃ©marre
...
RequÃªte 8  arrive â†’ sem <- struct{}{} â†’ slot 8 pris â†’ traitement dÃ©marre

sem = [X, X, X, X, X, X, X, X]  // Tous les cÅ“urs occupÃ©s

RequÃªte 9  arrive â†’ sem <- struct{}{} â†’ â¸ï¸ BLOQUE (attend qu'un slot se libÃ¨re)
RequÃªte 10 arrive â†’ sem <- struct{}{} â†’ â¸ï¸ BLOQUE
...

RequÃªte 1 termine â†’ <-sem â†’ slot 1 libÃ©rÃ©
sem = [_, X, X, X, X, X, X, X]

RequÃªte 9 dÃ©bloquÃ©e â†’ occupe le slot 1 â†’ traitement dÃ©marre
```

---

### ğŸ“Š Comparaison

| Approche | 1000 requÃªtes simultanÃ©es | Utilisation CPU | Temps total |
|----------|---------------------------|-----------------|-------------|
| Sans limitation | 1000 goroutines actives | 100% (thrashing) | ~60s |
| Worker Pool (8 slots) | Max 8 goroutines actives | ~85% (optimal) | ~25s |

**Gain :** **2.4x plus rapide** grÃ¢ce Ã  une meilleure utilisation du CPU

---

<a name="syncpool"></a>
## 5. sync.Pool â€” Recyclage de la mÃ©moire

### ğŸ¯ Le problÃ¨me

Pour encoder une image en JPEG, on a besoin d'un **buffer** (`bytes.Buffer`) temporaire.

```go
// âŒ APPROCHE NAÃVE
func handleOptimize(w http.ResponseWriter, r *http.Request) {
    buf := new(bytes.Buffer)  // Alloue un nouveau buffer
    jpeg.Encode(buf, img, nil)
    w.Write(buf.Bytes())
    // buf est dÃ©truit par le garbage collector aprÃ¨s la fonction
}
```

**Qu'est-ce qui se passe pour 1000 requÃªtes ?**

```
RequÃªte 1  â†’ alloue buffer (32 KB) â†’ utilise â†’ GC dÃ©truit
RequÃªte 2  â†’ alloue buffer (32 KB) â†’ utilise â†’ GC dÃ©truit
RequÃªte 3  â†’ alloue buffer (32 KB) â†’ utilise â†’ GC dÃ©truit
...
RequÃªte 1000 â†’ alloue buffer (32 KB) â†’ utilise â†’ GC dÃ©truit
```

**ProblÃ¨me :** Le **Garbage Collector (GC)** doit constamment :
1. DÃ©tecter les buffers inutilisÃ©s
2. Les libÃ©rer de la mÃ©moire

Cela consomme du **temps CPU** et crÃ©e des **pauses** dans le traitement.

---

### âœ… La solution : sync.Pool

Au lieu de dÃ©truire les buffers, on les **recycle** !

```go
// Pool global de buffers
var bufPool = sync.Pool{
    New: func() any {
        return new(bytes.Buffer)  // CrÃ©e un buffer UNIQUEMENT si le pool est vide
    },
}

func handleOptimize(w http.ResponseWriter, r *http.Request) {
    // RÃ©cupÃ¨re un buffer du pool (ou en crÃ©e un si pool vide)
    buf := bufPool.Get().(*bytes.Buffer)
    buf.Reset()  // Remet le buffer Ã  zÃ©ro (efface les donnÃ©es prÃ©cÃ©dentes)
    
    defer bufPool.Put(buf)  // Remet le buffer dans le pool Ã  la fin
    
    jpeg.Encode(buf, img, nil)
    w.Write(buf.Bytes())
}
```

---

### ğŸ”„ Cycle de vie d'un buffer

```
1Ã¨re requÃªte :
  Pool vide â†’ New() crÃ©e un buffer â†’ utilise â†’ Put() le stocke

2Ã¨me requÃªte :
  Pool a 1 buffer â†’ Get() le rÃ©cupÃ¨re â†’ Reset() efface â†’ utilise â†’ Put() le stocke

3Ã¨me requÃªte :
  Pool a 1 buffer â†’ Get() le rÃ©cupÃ¨re â†’ Reset() efface â†’ utilise â†’ Put() le stocke

...
```

**RÃ©sultat :** AprÃ¨s la 1Ã¨re requÃªte, **aucune nouvelle allocation mÃ©moire** ! On rÃ©utilise toujours les mÃªmes buffers.

---

### âš ï¸ Pourquoi `buf.Reset()` ?

Si on oublie `Reset()`, le buffer garde les donnÃ©es de la requÃªte prÃ©cÃ©dente !

```go
// âŒ SANS RESET
RequÃªte 1 : buf contient "image1.jpg" â†’ traite â†’ Put(buf)
RequÃªte 2 : Get(buf) â†’ buf contient ENCORE "image1.jpg" â†’ ğŸ’¥ corruption de donnÃ©es
```

```go
// âœ… AVEC RESET
RequÃªte 1 : buf contient "image1.jpg" â†’ traite â†’ Put(buf)
RequÃªte 2 : Get(buf) â†’ Reset() vide buf â†’ buf est propre â†’ âœ…
```

---

### ğŸ“Š Comparaison

| Approche | Allocations pour 1000 requÃªtes | Temps GC | RAM max |
|----------|-------------------------------|----------|---------|
| Sans Pool | 1000 allocations | ~100ms | ~32 MB |
| Avec Pool | ~8 allocations (1 par cÅ“ur CPU) | ~5ms | ~256 KB |

**Gain :** **20x moins de pression sur le GC**

---

<a name="chargement-unique"></a>
## 6. Chargement unique des ressources

### ğŸ¯ Le problÃ¨me

Pour dessiner le watermark, on a besoin d'une **police de caractÃ¨res** (fichier `.ttf`).

```go
// âŒ MAUVAISE APPROCHE
func handleOptimize(w http.ResponseWriter, r *http.Request) {
    fontBytes, _ := os.ReadFile("/fonts/Helvetica.ttc")  // Lit le fichier (2 MB)
    f, _ := opentype.ParseCollection(fontBytes)           // Parse le fichier
    font0, _ := f.Font(0)
    fontFace, _ := opentype.NewFace(font0, &options)
    
    // Utilise la police pour le watermark
    // ...
}
```

**Pour 1000 requÃªtes :**
```
1000 lectures fichier Ã— 2 MB = 2 GB lus depuis le disque ğŸ˜±
1000 parsing de police = Ã©norme perte de temps CPU
```

---

### âœ… La solution : Variable globale

On charge la police **une seule fois** au dÃ©marrage du serveur.

```go
// Variable globale (partagÃ©e entre toutes les requÃªtes)
var fontFace font.Face

func main() {
    loadFont()  // ChargÃ© UNE FOIS au dÃ©marrage
    http.ListenAndServe(":3001", nil)
}

func loadFont() error {
    fontBytes, _ := os.ReadFile(fontPath)
    f, _ := opentype.ParseCollection(fontBytes)
    font0, _ := f.Font(0)
    fontFace, _ = opentype.NewFace(font0, &opentype.FaceOptions{
        Size: 48,
        DPI:  72,
    })
    return nil
}

func handleOptimize(w http.ResponseWriter, r *http.Request) {
    // Utilise directement fontFace (dÃ©jÃ  chargÃ©e)
    drawer := &font.Drawer{
        Dst:  img,
        Src:  image.White,
        Face: fontFace,  // âœ… Pas besoin de recharger
    }
}
```

---

### âš ï¸ Thread-safety

**Question :** Plusieurs goroutines peuvent-elles utiliser `fontFace` en mÃªme temps sans danger ?

**RÃ©ponse :** Oui ! Tant qu'on ne **modifie pas** `fontFace`, c'est safe.

```go
// âœ… LECTURE SEULE (safe)
drawer.Face = fontFace  // Plusieurs goroutines peuvent lire en mÃªme temps

// âŒ Ã‰CRITURE (dangereux sans mutex)
fontFace = newFont  // Si plusieurs goroutines modifient en mÃªme temps â†’ corruption
```

Dans notre cas, `fontFace` est en **lecture seule** â†’ aucun problÃ¨me.

---

### ğŸ“Š Comparaison

| Approche | I/O disque pour 1000 requÃªtes | Temps parsing |
|----------|-------------------------------|---------------|
| Chargement Ã  chaque requÃªte | 2 GB | ~5 secondes |
| Chargement unique | 2 MB (1 fois) | ~5 ms (1 fois) |

**Gain :** **1000x moins d'I/O disque**

---

<a name="gzip"></a>
## 7. Compression Gzip â€” RÃ©duction de la bande passante

### ğŸ¯ Le problÃ¨me

Une image optimisÃ©e fait environ **325 KB**. Pour 1000 utilisateurs :

```
325 KB Ã— 1000 = 325 MB de bande passante utilisÃ©e
```

**CoÃ»t :** Sur un serveur avec une connexion limitÃ©e, cela peut saturer la bande passante.

---

### âœ… La solution : Compression Gzip

On compresse la rÃ©ponse **Ã  la volÃ©e** si le navigateur le supporte.

```go
func handleUpload(w http.ResponseWriter, r *http.Request) {
    // ... traitement image ...
    
    // VÃ©rifie si le client accepte gzip
    if strings.Contains(r.Header.Get("Accept-Encoding"), "gzip") {
        w.Header().Set("Content-Encoding", "gzip")
        
        gz, _ := gzip.NewWriterLevel(w, gzip.BestSpeed)
        defer gz.Close()
        
        io.Copy(gz, resp.Body)  // Compresse en streaming
    } else {
        io.Copy(w, resp.Body)  // Envoie non compressÃ©
    }
}
```

---

### ğŸ” Explication

#### `Accept-Encoding: gzip`

Quand le navigateur envoie une requÃªte, il indique les compressions qu'il supporte :

```
GET /upload HTTP/1.1
Host: localhost:3000
Accept-Encoding: gzip, deflate, br
```

On vÃ©rifie si `gzip` est dans la liste.

---

#### `gzip.BestSpeed` vs `gzip.BestCompression`

| Niveau | Taux de compression | Vitesse | Use case |
|--------|---------------------|---------|----------|
| `BestSpeed` | ~15% de rÃ©duction | TrÃ¨s rapide | Serveur web (c'est notre cas) |
| `DefaultCompression` | ~20% de rÃ©duction | Moyen | Ã‰quilibre |
| `BestCompression` | ~25% de rÃ©duction | Lent | Archivage de fichiers |

On choisit `BestSpeed` car on veut **privilÃ©gier la latence** (rÃ©pondre vite) plutÃ´t que d'Ã©conomiser quelques KB supplÃ©mentaires.

---

### ğŸ“Š Comparaison

| Fichier | Taille originale | Taille compressÃ©e | Gain |
|---------|------------------|-------------------|------|
| Image JPEG optimisÃ©e | 325 KB | ~280 KB | 14% |
| HTML page | 50 KB | ~8 KB | 84% |
| JSON data | 100 KB | ~15 KB | 85% |

**Note :** JPEG est dÃ©jÃ  compressÃ© (c'est un format avec perte), donc le gain est faible (~14%). Mais pour du texte (HTML, JSON), le gain est Ã©norme (80%+).

**Bande passante Ã©conomisÃ©e :** Pour 1000 requÃªtes :
```
Sans gzip : 325 MB
Avec gzip : 280 MB
Ã‰conomie  : 45 MB (~14%)
```

---

<a name="redis"></a>
## 8. Redis â€” Cache en mÃ©moire RAM

### ğŸ¯ C'est quoi Redis ?

**Redis** = **RE**mote **DI**ctionary **S**erver

C'est une base de donnÃ©es qui stocke tout **en RAM** (pas sur disque comme MySQL/PostgreSQL).

**Analogie :** C'est comme un dictionnaire gÃ©ant ultra-rapide :

```python
redis = {
    "clÃ©_1": "valeur_1",
    "clÃ©_2": "valeur_2",
    ...
}
```

**Pourquoi c'est rapide ?**

| OpÃ©ration | Disque SSD | RAM |
|-----------|------------|-----|
| Lire 1 KB | ~100 Âµs | ~0.1 Âµs |

**RAM = 1000x plus rapide que le disque**

---

### ğŸ¯ Le problÃ¨me

Traiter une image prend du temps :

```
Resize (1920Ã—1080 â†’ 800Ã—600) : ~80ms
Watermark (draw text)        : ~20ms
Encode JPEG                  : ~100ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                        : ~200ms
```

Si 100 utilisateurs uploadent **la mÃªme image** :

```
100 Ã— 200ms = 20 secondes de CPU gaspillÃ©
```

On refait 100 fois le mÃªme travail pour le mÃªme rÃ©sultat ğŸ˜±

---

### âœ… La solution : Cache Redis

**Principe :** On traite l'image **une seule fois**, puis on stocke le rÃ©sultat dans Redis.

```
1Ã¨re requÃªte  : Upload â†’ Traitement (200ms) â†’ Stocke dans Redis â†’ RÃ©pond au client
2Ã¨me requÃªte  : Upload â†’ Redis (< 1ms)                         â†’ RÃ©pond au client
3Ã¨me requÃªte  : Upload â†’ Redis (< 1ms)                         â†’ RÃ©pond au client
...
100Ã¨me requÃªte: Upload â†’ Redis (< 1ms)                         â†’ RÃ©pond au client
```

**Gain :** Au lieu de 20 secondes, on consomme `200ms + 99Ã—1ms = ~300ms` de CPU.

**66x plus efficace !**

---

### ğŸ”‘ Comment identifier une image ?

On a besoin d'une **clÃ© unique** pour chaque image diffÃ©rente.

**Mauvaise idÃ©e :** Utiliser le nom du fichier
```
"chat.jpg" â†’ mais si 2 personnes uploadent des images diffÃ©rentes nommÃ©es "chat.jpg" ?
```

**Bonne idÃ©e :** Calculer l'**empreinte SHA256** du contenu

---

### ğŸ” SHA256 â€” L'empreinte unique

**SHA256** = algorithme de hachage cryptographique

Il transforme **n'importe quelle donnÃ©e** en une chaÃ®ne de **64 caractÃ¨res hexadÃ©cimaux**.

```go
import "crypto/sha256"

data := []byte("Hello World")
hash := sha256.Sum256(data)
hashString := hex.EncodeToString(hash[:])
// hashString = "a591a6d40bf420404a011733cfb7b190d62c65bf0bcda32b57b277d9ad9f146e"
```

---

### âœ¨ PropriÃ©tÃ©s magiques de SHA256

#### 1. DÃ©terministe
MÃªme entrÃ©e â†’ toujours le mÃªme hash
```
"Hello" â†’ "185f8db32271fe25f561a6fc938b2e264306ec304eda518007d1764826381969"
"Hello" â†’ "185f8db32271fe25f561a6fc938b2e264306ec304eda518007d1764826381969"
"Hello" â†’ "185f8db32271fe25f561a6fc938b2e264306ec304eda518007d1764826381969"
```

#### 2. Sensible au moindre changement
Moindre modification â†’ hash complÃ¨tement diffÃ©rent
```
"Hello"  â†’ "185f8db32271fe25f561a6fc938b2e264306ec304eda518007d1764826381969"
"hello"  â†’ "2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824"
         (juste Hâ†’h change TOUT le hash)
```

#### 3. Collisions quasi-impossibles
ProbabilitÃ© que 2 images diffÃ©rentes aient le mÃªme hash :
```
1 / (2^256) â‰ˆ 1 / 115 quattuorvigintillion
```

C'est plus que le nombre d'atomes dans l'univers ğŸ¤¯

---

### ğŸ’¾ ImplÃ©mentation du cache

```go
import (
    "crypto/sha256"
    "encoding/hex"
    "github.com/redis/go-redis/v9"
)

var redisClient = redis.NewClient(&redis.Options{
    Addr: "localhost:6379",
})

func handleUpload(w http.ResponseWriter, r *http.Request) {
    file, _, _ := r.FormFile("image")
    data, _ := io.ReadAll(file)
    
    // 1. Calculer le hash de l'image
    hash := sha256.Sum256(data)
    cacheKey := hex.EncodeToString(hash[:])
    
    // 2. VÃ©rifier si dÃ©jÃ  dans le cache
    cached, err := redisClient.Get(ctx, cacheKey).Bytes()
    if err == nil {
        // âœ… CACHE HIT : L'image a dÃ©jÃ  Ã©tÃ© traitÃ©e
        w.Write(cached)
        return
    }
    
    // âŒ CACHE MISS : 1Ã¨re fois qu'on voit cette image
    
    // 3. Envoyer Ã  l'optimizer
    optimized := sendToOptimizer(data)
    
    // 4. Stocker dans Redis (expire aprÃ¨s 24h)
    redisClient.Set(ctx, cacheKey, optimized, 24*time.Hour)
    
    // 5. RÃ©pondre au client
    w.Write(optimized)
}
```

---

### â° TTL â€” Time To Live

**ProblÃ¨me :** Si on stocke toutes les images pour toujours, Redis va consommer toute la RAM du serveur.

**Solution :** On donne une **durÃ©e de vie** Ã  chaque entrÃ©e.

```go
redisClient.Set(ctx, cacheKey, data, 24*time.Hour)
                                      ^^^^^^^^^^^^
                                      TTL = 24 heures
```

**Timeline :**
```
t = 0h    â†’ Redis.Set("abc123...", imageData, 24h)
            Redis stocke : {"abc123...": imageData, expireAt: 2026-02-24 14:00}

t = 12h   â†’ Redis.Get("abc123...")
            âœ… retourne imageData (encore valide)

t = 24h   â†’ Redis supprime automatiquement l'entrÃ©e

t = 25h   â†’ Redis.Get("abc123...")
            âŒ KeyNotFound â†’ CACHE MISS â†’ retraitement
```

---

### ğŸ” Inspecter Redis en ligne de commande

```bash
# Se connecter Ã  Redis dans Docker
docker exec -it watermark-redis-1 redis-cli

# Voir toutes les clÃ©s stockÃ©es
KEYS *
# Exemple de sortie :
# 1) "063129c3a4ad87ec..."
# 2) "a3f8c2d1e4b79f3c..."

# Voir le TTL restant d'une clÃ© (en secondes)
TTL "063129c3a4ad87ec..."
# 43200  (= 12 heures restantes)

# Voir la taille d'une entrÃ©e (en bytes)
STRLEN "063129c3a4ad87ec..."
# 325480  (= 325 KB)

# Surveiller Redis en temps rÃ©el (affiche chaque commande)
MONITOR

# Statistiques mÃ©moire
INFO memory
```

---

### ğŸ“Š Impact du cache

**ScÃ©nario :** 1000 utilisateurs uploadent 100 images uniques (10 utilisateurs par image).

#### Sans cache
```
1000 requÃªtes Ã— 200ms = 200 secondes de CPU
```

#### Avec cache
```
100 images uniques Ã— 200ms = 20 secondes
900 cache hits Ã— 1ms       = 0.9 secondes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                      = 20.9 secondes
```

**Gain :** **10x plus rapide**

---

### ğŸ¯ Cache HIT vs Cache MISS â€” Visualisation

```
RequÃªte 1 (image A) :
  Client â†’ API â†’ hash="abc123..."
               â†’ Redis.Get("abc123...") â†’ âŒ KeyNotFound (MISS)
               â†’ Optimizer (200ms)
               â†’ Redis.Set("abc123...", result, 24h)
               â†’ Client (total: 203ms)

RequÃªte 2 (image A, mÃªme image) :
  Client â†’ API â†’ hash="abc123..."
               â†’ Redis.Get("abc123...") â†’ âœ… TrouvÃ© (HIT)
               â†’ Client (total: 3ms)

RequÃªte 3 (image B, diffÃ©rente) :
  Client â†’ API â†’ hash="def456..."
               â†’ Redis.Get("def456...") â†’ âŒ KeyNotFound (MISS)
               â†’ Optimizer (200ms)
               â†’ Redis.Set("def456...", result, 24h)
               â†’ Client (total: 203ms)

RequÃªte 4 (image A, encore) :
  Client â†’ API â†’ hash="abc123..."
               â†’ Redis.Get("abc123...") â†’ âœ… TrouvÃ© (HIT)
               â†’ Client (total: 3ms)
```

---

<a name="minio"></a>
## 9. MinIO â€” Stockage objet persistant

### ğŸ¯ Le problÃ¨me

Si l'optimizer plante en plein traitement, l'image uploadÃ©e par le client est **perdue** â€” il doit tout re-uploader.

```
ScÃ©nario sans MinIO :
  Client envoie image â†’ optimizer crash en cours de route
  â†’ image perdue, client doit rÃ©-uploader
  â†’ si optimizer reste KO, traitement impossible
```

---

### âœ… La solution : sauvegarder l'original d'abord

**MinIO** est un serveur de stockage objet **compatible avec l'API Amazon S3**, qui persiste sur disque.

DÃ¨s que l'image arrive, elle est sauvegardÃ©e dans MinIO **avant** d'Ãªtre envoyÃ©e Ã  l'optimizer. Si l'optimizer plante, l'API rÃ©cupÃ¨re l'original depuis MinIO et **rÃ©essaie automatiquement**.

```
bucket "watermarks"
â””â”€â”€ original/
    â”œâ”€â”€ a3f8c2d1e4b79f3c....jpg   (image originale, 2.1 MB)
    â”œâ”€â”€ 063129c3a4ad87ec....jpg   (image originale, 3.4 MB)
    â””â”€â”€ b7e2f1a0d5c84e9b....jpg   (image originale, 1.8 MB)
```

---

### ğŸ”„ Flow complet

```
â‘  Lecture image
â‘¡ SHA256

â‘¢ Redis.Get â”€â”€â–º âœ… HIT  â†’ rÃ©pond immÃ©diatement (< 1ms)

â‘¢ Redis.Get â”€â”€â–º âŒ MISS
        â”‚
        â‘£ MinIO.Put("original/<hash>.jpg")  â† original sauvegardÃ© sur disque
        â”‚
        â‘¤ Optimizer
        â”‚
        â”œâ”€â”€â–º âœ… OK
        â”‚       â‘¥ Redis.Set (TTL 24h)
        â”‚       â‘¦ RÃ©pond au client (~200ms)
        â”‚
        â””â”€â”€â–º âŒ KO (crash, timeout)
                â”‚
                MinIO.Get("original/<hash>.jpg")  â† rÃ©cupÃ¨re l'original
                â”‚
                â‘¤b Optimizer (2Ã¨me tentative)
                â”‚
                â”œâ”€â”€â–º âœ… OK â†’ â‘¥ Redis.Set â†’ â‘¦ RÃ©pond
                â””â”€â”€â–º âŒ KO â†’ 502 Bad Gateway
```

---

### ğŸ’¾ ImplÃ©mentation

```go
// Ã‰tape 4 : sauvegarder l'original AVANT de traiter
minioClient.PutObject(ctx, minioBucket, "original/"+cacheKey+".jpg",
    bytes.NewReader(data), int64(len(data)),
    minio.PutObjectOptions{ContentType: "image/jpeg"},
)

// Ã‰tape 5 : envoyer Ã  l'optimizer
result, err := sendToOptimizer(optimizerURL, filename, data)
if err != nil {
    // Optimizer KO â†’ rÃ©cupÃ©rer l'original depuis MinIO et rÃ©essayer
    obj, _ := minioClient.GetObject(ctx, minioBucket, "original/"+cacheKey+".jpg", ...)
    recovered, _ := io.ReadAll(obj)
    result, err = sendToOptimizer(optimizerURL, filename, recovered)
    if err != nil {
        http.Error(w, "Microservice indisponible", 502)
        return
    }
}

// Ã‰tape 6 : mettre en cache Redis
redisClient.Set(ctx, cacheKey, result, 24*time.Hour)
```

---

### âš ï¸ Sauvegarde non bloquante

Si MinIO est indisponible, on continue quand mÃªme vers l'optimizer :

```go
_, err = minioClient.PutObject(...)
if err != nil {
    log.Printf("âš  Sauvegarde original Ã©chouÃ©e : %v", err)
    // On continue â€” pas de sauvegarde, mais le traitement s'effectue quand mÃªme
}
```

**PrioritÃ© :** Traiter et rÃ©pondre > Sauvegarder dans MinIO

---

### ğŸ–¥ï¸ Console web MinIO

MinIO expose une interface web sur le port **9001** :

```
http://localhost:9001
Login : minioadmin / minioadmin
```

Elle permet de :
- Parcourir les objets stockÃ©s
- TÃ©lÃ©charger/supprimer des images
- Voir la consommation disque
- GÃ©rer les buckets et les permissions

---

### ğŸ” Inspecter MinIO en ligne de commande

```bash
# Installer le client MinIO (mc)
brew install minio/stable/mc

# Configurer l'alias
mc alias set local http://localhost:9000 minioadmin minioadmin

# Lister les objets du bucket
mc ls local/watermarks

# Voir la taille totale du bucket
mc du local/watermarks

# TÃ©lÃ©charger un objet
mc cp local/watermarks/abc123....jpg ./output.jpg
```

---

### ğŸ“Š Redis vs MinIO

| CritÃ¨re | Redis | MinIO |
|---------|-------|-------|
| Vitesse | < 1ms | ~5ms |
| Persistance | Non (RAM) | Oui (disque) |
| TTL | 24h | IllimitÃ© |
| Survit au reboot | Non | Oui |
| CapacitÃ© | RAM (limitÃ©e) | Disque (grande) |
| Usage | Cache chaud | Stockage long terme |

**Gain :** L'image originale est toujours rÃ©cupÃ©rable. Si l'optimizer plante, la **reprise est automatique** sans que le client ait Ã  rÃ©-uploader.

---

<a name="rÃ©sumÃ©"></a>
## 10. ğŸ“Š RÃ©sumÃ© des gains de performance

| Optimisation | ProblÃ¨me rÃ©solu | Gain | Ressource Ã©conomisÃ©e |
|--------------|-----------------|------|----------------------|
| **io.Pipe** | RAM saturÃ©e par les uploads | **300x** | RAM |
| **http.Client partagÃ©** | Connexions TCP rÃ©pÃ©tÃ©es | **12x** | Latence rÃ©seau |
| **Worker Pool** | CPU saturÃ© par trop de goroutines | **2.4x** | CPU |
| **sync.Pool** | Allocations mÃ©moire constantes | **20x** | GC / RAM |
| **Chargement unique** | Lecture fichier rÃ©pÃ©tÃ©e | **1000x** | I/O disque |
| **Gzip** | Bande passante gaspillÃ©e | **14%** | RÃ©seau |
| **Redis cache** | Retraitement inutile | **66x** | CPU |
| **MinIO** | Perte donnÃ©es aprÃ¨s reboot | **âˆ** | DurabilitÃ© |

---

## ğŸ¯ Performance globale

**Sans optimisations :**
```
1000 images uploadÃ©es simultanÃ©ment
â†’ 1000 MB RAM
â†’ 60 secondes CPU
â†’ 325 MB bande passante
â†’ Crash probable ğŸ’¥
```

**Avec optimisations :**
```
1000 images uploadÃ©es simultanÃ©ment
â†’ 3 MB RAM (-99.7%)
â†’ 4 secondes CPU (-93%)
â†’ 280 MB bande passante (-14%)
â†’ Serveur stable âœ…
```

---

## ğŸ§  Concepts clÃ©s Ã  retenir

### 1. **Streaming > Buffering**
Ne charge jamais tout en mÃ©moire si tu peux le traiter par morceaux.

### 2. **RÃ©utilisation > CrÃ©ation**
RÃ©utilise les connexions TCP, les buffers, les ressources chargÃ©es.

### 3. **Limitation > LibertÃ©**
Limite les goroutines actives pour Ã©viter la saturation CPU.

### 4. **Cache > Recalcul**
Si le rÃ©sultat est dÃ©terministe, stocke-le en cache.

### 5. **RAM > Disque**
La RAM est 1000x plus rapide. Utilise Redis pour les donnÃ©es frÃ©quentes.

### 6. **Compression = Gratuit**
Gzip coÃ»te peu de CPU mais Ã©conomise beaucoup de bande passante.

---

## ğŸ“š Pour aller plus loin

- **Profiling Go** : `go tool pprof` pour identifier les bottlenecks
- **Monitoring Redis** : `redis-cli --stat` pour voir les stats en temps rÃ©el
- **Load testing** : `wrk`, `hey`, ou `k6` pour tester la charge
- **Distributed caching** : Redis Cluster pour scaler horizontalement

---

**ğŸ“ Fin du cours â€” Serveur Haute Performance**