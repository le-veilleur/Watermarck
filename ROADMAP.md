# Roadmap : Serveur Haute Performance
## Tout ce qu'on peut apprendre et implÃ©menter sur NWS Watermark

---

## ğŸ“‹ Table des matiÃ¨res

1. [Ã‰tat actuel du projet](#actuel)
2. [ObservabilitÃ© â€” voir ce qui se passe](#observabilite)
3. [RÃ©silience â€” ne pas tomber sous charge](#resilience)
4. [Performance Go â€” le runtime en profondeur](#go-perf)
5. [Cache avancÃ© â€” aller plus loin que Redis](#cache)
6. [HTTP avancÃ© â€” protocoles modernes](#http)
7. [Optimisation image â€” formats et parallÃ©lisme](#image)
8. [Architecture distribuÃ©e â€” scaler horizontalement](#distribue)
9. [Linux & OS â€” le niveau zÃ©ro](#linux)
10. [Load testing â€” mesurer avant d'optimiser](#load-testing)
11. [Chaos Engineering â€” tester les pannes](#chaos)
12. [SÃ©curitÃ© â€” ce qui manque en prod](#securite)
13. [Ordre d'apprentissage suggÃ©rÃ©](#ordre)

---

<a name="actuel"></a>
## 1. Ã‰tat actuel du projet

Ce qu'on a dÃ©jÃ  implÃ©mentÃ© et ce que Ã§a couvre :

```
NWS Watermark â€” ce qui est fait
â”‚
â”œâ”€â”€ API (Go)
â”‚   â”œâ”€â”€ âœ… Cache Redis (SHA256 â†’ image watermarkÃ©e, TTL 24h)
â”‚   â”œâ”€â”€ âœ… Stockage MinIO (original dÃ©dupliquÃ© par hash image)
â”‚   â”œâ”€â”€ âœ… Fallback RabbitMQ (si optimizer KO â†’ job persistent)
â”‚   â”œâ”€â”€ âœ… gzip (Content-Encoding nÃ©gociÃ© via Accept-Encoding)
â”‚   â”œâ”€â”€ âœ… io.Pipe (streaming multipart sans buffer intermÃ©diaire)
â”‚   â””â”€â”€ âœ… Cache key = SHA256(image + wm_text|wm_position)
â”‚
â”œâ”€â”€ Optimizer (Go)
â”‚   â”œâ”€â”€ âœ… Worker pool (semaphore = 1 slot/CPU)
â”‚   â”œâ”€â”€ âœ… sync.Pool (buffers JPEG recyclÃ©s)
â”‚   â”œâ”€â”€ âœ… Resize BiLinear (ratio prÃ©servÃ©, max 1920Ã—1080)
â”‚   â”œâ”€â”€ âœ… Watermark adaptatif (couleur auto fond clair/sombre)
â”‚   â””â”€â”€ âœ… Position dynamique (4 coins via formulaire)
â”‚
â””â”€â”€ Front (React)
    â”œâ”€â”€ âœ… Drag & drop
    â”œâ”€â”€ âœ… Slider avant/aprÃ¨s
    â”œâ”€â”€ âœ… Pipeline visualisÃ© (latence par Ã©tape)
    â””â”€â”€ âœ… ParamÃ¨tres watermark (texte + position)
```

Ce tableau montre oÃ¹ on en est. Tout ce qui suit est ce qui manque.

---

<a name="observabilite"></a>
## 2. ObservabilitÃ© â€” voir ce qui se passe

> **Principe :** on ne peut pas optimiser ce qu'on ne mesure pas.
> Sans observabilitÃ©, on optimise Ã  l'aveugle et on rate les vrais bottlenecks.

---

### 2.1 pprof â€” profiling CPU et mÃ©moire

**C'est quoi :** un outil intÃ©grÃ© Ã  Go qui enregistre oÃ¹ le CPU passe son temps et ce qui est allouÃ© en mÃ©moire.

**Ce qu'on apprendrait :**
- Flame graphs (visualiser la pile d'appels)
- Heap profiling (trouver les allocations qui font pression sur le GC)
- Goroutine profiling (dÃ©tecter les goroutines bloquÃ©es)
- Mutex profiling (trouver les contensions de locks)

**Comment l'implÃ©menter sur le projet :**

```go
import _ "net/http/pprof"  // l'import suffit Ã  enregistrer les routes

// Exposer sur un port sÃ©parÃ© (ne jamais exposer en prod sur le port public)
go func() {
    log.Println(http.ListenAndServe(":6060", nil))
}()
```

```bash
# Analyser le CPU pendant 30 secondes pendant un load test
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30

# Analyser la heap
go tool pprof http://localhost:6060/debug/pprof/heap

# Voir les goroutines bloquÃ©es
go tool pprof http://localhost:6060/debug/pprof/goroutine
```

**Ce qu'on dÃ©couvrirait probablement :**
- `adaptiveColor` est le bottleneck (boucle pixel par pixel)
- `jpeg.Encode` alloue malgrÃ© le sync.Pool si mal utilisÃ©
- Les goroutines RabbitMQ en attente consomment de la mÃ©moire

**DifficultÃ© :** â­â­ â€” intÃ©gration triviale, lecture des flame graphs demande de la pratique

---

### 2.2 Prometheus + Grafana â€” mÃ©triques en temps rÃ©el

**C'est quoi :** Prometheus collecte des mÃ©triques numÃ©riques toutes les N secondes (scraping), Grafana les affiche en dashboards.

**Ce qu'on apprendrait :**
- Les 4 types de mÃ©triques : Counter, Gauge, Histogram, Summary
- Le modÃ¨le Pull (Prometheus scrape le serveur) vs Push (le serveur envoie)
- Les percentiles : p50, p95, p99 (pourquoi la moyenne ment)
- PromQL â€” le langage de requÃªte

**MÃ©triques Ã  exposer sur le projet :**

```go
import "github.com/prometheus/client_golang/prometheus"

var (
    // Nombre total d'uploads
    uploadsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{Name: "uploads_total"},
        []string{"status"},  // labels: "success", "error", "rabbit"
    )

    // Latence du pipeline par Ã©tape
    stepDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "pipeline_step_duration_seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"step"},  // "redis", "minio", "optimizer", "gzip"
    )

    // Taux de cache hit Redis
    cacheHits = prometheus.NewCounter(
        prometheus.CounterOpts{Name: "redis_cache_hits_total"},
    )

    // Taille des images en entrÃ©e/sortie
    imageSize = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "image_size_bytes",
            Buckets: prometheus.ExponentialBuckets(1024, 2, 20),
        },
        []string{"type"},  // "input", "output"
    )
)
```

**Dashboard Grafana qu'on pourrait construire :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NWS Watermark â€” Performance Dashboard                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Uploads/sec  â”‚ Cache hit %  â”‚ p99 latency  â”‚ Queue depth    â”‚
â”‚    42 req/s  â”‚    87%       â”‚    1.2s      â”‚   RabbitMQ: 3  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Latence par Ã©tape (p95)                   â”‚
â”‚  Redis   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  2ms                                    â”‚
â”‚  MinIO   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  45ms                                   â”‚
â”‚  Optim.  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  320ms   â† bottleneck                   â”‚
â”‚  gzip    â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1ms                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DifficultÃ© :** â­â­â­ â€” intÃ©gration Go facile, design des mÃ©triques utiles demande de l'expÃ©rience

---

### 2.3 OpenTelemetry â€” tracing distribuÃ©

**C'est quoi :** suivre une requÃªte Ã  travers plusieurs services avec un identifiant unique (trace ID). Chaque opÃ©ration = un "span" avec sa durÃ©e.

**Ce qu'on apprendrait :**
- Propagation de contexte entre services (headers W3C TraceContext)
- CorrÃ©lation logs + traces
- DÃ©tecter les bottlenecks dans une chaÃ®ne de microservices
- Jaeger ou Tempo comme backend de visualisation

**Ce qu'on verrait pour un upload :**

```
Trace ID: abc123
â”‚
â”œâ”€â”€ [API] handleUpload              0ms â†’ 380ms
â”‚   â”œâ”€â”€ [API] readImage             0ms â†’ 2ms
â”‚   â”œâ”€â”€ [API] sha256                2ms â†’ 3ms
â”‚   â”œâ”€â”€ [API] redis.Get             3ms â†’ 5ms    â† MISS
â”‚   â”œâ”€â”€ [API] minio.Put             5ms â†’ 52ms   â† lent !
â”‚   â”œâ”€â”€ [API] sendToOptimizer       52ms â†’ 370ms
â”‚   â”‚   â””â”€â”€ [OPTIMIZER] handleOptimize  0ms â†’ 315ms
â”‚   â”‚       â”œâ”€â”€ decode              0ms â†’ 8ms
â”‚   â”‚       â”œâ”€â”€ resize              8ms â†’ 45ms
â”‚   â”‚       â”œâ”€â”€ watermark           45ms â†’ 312ms  â† TRÃˆS lent
â”‚   â”‚       â””â”€â”€ encode              312ms â†’ 315ms
â”‚   â””â”€â”€ [API] redis.Set             370ms â†’ 372ms
â””â”€â”€ [API] gzip + send               372ms â†’ 380ms
```

D'un coup on voit que `watermark` prend 267ms sur 380ms totaux.

**DifficultÃ© :** â­â­â­â­ â€” setup complexe, mais c'est le standard industrie

---

### 2.4 Structured logging â€” logs exploitables

**C'est quoi :** remplacer `log.Printf("[API] ...")` par du JSON structurÃ© avec des champs typÃ©s.

**Le problÃ¨me avec les logs actuels :**

```
[API] â‘¤ Optimizer  : âœ“ 245.3 KB reÃ§us en 312ms
```

Ce log est lisible mais **pas requÃªtable** â€” impossible de filtrer "tous les uploads > 500ms" ou "toutes les erreurs MinIO".

**Avec zerolog :**

```go
log.Info().
    Str("step", "optimizer").
    Int("bytes", len(result)).
    Dur("duration", optimizerDur).
    Str("filename", header.Filename).
    Msg("optimizer response received")
```

**Ce que Ã§a produit :**

```json
{"level":"info","step":"optimizer","bytes":251187,"duration_ms":312,"filename":"photo.jpg","time":"2026-02-24T10:23:41Z","message":"optimizer response received"}
```

RequÃªtable dans Loki, Elasticsearch, Datadog, etc.

**DifficultÃ© :** â­â­ â€” migration mÃ©canique mais disciplinÃ©e

---

### 2.5 Pyroscope â€” continuous profiling

**C'est quoi :** pprof en continu, toujours actif en prod, avec historique. On peut comparer "avant deploy" vs "aprÃ¨s deploy".

**Ce qu'on apprendrait :** comment les performances Ã©voluent dans le temps, dÃ©tecter des rÃ©gressions automatiquement.

**DifficultÃ© :** â­â­ â€” agent Ã  ajouter, dashboard fourni

---

<a name="resilience"></a>
## 3. RÃ©silience â€” ne pas tomber sous charge

> **Principe :** un systÃ¨me haute performance doit dÃ©grader gracieusement,
> pas s'effondrer brutalement.

---

### 3.1 Circuit Breaker

**C'est quoi :** si l'optimizer Ã©choue N fois consÃ©cutives, on "ouvre le circuit" â€” on arrÃªte d'essayer et on bascule directement sur RabbitMQ sans attendre le timeout HTTP.

**Les 3 Ã©tats :**

```
CLOSED (normal)
  â”‚  5 erreurs consÃ©cutives
  â–¼
OPEN (court-circuit)
  â”‚  aprÃ¨s 30 secondes
  â–¼
HALF-OPEN (test)
  â”‚  1 requÃªte test :
  â”‚  âœ… succÃ¨s â†’ retour CLOSED
  â””â”€ âŒ Ã©chec  â†’ retour OPEN
```

**Sans circuit breaker :**
```
100 requÃªtes simultanÃ©es â†’ chacune attend 30s timeout â†’ 100 goroutines bloquÃ©es
â†’ mÃ©moire Ã©puisÃ©e â†’ API crashe
```

**Avec circuit breaker :**
```
100 requÃªtes simultanÃ©es â†’ les 5 premiÃ¨res Ã©chouent â†’ circuit ouvert
â†’ les 95 suivantes â†’ RabbitMQ immÃ©diatement â†’ 0ms de blocage
```

```go
// Librairie : github.com/sony/gobreaker
cb := gobreaker.NewCircuitBreaker(gobreaker.Settings{
    MaxRequests:  1,              // 1 requÃªte test en half-open
    Interval:     10 * time.Second,
    Timeout:      30 * time.Second,
    ReadyToTrip:  func(counts gobreaker.Counts) bool {
        return counts.ConsecutiveFailures >= 5
    },
})

result, err := cb.Execute(func() (interface{}, error) {
    return sendToOptimizer(url, filename, data, wmText, wmPosition)
})
```

**Ce qu'on apprendrait :** patterns de rÃ©silience, fail-fast, bulkhead, le livre "Release It!" de Michael Nygard.

**DifficultÃ© :** â­â­â­

---

### 3.2 Rate Limiting â€” limiter les abus

**C'est quoi :** limiter le nombre de requÃªtes par IP (ou par token) pour Ã©viter qu'un client monopolise les ressources.

**Les deux algorithmes principaux :**

**Token Bucket** (notre cas idÃ©al) :
```
Bucket de 10 tokens, se remplit Ã  2 tokens/sec
â†’ bursts autorisÃ©s jusqu'Ã  10 requÃªtes instantanÃ©es
â†’ dÃ©bit moyen limitÃ© Ã  2 req/sec
```

**Sliding Window** :
```
Max 100 requÃªtes sur les 60 derniÃ¨res secondes glissantes
â†’ pas de burst autorisÃ©
â†’ plus Ã©quitable entre clients
```

```go
import "golang.org/x/time/rate"

// Map IP â†’ limiteur (avec nettoyage pÃ©riodique pour Ã©viter les fuites mÃ©moire)
var limiters sync.Map

func getLimiter(ip string) *rate.Limiter {
    if v, ok := limiters.Load(ip); ok {
        return v.(*rate.Limiter)
    }
    // 2 req/sec, burst de 10
    l := rate.NewLimiter(rate.Limit(2), 10)
    limiters.Store(ip, l)
    return l
}

func rateLimitMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        limiter := getLimiter(r.RemoteAddr)
        if !limiter.Allow() {
            http.Error(w, "Too Many Requests", http.StatusTooManyRequests)
            return
        }
        next.ServeHTTP(w, r)
    })
}
```

**Ce qu'on apprendrait :** Token Bucket, Leaky Bucket, Sliding Window Counter, `sync.Map`, nettoyage de state (TTL sur les entrÃ©es).

**DifficultÃ© :** â­â­

---

### 3.3 Retry avec backoff exponentiel + jitter

**Le problÃ¨me du retry fixe actuel :**

```go
// âŒ Actuel â€” retry fixe
time.Sleep(10 * time.Second)
```

Si 100 jobs Ã©chouent en mÃªme temps, ils rÃ©essaient **tous** dans 10 secondes â†’ pic de charge â†’ ils rÃ©Ã©chouent tous â†’ ...

**Backoff exponentiel + jitter :**

```go
// âœ… Exponential backoff avec jitter
func backoff(attempt int) time.Duration {
    base := time.Second
    max  := 5 * time.Minute
    exp  := base * (1 << attempt)  // 1s, 2s, 4s, 8s, 16s...
    if exp > max { exp = max }

    // Jitter : +/- 25% alÃ©atoire â†’ les retries se dispersent dans le temps
    jitter := time.Duration(rand.Int63n(int64(exp / 4)))
    return exp + jitter
}

// Attempt 0 :  1s  Â± 250ms
// Attempt 1 :  2s  Â± 500ms
// Attempt 2 :  4s  Â± 1s
// Attempt 3 :  8s  Â± 2s
// Attempt 4 : 16s  Â± 4s
```

**Ce qu'on apprendrait :** Thundering Herd problem, jitter, les patterns AWS de retry (https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/).

**DifficultÃ© :** â­â­

---

### 3.4 Context + timeout propagation

**C'est quoi :** passer un `context.Context` Ã  travers tout le pipeline pour que si le client coupe la connexion, toutes les opÃ©rations en cours s'annulent.

**Actuellement :** si le client ferme la connexion pendant le traitement, l'API continue quand mÃªme Ã  travailler (rÃ©sultat stockÃ© dans Redis pour rien).

```go
// Avec context propagÃ©
func handleUpload(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()  // annulÃ© si le client dÃ©connecte

    // Redis respecte le contexte
    cached, err := redisClient.Get(ctx, cacheKey).Bytes()

    // MinIO respecte le contexte
    _, err = minioClient.PutObject(ctx, bucket, key, ...)

    // Timeout sur l'optimizer : max 10s
    ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
    defer cancel()
    result, err := sendToOptimizer(ctx, url, filename, data, ...)
}
```

**Ce qu'on apprendrait :** `context.Context`, `context.WithTimeout`, `context.WithCancel`, `context.WithDeadline`, propagation dans les goroutines, annulation en cascade.

**DifficultÃ© :** â­â­â­ â€” conceptuellement simple, bien faire la propagation est subtil

---

### 3.5 Health checks + Readiness probes

**C'est quoi :** des endpoints qui disent si le service est vivant (`/health`) et prÃªt Ã  recevoir du trafic (`/ready`).

```go
// /health â€” le processus est-il vivant ?
mux.HandleFunc("GET /health", func(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
})

// /ready â€” toutes les dÃ©pendances sont-elles disponibles ?
mux.HandleFunc("GET /ready", func(w http.ResponseWriter, r *http.Request) {
    checks := map[string]string{}

    if err := redisClient.Ping(r.Context()).Err(); err != nil {
        checks["redis"] = err.Error()
    }
    if _, err := minioClient.BucketExists(r.Context(), minioBucket); err != nil {
        checks["minio"] = err.Error()
    }

    if len(checks) > 0 {
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(checks)
        return
    }
    w.WriteHeader(http.StatusOK)
})
```

**Ce qu'on apprendrait :** Kubernetes liveness/readiness/startup probes, graceful shutdown, load balancer integration.

**DifficultÃ© :** â­â­

---

### 3.6 Graceful shutdown

**C'est quoi :** quand le processus reÃ§oit SIGTERM (ex: `docker stop`), finir les requÃªtes en cours avant de s'arrÃªter.

```go
srv := &http.Server{Addr: ":3000", Handler: corsMiddleware(mux)}

go srv.ListenAndServe()

// Attendre SIGTERM ou SIGINT
quit := make(chan os.Signal, 1)
signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)
<-quit

// 30 secondes pour finir les requÃªtes en cours
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()
srv.Shutdown(ctx)
```

**Ce qu'on apprendrait :** signaux Unix, lifecycle d'un processus, rolling deployments sans coupure.

**DifficultÃ© :** â­â­

---

<a name="go-perf"></a>
## 4. Performance Go â€” le runtime en profondeur

> **Principe :** Go fait beaucoup de choses automatiquement (GC, scheduler).
> Comprendre ses mÃ©canismes permet de travailler avec lui plutÃ´t que contre lui.

---

### 4.1 Le scheduler Go â€” goroutines et GOMAXPROCS

**C'est quoi :** Go utilise un scheduler M:N â€” N goroutines tournent sur M threads OS. Le scheduler Go dÃ©cide quelle goroutine tourne sur quel thread.

```
Goroutines (N)     : 10 000 goroutines crÃ©Ã©es
Threads OS (M)     : GOMAXPROCS threads (= nb de CPU par dÃ©faut)
Processeurs (P)    : file de run queue par thread

G = Goroutine  M = Thread OS  P = Processeur logique

   P1          P2          P3          P4
[ G1 G3 G7 ][ G2 G8 ]  [ G4 G9 ]  [ G5 G6 ]
     â”‚              â”‚          â”‚          â”‚
     M1             M2         M3         M4
     â”‚              â”‚          â”‚          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Work stealing :** si P1 est vide et P2 a 8 goroutines â†’ P1 "vole" la moitiÃ© du travail de P2.

**Ce qu'on apprendrait :** pourquoi `GOMAXPROCS=1` peut Ãªtre plus rapide pour certains workloads, preemption coopÃ©rative vs asynchrone, `runtime.Gosched()`.

**DifficultÃ© :** â­â­â­

---

### 4.2 Le garbage collector Go â€” GC tuning

**C'est quoi :** Go utilise un GC concurrent tri-color mark-and-sweep. Il tourne en parallÃ¨le du programme et cause des "stop-the-world" trÃ¨s courts.

**Le paramÃ¨tre GOGC :**

```bash
# GOGC=100 (dÃ©faut) : GC se dÃ©clenche quand la heap double
# GOGC=200          : GC moins frÃ©quent â†’ moins de CPU GC, plus de mÃ©moire
# GOGC=50           : GC plus frÃ©quent â†’ plus de CPU GC, moins de mÃ©moire
# GOGC=off          : dÃ©sactive le GC (dangereux)

GOGC=200 ./optimizer  # bon pour un service avec beaucoup d'allocations temporaires
```

**GOMEMLIMIT (Go 1.19+) :**

```bash
# Limite la mÃ©moire totale utilisÃ©e â€” le GC devient plus agressif si on approche la limite
GOMEMLIMIT=512MiB ./api
```

**Le memory ballast trick (prÃ©-Go 1.19) :**

```go
// Allouer un gros tableau vide pour tromper le GC et le rendre moins frÃ©quent
// Le GC croit avoir plus de mÃ©moire disponible
ballast := make([]byte, 100*1024*1024)  // 100 MB "fantÃ´me"
runtime.KeepAlive(ballast)
```

**Ce qu'on apprendrait :** tri-color mark-and-sweep, write barriers, GC pause times, GOGC, GOMEMLIMIT, le balance CPU/mÃ©moire.

**DifficultÃ© :** â­â­â­â­

---

### 4.3 Escape analysis â€” allouer sur la stack vs heap

**C'est quoi :** le compilateur Go dÃ©cide si une variable va sur la **stack** (rapide, pas de GC) ou la **heap** (plus lent, GC doit la collecter).

```go
// Stack allocation (pas de GC)
func add(a, b int) int {
    result := a + b  // result reste sur la stack
    return result
}

// Heap allocation (GC doit collecter)
func newSlice() []byte {
    s := make([]byte, 1024)  // s "Ã©chappe" vers la heap si retournÃ©
    return s
}
```

**Voir ce que le compilateur dÃ©cide :**

```bash
go build -gcflags="-m" ./optimizer/...

# Output :
# ./main.go:164:13: image.NewRGBA(img.Bounds()) escapes to heap
# ./main.go:201:14: make([]byte, sampleW*sampleH) does not escape
```

**Ce qu'on apprendrait :** `//go:noescape`, inlining (`//go:noinline`), bounds check elimination, les micro-optimisations valides vs prÃ©maturÃ©es.

**DifficultÃ© :** â­â­â­â­

---

### 4.4 sync primitives avancÃ©es

**`sync.Map`** â€” map thread-safe sans mutex global :
```go
// Meilleur que map + RWMutex quand les clÃ©s sont stables (beaucoup de lectures, peu d'Ã©critures)
var cache sync.Map
cache.Store("key", value)
v, ok := cache.Load("key")
cache.LoadOrStore("key", defaultValue)
```

**`atomic`** â€” opÃ©rations sans mutex pour les compteurs :
```go
import "sync/atomic"

var requestCount int64
atomic.AddInt64(&requestCount, 1)       // incrÃ©mentation atomique
n := atomic.LoadInt64(&requestCount)    // lecture atomique
```

**`errgroup`** â€” goroutines parallÃ¨les avec gestion d'erreur :
```go
import "golang.org/x/sync/errgroup"

// Lancer resize ET charger la font en parallÃ¨le
g, ctx := errgroup.WithContext(context.Background())

var resized image.Image
g.Go(func() error {
    resized = resize(img)
    return nil
})

var metadata map[string]string
g.Go(func() error {
    metadata = extractMetadata(img)
    return nil
})

if err := g.Wait(); err != nil {
    return err  // retourne la premiÃ¨re erreur
}
```

**DifficultÃ© :** â­â­â­

---

### 4.5 Channel patterns avancÃ©s

**Fan-out** (distribuer le travail sur N workers) :
```
Source â”€â”€â–º ch â”€â”€â”¬â”€â”€â–º Worker 1
                â”œâ”€â”€â–º Worker 2
                â””â”€â”€â–º Worker 3
```

**Fan-in** (agrÃ©ger N rÃ©sultats en un) :
```
Worker 1 â”€â”€â”
Worker 2 â”€â”€â”¼â”€â”€â–º merge ch â”€â”€â–º Consumer
Worker 3 â”€â”€â”˜
```

**Pipeline** (chaÃ®ner des Ã©tapes) :
```
decode(images) â”€â”€â–º resize(decoded) â”€â”€â–º watermark(resized) â”€â”€â–º encode(watermarked)
```

**Ce qu'on apprendrait :** `done` channel pattern, `select` avec timeout, channel directionality (`chan<-` vs `<-chan`), les patterns du livre "Concurrency in Go" de Katherine Cox-Buday.

**DifficultÃ© :** â­â­â­

---

<a name="cache"></a>
## 5. Cache avancÃ© â€” aller plus loin que Redis

---

### 5.1 Cache multi-niveaux (L1 + L2)

**Principe :**

```
RequÃªte
  â”‚
  â–¼
L1 : cache en RAM du process (ristretto / groupcache)
  â”‚  ~1Âµs    hit rate: 40%
  â–¼
L2 : Redis
  â”‚  ~1ms    hit rate: 85%
  â–¼
L3 : traitement complet (optimizer)
     ~300ms  hit rate: 0% (cache miss total)
```

**Ristretto** (cache LRU concurrent de DGraph) :

```go
cache, _ := ristretto.NewCache(&ristretto.Config{
    NumCounters: 1e7,      // 10M compteurs de frÃ©quence
    MaxCost:     1 << 30,  // 1 GB max
    BufferItems: 64,
})

// Stocker (cost = taille en bytes)
cache.Set(cacheKey, imageBytes, int64(len(imageBytes)))

// Lire
if val, found := cache.Get(cacheKey); found {
    return val.([]byte), nil
}
```

**Ce qu'on apprendrait :** LRU vs LFU vs ARC eviction, cache coherence, invalidation (le problÃ¨me le plus dur de l'informatique), TinyLFU algorithm de ristretto.

**DifficultÃ© :** â­â­â­

---

### 5.2 Cache stampede â€” le problÃ¨me de l'expiration simultanÃ©e

**C'est quoi :** 1000 requÃªtes arrivent au mÃªme moment, le cache expire â†’ les 1000 font le traitement en mÃªme temps â†’ le service explose.

```
T=0   : 1000 requÃªtes â†’ cache HIT (Redis)
T=24h : le cache expire
T=24h+1ms : 1000 requÃªtes â†’ cache MISS â†’ 1000 fois l'optimizer â†’ ğŸ’¥
```

**Solution : singleflight** â€” si 1000 requÃªtes veulent la mÃªme clÃ©, une seule fait le travail, les 999 autres attendent le rÃ©sultat.

```go
import "golang.org/x/sync/singleflight"

var sf singleflight.Group

result, err, shared := sf.Do(cacheKey, func() (interface{}, error) {
    // Ce code n'est exÃ©cutÃ© qu'UNE SEULE FOIS mÃªme si 1000 goroutines arrivent ici
    return processImage(data, wmText, wmPosition)
})

if shared {
    log.Printf("rÃ©sultat partagÃ© avec d'autres goroutines")
}
```

**Ce qu'on apprendrait :** singleflight, mutex coarse-grained vs fine-grained, probabilistic early expiration.

**DifficultÃ© :** â­â­â­

---

### 5.3 ETags + cache HTTP cÃ´tÃ© client

**C'est quoi :** envoyer un identifiant de version au client. Si l'image n'a pas changÃ©, rÃ©pondre `304 Not Modified` sans retransfÃ©rer les donnÃ©es.

```
RequÃªte 1 :
  Client â†’ GET /image/abc123
  Serveur â†’ 200 + image + ETag: "abc123"

RequÃªte 2 (mÃªme image) :
  Client â†’ GET /image/abc123 + If-None-Match: "abc123"
  Serveur â†’ 304 Not Modified (0 bytes transfÃ©rÃ©s)
```

```go
func handleGetImage(w http.ResponseWriter, r *http.Request) {
    hash := r.PathValue("hash")
    etag := `"` + hash + `"`

    // Si le client a dÃ©jÃ  cette version â†’ 304
    if r.Header.Get("If-None-Match") == etag {
        w.WriteHeader(http.StatusNotModified)
        return
    }

    data, _ := redisClient.Get(r.Context(), hash).Bytes()
    w.Header().Set("ETag", etag)
    w.Header().Set("Cache-Control", "public, max-age=86400")
    sendResponse(w, r, data)
}
```

**Ce qu'on apprendrait :** HTTP caching headers (`ETag`, `Last-Modified`, `Cache-Control`, `Vary`), strong vs weak ETags, conditional requests.

**DifficultÃ© :** â­â­

---

### 5.4 Bloom filter â€” Ã©viter les requÃªtes inutiles

**C'est quoi :** structure de donnÃ©es probabiliste qui rÃ©pond "cet Ã©lÃ©ment n'existe PAS" avec certitude, ou "cet Ã©lÃ©ment EXISTE probablement". ZÃ©ro faux nÃ©gatifs, quelques faux positifs contrÃ´lÃ©s.

**Usage sur le projet :** avant de faire un Redis.Get, vÃ©rifier dans le Bloom filter si l'image a dÃ©jÃ  Ã©tÃ© traitÃ©e. Si le Bloom filter dit "non" â†’ pas la peine d'interroger Redis.

```
Bloom filter â†’ "probablement oui" â†’ Redis.Get â†’ HIT ou MISS
Bloom filter â†’ "dÃ©finitivement non" â†’ aller directement Ã  l'optimizer
```

```
Taille : 1 million d'entrÃ©es â†’ ~1.2 MB de RAM
Faux positifs : ~1%
Gain : Ã©vite ~99% des Redis.Get inutiles
```

**Ce qu'on apprendrait :** hash functions, bit arrays, taux de faux positifs, HyperLogLog (compter des Ã©lÃ©ments uniques approximativement), Count-Min Sketch.

**DifficultÃ© :** â­â­â­â­

---

<a name="http"></a>
## 6. HTTP avancÃ© â€” protocoles modernes

---

### 6.1 HTTP/2 â€” multiplexing et compression de headers

**Le problÃ¨me HTTP/1.1 :**

```
HTTP/1.1 : une requÃªte Ã  la fois par connexion
â†’ le navigateur ouvre 6-8 connexions TCP en parallÃ¨le pour contourner
â†’ overhead de connexion, head-of-line blocking
```

**HTTP/2 :**

```
Une seule connexion TCP
  â”‚
  â”œâ”€â”€ Stream 1 : GET /upload    â”€â”€â–º  traitement parallÃ¨le
  â”œâ”€â”€ Stream 2 : GET /status    â”€â”€â–º  traitement parallÃ¨le
  â””â”€â”€ Stream 3 : GET /image     â”€â”€â–º  traitement parallÃ¨le
```

**HPACK** : compression des headers HTTP/2. Les headers rÃ©pÃ©tÃ©s (User-Agent, Accept-Encoding...) ne sont envoyÃ©s qu'une fois puis indexÃ©s.

```go
// En Go, HTTP/2 est automatique avec TLS
srv := &http.Server{
    Addr:    ":443",
    Handler: mux,
    TLSConfig: &tls.Config{
        MinVersion: tls.VersionTLS13,
    },
}
// http2.ConfigureServer(srv, nil) â€” automatique avec TLS
srv.ListenAndServeTLS("cert.pem", "key.pem")
```

**Ce qu'on apprendrait :** streams, frames, flow control, server push (HTTP/2), HPACK compression, head-of-line blocking.

**DifficultÃ© :** â­â­â­

---

### 6.2 HTTP/3 â€” QUIC remplace TCP

**Le problÃ¨me de TCP :**
- TCP reordering : si un paquet est perdu, tous les streams HTTP/2 bloquent (head-of-line blocking au niveau TCP)
- Handshake lent : 1-3 RTT pour Ã©tablir TLS sur TCP

**QUIC (HTTP/3) :**

```
UDP + QUIC = streams indÃ©pendants
â†’ si un paquet est perdu, seul le stream concernÃ© est retardÃ©
â†’ 0-RTT reconnexion pour les clients connus
```

```
HTTP/1.1 :  TCP(3-way) + TLS(2-way) = 3 RTT avant la premiÃ¨re donnÃ©e
HTTP/2   :  TCP(3-way) + TLS(2-way) = 3 RTT (mÃªme connexion ensuite)
HTTP/3   :  QUIC = 1 RTT (ou 0-RTT pour clients connus)
```

**Ce qu'on apprendrait :** UDP vs TCP, QUIC protocol, 0-RTT, `quic-go` library.

**DifficultÃ© :** â­â­â­â­â­

---

### 6.3 gRPC â€” performance vs REST

**C'est quoi :** protocole RPC (Remote Procedure Call) dÃ©veloppÃ© par Google. Utilise Protocol Buffers (binaire) au lieu de JSON (texte) et HTTP/2 au lieu de HTTP/1.1.

**Comparaison avec notre API REST :**

| | REST + JSON (actuel) | gRPC + Protobuf |
|---|---|---|
| Format | JSON (texte) | Protobuf (binaire) |
| Taille payload | 100% | ~30-50% |
| Parse CPU | Moyen | Minimal |
| Streaming | LimitÃ© | Natif (bidirectionnel) |
| Code generation | Non | Oui (`.proto` â†’ Go) |
| Browser support | Natif | NÃ©cessite grpc-web |

**Pour la communication API â†’ Optimizer :** gRPC serait plus efficace que multipart HTTP.

```protobuf
// optimize.proto
service Optimizer {
    rpc Optimize(OptimizeRequest) returns (OptimizeResponse);
}

message OptimizeRequest {
    bytes  image_data  = 1;
    string wm_text     = 2;
    string wm_position = 3;
    string filename    = 4;
}

message OptimizeResponse {
    bytes result = 1;
}
```

**Ce qu'on apprendrait :** Protocol Buffers, IDL (Interface Definition Language), code generation, streaming RPC, interceptors (Ã©quivalent des middlewares HTTP).

**DifficultÃ© :** â­â­â­â­

---

### 6.4 Server-Sent Events â€” remplacer le polling

**Le problÃ¨me actuel :** quand l'optimizer est KO, le front poll `/status/{hash}` toutes les 500ms. C'est du gaspillage â€” on fait des requÃªtes HTTP mÃªme quand rien n'a changÃ©.

**Server-Sent Events (SSE) :** le serveur pousse les mises Ã  jour au client dÃ¨s qu'elles arrivent.

```go
func handleStatusSSE(w http.ResponseWriter, r *http.Request) {
    hash := r.PathValue("hash")

    w.Header().Set("Content-Type", "text/event-stream")
    w.Header().Set("Cache-Control", "no-cache")

    flusher := w.(http.Flusher)

    for {
        select {
        case <-r.Context().Done():
            return  // client dÃ©connectÃ©
        case <-time.After(500 * time.Millisecond):
            exists, _ := redisClient.Exists(r.Context(), hash).Result()
            if exists == 1 {
                fmt.Fprintf(w, "data: {\"status\":\"done\",\"url\":\"/image/%s\"}\n\n", hash)
                flusher.Flush()
                return
            }
            fmt.Fprintf(w, "data: {\"status\":\"pending\"}\n\n")
            flusher.Flush()
        }
    }
}
```

**Ce qu'on apprendrait :** SSE vs WebSockets vs polling, `http.Flusher`, long-polling, push vs pull.

**DifficultÃ© :** â­â­

---

<a name="image"></a>
## 7. Optimisation image â€” formats et parallÃ©lisme

---

### 7.1 WebP et AVIF â€” les formats modernes

**Comparaison pour une photo de 500 KB en JPEG qualitÃ© 85 :**

| Format | Taille | QualitÃ© visuelle | Support navigateur |
|---|---|---|---|
| JPEG | 500 KB | RÃ©fÃ©rence | 100% |
| WebP | ~350 KB (-30%) | Ã‰quivalente | 97% |
| AVIF | ~250 KB (-50%) | LÃ©gÃ¨rement meilleure | 90% |
| JPEG XL | ~200 KB (-60%) | Meilleure | 75% |

**NÃ©gociation via Accept :**

```go
// Le navigateur annonce ce qu'il accepte
// Accept: image/avif,image/webp,image/jpeg,*/*

func bestFormat(r *http.Request) string {
    accept := r.Header.Get("Accept")
    if strings.Contains(accept, "image/avif") { return "avif" }
    if strings.Contains(accept, "image/webp") { return "webp" }
    return "jpeg"
}
```

**Ce qu'on apprendrait :** codecs d'image modernes, DCT vs AV1 (AVIF), librairies Go `golang.org/x/image/webp`, `gen2brain/avif`.

**DifficultÃ© :** â­â­â­

---

### 7.2 Traitement parallÃ¨le des pixels

**Le bottleneck actuel de `sampleLuminance` :**

```go
// âŒ SÃ©quentiel â€” 200Ã—50 = 10 000 pixels, un par un
for py := startY; py < endY; py++ {
    for px := startX; px < endX; px++ {
        r, g, b, _ := img.At(px, py).RGBA()
        total += 0.299*float64(r>>8) + ...
    }
}
```

**ParallÃ©lisation par lignes :**

```go
// âœ… ParallÃ¨le â€” chaque ligne traitÃ©e par une goroutine
var mu sync.Mutex
var total float64

var wg sync.WaitGroup
for py := startY; py < endY; py++ {
    wg.Add(1)
    go func(row int) {
        defer wg.Done()
        var rowTotal float64
        for px := startX; px < endX; px++ {
            r, g, b, _ := img.At(px, row).RGBA()
            rowTotal += 0.299*float64(r>>8) + 0.587*float64(g>>8) + 0.114*float64(b>>8)
        }
        mu.Lock()
        total += rowTotal
        mu.Unlock()
    }(py)
}
wg.Wait()
```

**Ce qu'on apprendrait :** quand la parallÃ©lisation aide vs quand elle nuit (overhead goroutines vs gain calcul), false sharing, SIMD/AVX.

**DifficultÃ© :** â­â­â­

---

### 7.3 Progressive JPEG et lazy decoding

**Progressive JPEG :** l'image s'affiche d'abord floue puis de plus en plus nette (comme sur les sites web lents).

```go
// Le package standard image/jpeg ne supporte pas le progressive JPEG en Ã©criture
// Il faut libjpeg-turbo via cgo ou une librairie externe
```

**Lazy decoding :** ne dÃ©coder que le header de l'image (dimensions, format) sans dÃ©coder les pixels â€” utile pour valider une image sans la charger entiÃ¨rement.

```go
// Lire uniquement la config (largeur, hauteur, format) sans dÃ©coder les pixels
config, format, err := image.DecodeConfig(file)
fmt.Printf("%s : %dx%d\n", format, config.Width, config.Height)
```

**Ce qu'on apprendrait :** structure interne des formats JPEG/PNG/WebP, libjpeg-turbo, cgo (appeler du C depuis Go).

**DifficultÃ© :** â­â­â­â­

---

<a name="distribue"></a>
## 8. Architecture distribuÃ©e â€” scaler horizontalement

---

### 8.1 Scaling horizontal de l'optimizer

**Actuel :** 1 instance de l'optimizer, semaphore limitÃ© Ã  nb_CPU.

**ScalÃ© :** 3 instances derriÃ¨re un load balancer.

```yaml
# docker-compose.yml
optimizer:
  build: ./optimizer
  deploy:
    replicas: 3          # 3 instances

nginx:
  image: nginx:alpine
  config: |
    upstream optimizer {
        least_conn;              # envoyer au moins chargÃ©
        server optimizer:3001;   # Docker rÃ©sout en round-robin
    }
```

**Ce qu'on apprendrait :** round-robin vs least-connections vs IP hash, health checks du load balancer, sticky sessions (et pourquoi les Ã©viter), service discovery.

**DifficultÃ© :** â­â­â­

---

### 8.2 Dead Letter Queue (DLQ)

**Actuel :** si un job RabbitMQ Ã©choue indÃ©finiment â†’ NACK â†’ requeue â†’ boucle infinie.

**Avec DLQ :** aprÃ¨s 3 NACKs â†’ le message va dans `watermark_failed` au lieu de boucler.

```go
// DÃ©clarer la queue principale avec DLQ attachÃ©e
args := amqp.Table{
    "x-dead-letter-exchange":    "",                  // exchange par dÃ©faut
    "x-dead-letter-routing-key": "watermark_failed",  // queue DLQ
    "x-message-ttl":             int64(24 * 60 * 60 * 1000), // 24h max
}
ch.QueueDeclare("watermark_retry", true, false, false, false, args)

// DÃ©clarer la DLQ (passive, juste pour stocker)
ch.QueueDeclare("watermark_failed", true, false, false, false, nil)
```

**Ce qu'on apprendrait :** DLQ patterns, message replay, poison pills, observabilitÃ© des queues (RabbitMQ Management UI).

**DifficultÃ© :** â­â­â­

---

### 8.3 Consistent hashing â€” Redis Cluster

**Le problÃ¨me du sharding naÃ¯f :**

```
hash % 3 noeuds = noeud cible

Si on passe de 3 Ã  4 noeuds â†’ hash % 4 â†’ TOUS les mappings changent
â†’ 100% de cache miss pendant des heures
```

**Consistent hashing :**

```
Anneau de 0 Ã  2^32
Chaque noeud occupe plusieurs positions sur l'anneau
Chaque clÃ© â†’ position sur l'anneau â†’ noeud le plus proche

Ajouter un noeud â†’ seules les clÃ©s entre lui et son voisin migrent (~1/N keys)
```

**Ce qu'on apprendrait :** Redis Cluster (16384 hash slots), consistent hashing, virtual nodes, rendezvous hashing.

**DifficultÃ© :** â­â­â­â­

---

### 8.4 Event Sourcing + CQRS

**CQRS (Command Query Responsibility Segregation) :**
- SÃ©parer les opÃ©rations d'Ã©criture (Commands) des lectures (Queries)
- Sur le projet : la command = upload+watermark, la query = rÃ©cupÃ©rer le rÃ©sultat

**Event Sourcing :**
- Au lieu de stocker l'Ã©tat final â†’ stocker tous les Ã©vÃ©nements qui l'ont produit
- `ImageUploaded{hash, filename}` â†’ `WatermarkApplied{hash, text, position}` â†’ `ImageServed{hash}`
- On peut rejouer l'historique, auditer, faire du time-travel debugging

**Ce qu'on apprendrait :** immutabilitÃ© des Ã©vÃ©nements, projections, sagas, Kafka pour la persistance des Ã©vÃ©nements.

**DifficultÃ© :** â­â­â­â­â­

---

<a name="linux"></a>
## 9. Linux & OS â€” le niveau zÃ©ro

> **Principe :** Go compile vers du code natif qui appelle directement le kernel Linux.
> Comprendre les syscalls et les primitives OS explique pourquoi certaines optimisations fonctionnent.

---

### 9.1 io_uring â€” I/O asynchrone Linux

**C'est quoi :** interface kernel Linux (depuis 5.1) pour faire des I/O asynchrones sans syscalls par opÃ©ration. Au lieu de `read()` + `write()` bloquants, on soumet un batch d'opÃ©rations dans un ring buffer partagÃ©.

```
Avant (epoll) :           AprÃ¨s (io_uring) :
  read() â†’ syscall          submit batch â†’ 1 syscall pour N opÃ©rations
  poll()  â†’ syscall         poll()        â†’ peut Ãªtre remplacÃ© par busy-wait
  write() â†’ syscall         â†’ 0 copie mÃ©moire user/kernel
```

**Ce qu'on apprendrait :** ring buffers, zero-copy I/O, uring_enter syscall, diffÃ©rence epoll/kqueue/IOCP, pourquoi Node.js et nginx sont rapides.

**DifficultÃ© :** â­â­â­â­â­

---

### 9.2 Zero-copy â€” sendfile et splice

**Le problÃ¨me de la copie classique :**

```
Disque â†’ kernel buffer â†’ user buffer â†’ kernel buffer rÃ©seau â†’ NIC
            (copie 1)    (copie 2)       (copie 3)
```

**`sendfile` syscall (zero-copy) :**

```
Disque â†’ kernel buffer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NIC
                                    (0 copie user space)
```

**En Go :**

```go
// Go utilise sendfile automatiquement quand on fait :
src, _ := os.Open("image.jpg")
dst, _ := os.Create("output.jpg")
io.Copy(dst, src)  // â†’ utilise sendfile sous le capot sur Linux
```

Mais dÃ¨s qu'on passe par un `http.ResponseWriter`, on repasse en copie normale. Des librairies comme `fasthttp` Ã©vitent Ã§a.

**Ce qu'on apprendrait :** sendfile(2), splice(2), mmap, DMA, le chemin d'une donnÃ©e du disque au rÃ©seau.

**DifficultÃ© :** â­â­â­â­â­

---

### 9.3 epoll â€” le cÅ“ur des serveurs haute performance

**C'est quoi :** mÃ©canisme Linux pour surveiller des milliers de file descriptors (connexions rÃ©seau) avec un seul appel bloquant.

```
Sans epoll (select/poll) :
  for each connection : is_ready() â†’ O(n) par itÃ©ration â†’ inutilisable Ã  10k connexions

Avec epoll :
  kernel notifie "ces X connexions sont prÃªtes" â†’ O(1) par notification
  â†’ c'est ce qui permet Ã  nginx de gÃ©rer 1M connexions simultanÃ©es
```

Go utilise epoll en interne pour son scheduler rÃ©seau. Comprendre epoll explique pourquoi les goroutines Go sont si lÃ©gÃ¨res comparÃ©es aux threads.

**Ce qu'on apprendrait :** le C10K problem, edge-triggered vs level-triggered, kqueue (macOS), IOCP (Windows), netpoller de Go.

**DifficultÃ© :** â­â­â­â­â­

---

<a name="load-testing"></a>
## 10. Load testing â€” mesurer avant d'optimiser

> **Principe :** sans load test, toutes les optimisations sont des suppositions.

---

### 10.1 k6 â€” load testing moderne

**C'est quoi :** outil de load testing scriptable en JavaScript, dÃ©veloppÃ© par Grafana Labs.

```javascript
// load-test.js
import http from 'k6/http';

export let options = {
    stages: [
        { duration: '30s', target: 10  },   // montÃ©e Ã  10 users
        { duration: '1m',  target: 50  },   // 50 users pendant 1 min
        { duration: '30s', target: 100 },   // pic Ã  100 users
        { duration: '30s', target: 0   },   // descente
    ],
    thresholds: {
        http_req_duration: ['p95<500'],  // 95% des requÃªtes < 500ms
        http_req_failed:   ['rate<0.01'], // < 1% d'erreurs
    },
};

export default function() {
    const formData = {
        image: http.file(open('./test.jpg', 'b'), 'test.jpg', 'image/jpeg'),
        wm_text: 'NWS Â© 2026',
        wm_position: 'bottom-right',
    };
    const res = http.post('http://localhost:3000/upload', formData);
    check(res, { 'status 200': (r) => r.status === 200 });
}
```

```bash
k6 run --out prometheus=remote_write_url load-test.js
```

**Ce qu'on apprendrait :** Virtual Users (VU), ramp-up, throughput vs latency tradeoff, percentiles (p95/p99), corrÃ©lation load test + pprof.

**DifficultÃ© :** â­â­

---

### 10.2 wrk et vegeta â€” tests simples et rapides

```bash
# wrk â€” 12 threads, 400 connexions, pendant 30s
wrk -t12 -c400 -d30s http://localhost:3000/image/abc123

# vegeta â€” 100 req/sec pendant 60s
echo "GET http://localhost:3000/image/abc123" | \
  vegeta attack -rate=100 -duration=60s | \
  vegeta report
```

**Ce qu'on apprendrait :** diffÃ©rence wrk (throughput max) vs vegeta (dÃ©bit constant), latency distribution, coordinated omission problem (pourquoi les benchmarks mentent souvent).

**DifficultÃ© :** â­

---

### 10.3 Coordinated Omission â€” pourquoi les benchmarks mentent

**C'est quoi :** le problÃ¨me le plus souvent ignorÃ© dans les benchmarks de performance.

```
Service prend 10ms normalement, mais 10s sous charge

Benchmark naÃ¯f :
  Envoie une requÃªte â†’ attend la rÃ©ponse â†’ envoie la suivante
  â†’ "10ms de latence moyenne !"

RÃ©alitÃ© : si 100 requÃªtes arrivent en 1 seconde mais le service prend 10s
  â†’ 990 requÃªtes attendent â†’ latence rÃ©elle = plusieurs secondes

Le benchmark naÃ¯f ne mesure pas l'attente, seulement le traitement.
```

**La solution :** HdrHistogram + scheduled requests (vegeta, wrk2, JMeter).

**Ce qu'on apprendrait :** Gil Tene's talk "How NOT to measure latency", HdrHistogram, latency vs response time.

**DifficultÃ© :** â­â­â­ (conceptuel, pas de code)

---

<a name="chaos"></a>
## 11. Chaos Engineering â€” tester les pannes volontairement

> **Principe :** Netflix a inventÃ© Chaos Monkey : un outil qui tue des serveurs alÃ©atoirement en prod.
> Si ton systÃ¨me tient face aux pannes, c'est qu'il est vraiment rÃ©silient.

---

### 11.1 Pumba â€” chaos pour Docker

**C'est quoi :** outil qui injecte des pannes dans des conteneurs Docker (latence, perte de paquets, crash).

```bash
# Ajouter 200ms de latence sur les paquets sortants de l'optimizer
pumba netem --duration 5m delay --time 200 watermark-optimizer-1

# Tuer le conteneur optimizer toutes les 30 secondes
pumba --random --interval 30s kill watermark-optimizer-1

# Perdre 10% des paquets rÃ©seau
pumba netem --duration 2m loss --percent 10 watermark-api-1
```

**Ce qu'on dÃ©couvrirait :**
- Est-ce que le fallback RabbitMQ se dÃ©clenche vraiment ?
- Est-ce que le circuit breaker s'ouvre ?
- Est-ce que les logs montrent clairement ce qui se passe ?

**Ce qu'on apprendrait :** Game Days, blast radius, steady state hypothesis, les principes de Chaos Engineering (Principles of Chaos).

**DifficultÃ© :** â­â­â­

---

### 11.2 Toxiproxy â€” simuler des rÃ©seaux dÃ©gradÃ©s

**C'est quoi :** proxy TCP qui permet de simuler des conditions rÃ©seau dÃ©gradÃ©es entre services.

```go
// CrÃ©er un proxy Redis avec latence alÃ©atoire
client := toxiproxy.NewClient("localhost:8474")
proxy, _ := client.CreateProxy("redis", "localhost:16379", "localhost:6379")

// Ajouter 100ms de latence
proxy.AddToxic("latency", "latency", "downstream", 1.0, toxiproxy.Attributes{
    "latency": 100,
    "jitter":  50,
})

// Simuler une connexion intermittente (down 10% du temps)
proxy.AddToxic("intermittent", "timeout", "downstream", 0.1, toxiproxy.Attributes{
    "timeout": 0,
})
```

**Ce qu'on apprendrait :** tester les timeouts, valider les circuit breakers, reproduction de bugs rÃ©seau difficiles Ã  reproduire.

**DifficultÃ© :** â­â­â­

---

<a name="securite"></a>
## 12. SÃ©curitÃ© â€” ce qui manque en prod

---

### 12.1 TLS / HTTPS avec autocert

```go
import "golang.org/x/crypto/acme/autocert"

// Let's Encrypt automatique
m := &autocert.Manager{
    Cache:      autocert.DirCache("certs"),
    Prompt:     autocert.AcceptTOS,
    HostPolicy: autocert.HostWhitelist("watermark.example.com"),
}

srv := &http.Server{
    Addr:      ":443",
    TLSConfig: m.TLSConfig(),
    Handler:   mux,
}
srv.ListenAndServeTLS("", "")  // autocert gÃ¨re les certificats
```

**Ce qu'on apprendrait :** TLS 1.3, ACME protocol, certificate pinning, HSTS, mTLS (mutual TLS pour la communication inter-services).

**DifficultÃ© :** â­â­â­

---

### 12.2 Validation et sÃ©curitÃ© des uploads

**Ce qui manque actuellement :**

```go
// âŒ Pas de validation du type MIME rÃ©el
file, header, _ := r.FormFile("image")
// On fait confiance au Content-Type envoyÃ© par le client

// âœ… Lire les magic bytes pour dÃ©tecter le vrai format
buf := make([]byte, 512)
file.Read(buf)
file.Seek(0, io.SeekStart)

contentType := http.DetectContentType(buf)
if contentType != "image/jpeg" && contentType != "image/png" {
    http.Error(w, "Format non supportÃ©", http.StatusBadRequest)
    return
}

// âœ… Limiter la taille
r.Body = http.MaxBytesReader(w, r.Body, 20*1024*1024)  // 20 MB max
```

**Ce qu'on apprendrait :** magic bytes, MIME sniffing, zip bombs (images malformÃ©es qui explosent en dÃ©compression), path traversal.

**DifficultÃ© :** â­â­

---

### 12.3 JWT + authentification

```go
import "github.com/golang-jwt/jwt/v5"

func authMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        token := r.Header.Get("Authorization")
        // Bearer <token>
        claims, err := jwt.Parse(token[7:], func(t *jwt.Token) (interface{}, error) {
            return publicKey, nil  // RS256 : vÃ©rification avec clÃ© publique
        })
        if err != nil {
            http.Error(w, "Unauthorized", http.StatusUnauthorized)
            return
        }
        ctx := context.WithValue(r.Context(), "user", claims.Subject)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}
```

**Ce qu'on apprendrait :** RS256 vs HS256, refresh tokens, token revocation, JWKS endpoints.

**DifficultÃ© :** â­â­â­

---

<a name="ordre"></a>
## 13. Ordre d'apprentissage suggÃ©rÃ©

```
PHASE 1 â€” Mesurer (sans mesure, on optimise Ã  l'aveugle)
â”œâ”€â”€ pprof                â†’ comprendre oÃ¹ va le CPU et la mÃ©moire
â”œâ”€â”€ k6 load test         â†’ Ã©tablir une baseline de performance
â””â”€â”€ structured logging   â†’ rendre les logs exploitables

PHASE 2 â€” RÃ©silience (rendre le systÃ¨me robuste)
â”œâ”€â”€ context + timeout    â†’ annuler le travail inutile
â”œâ”€â”€ graceful shutdown    â†’ zÃ©ro coupure au dÃ©ploiement
â”œâ”€â”€ rate limiting        â†’ se protÃ©ger des abus
â””â”€â”€ circuit breaker      â†’ fail-fast sur l'optimizer

PHASE 3 â€” ObservabilitÃ© (voir en production)
â”œâ”€â”€ Prometheus + Grafana â†’ dashboards de mÃ©triques
â”œâ”€â”€ health checks        â†’ intÃ©gration Docker/Kubernetes
â””â”€â”€ OpenTelemetry        â†’ tracing distribuÃ© end-to-end

PHASE 4 â€” Performance (optimiser avec des donnÃ©es)
â”œâ”€â”€ Cache L1 (ristretto) â†’ rÃ©duire les appels Redis
â”œâ”€â”€ singleflight         â†’ Ã©liminer le cache stampede
â”œâ”€â”€ ETags                â†’ Ã©viter de retransfÃ©rer les images
â””â”€â”€ GC tuning (GOGC)     â†’ rÃ©duire la pression mÃ©moire

PHASE 5 â€” Scaling (passer Ã  l'Ã©chelle)
â”œâ”€â”€ HTTP/2               â†’ multiplexing connexions
â”œâ”€â”€ WebP/AVIF            â†’ images plus lÃ©gÃ¨res
â”œâ”€â”€ scaling horizontal   â†’ plusieurs instances optimizer
â””â”€â”€ DLQ RabbitMQ         â†’ ne plus perdre de jobs

PHASE 6 â€” Chaos et sÃ©curitÃ©
â”œâ”€â”€ TLS + autocert       â†’ HTTPS en prod
â”œâ”€â”€ validation uploads   â†’ sÃ©curitÃ© des entrÃ©es
â”œâ”€â”€ Pumba / Toxiproxy    â†’ tester les pannes
â””â”€â”€ JWT                  â†’ authentification

PHASE 7 â€” Internals (comprendre en profondeur)
â”œâ”€â”€ GC mark-and-sweep    â†’ tuning mÃ©moire avancÃ©
â”œâ”€â”€ escape analysis      â†’ optimiser les allocations
â”œâ”€â”€ epoll / io_uring     â†’ I/O asynchrone niveau OS
â””â”€â”€ gRPC + Protobuf      â†’ remplacer HTTP/JSON inter-services
```

---

## RÃ©capitulatif par difficultÃ©

| DifficultÃ© | Sujet | Temps estimÃ© |
|---|---|---|
| â­ | wrk / vegeta | 1h |
| â­â­ | pprof, rate limiting, graceful shutdown, ETags, SSE, structured logging | 1-2 jours |
| â­â­â­ | Prometheus, circuit breaker, context, cache L1, scaling horizontal, k6, DLQ, WebP | 1 semaine |
| â­â­â­â­ | OpenTelemetry, GC tuning, escape analysis, consistent hashing, bloom filter, AVIF | 2-3 semaines |
| â­â­â­â­â­ | gRPC, HTTP/3, event sourcing, io_uring, epoll, zero-copy | 1-2 mois |
