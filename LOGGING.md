# Cours : Structured Logging
## Des logs exploitables en production

---

## üìã Table des mati√®res

1. [Le probl√®me des logs texte](#probleme)
2. [C'est quoi le structured logging ?](#intro)
3. [Les niveaux de log](#niveaux)
4. [zerolog ‚Äî le plus rapide en Go](#zerolog)
5. [zap ‚Äî l'alternative de Uber](#zap)
6. [Les champs √† toujours inclure](#champs)
7. [Log sampling ‚Äî ne pas tout logger](#sampling)
8. [Corr√©lation avec les traces (trace ID)](#correlation)
9. [Les backends ‚Äî o√π envoyer les logs](#backends)
10. [Utilisation dans NWS Watermark](#watermark)
11. [Les anti-patterns √† √©viter](#antipatterns)
12. [R√©sum√©](#r√©sum√©)

---

<a name="probleme"></a>
## 1. Le probl√®me des logs texte

### Ce qu'on a actuellement

```
[API] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
[API] ‚Üí Nouvelle requ√™te re√ßue
[API] ‚ë† Lecture    : photo.jpg | 2.3 MB | 1.2ms
[API] ‚ë° SHA256     : a3f8c2d1e4b5... | calcul√© en 0.8ms
[API] ‚ë¢ Redis      : ‚ùå CACHE MISS | lookup en 1.1ms
[API] ‚ë£ MinIO.Put  : ‚úì Original sauvegard√© | 2.3 MB | en 45ms
[API] ‚ë§ Optimizer  : ‚úì 245.3 KB re√ßus en 312ms
[API] ‚ë• Redis.Set  : ‚úì 245.3 KB stock√©s | TTL 24h | en 0.9ms
[API] ‚ë¶ R√©ponse    : gzip=true | taille=245.3 KB
[API] ‚è± Total      : 361ms
```

Ce log est **lisible par un humain** mais **inutilisable par une machine**.

**Probl√®mes concrets en production :**

```bash
# Trouver toutes les requ√™tes > 500ms ‚Üí impossible
grep "Total" api.log | ???

# Compter les CACHE MISS par heure ‚Üí impossible
grep "CACHE MISS" api.log | ???

# Corr√©ler une erreur avec un utilisateur sp√©cifique ‚Üí impossible
grep "erreur" api.log  # aucune info sur qui a fait la requ√™te

# Alerter si le taux d'erreur d√©passe 1% ‚Üí impossible sans parser du texte
```

**Le vrai probl√®me :** les logs texte n√©cessitent du parsing fragile (regex) pour en extraire des donn√©es. Si le format du message change d'un caract√®re ‚Üí le parsing casse.

---

### Ce qu'on veut

```json
{"level":"info","time":"2026-02-24T10:23:41Z","service":"api","request_id":"abc123","step":"optimizer","filename":"photo.jpg","bytes_in":2411520,"bytes_out":251187,"duration_ms":312,"cache":"miss"}
```

Une ligne = un objet JSON. N'importe quelle ligne est **requ√™table** directement.

```bash
# Toutes les requ√™tes > 500ms
cat api.log | jq 'select(.duration_ms > 500)'

# Taux de cache miss par heure
cat api.log | jq -s 'group_by(.time[:13]) | map({hour: .[0].time[:13], miss_rate: (map(select(.cache=="miss")) | length) / length})'

# Corr√©ler avec un request_id
cat api.log | jq 'select(.request_id == "abc123")'
```

---

<a name="intro"></a>
## 2. C'est quoi le structured logging ?

**Structured logging** = logger des **paires cl√©-valeur typ√©es** plut√¥t que des cha√Ænes de texte.

```
Non structur√© :  "Optimizer a re√ßu 245 KB en 312ms pour photo.jpg"
Structur√© :      {step:"optimizer", bytes:245187, duration_ms:312, filename:"photo.jpg"}
```

**Analogie :** c'est la diff√©rence entre √©crire une note "Marie a appel√© √† 14h pour annuler le RDV de jeudi" vs remplir un formulaire avec les champs `contact`, `heure`, `action`, `date_rdv`. Le formulaire est cherchable, filtrable, agr√©geable.

### Les 3 propri√©t√©s d'un bon log

1. **Structured** ‚Äî JSON ou autre format machine-readable
2. **Leveled** ‚Äî DEBUG, INFO, WARN, ERROR, FATAL
3. **Contextual** ‚Äî chaque log porte le contexte (request_id, user_id, service...)

---

<a name="niveaux"></a>
## 3. Les niveaux de log

| Niveau | Usage | En prod ? |
|---|---|---|
| `TRACE` | D√©tails tr√®s fins (chaque pixel trait√©) | Jamais |
| `DEBUG` | Informations de d√©veloppement | Non (trop verbeux) |
| `INFO` | √âv√©nements normaux (requ√™te re√ßue, cache hit) | Oui |
| `WARN` | Situation anormale mais r√©cup√©rable (retry, d√©gradation) | Oui |
| `ERROR` | Erreur qui n√©cessite attention (√©chec optimizer, erreur Redis) | Oui |
| `FATAL` | Erreur non r√©cup√©rable ‚Üí le processus s'arr√™te | Oui |

### La r√®gle du niveau en production

```
Dev :    DEBUG ‚Üí tout voir
Staging: INFO  ‚Üí comportement normal + anomalies
Prod :   INFO  ‚Üí comportement normal + anomalies
         WARN  ‚Üí anomalies r√©cup√©rables
         ERROR ‚Üí incidents

# Jamais DEBUG en prod ‚Üí trop de volume ‚Üí co√ªts de stockage, signal noy√© dans le bruit
```

### Changer le niveau dynamiquement

Les bons loggers permettent de changer le niveau sans red√©marrer :

```go
// zerolog : changer le niveau global √† la vol√©e
zerolog.SetGlobalLevel(zerolog.DebugLevel)  // activer debug temporairement
zerolog.SetGlobalLevel(zerolog.InfoLevel)   // revenir √† la normale
```

---

<a name="zerolog"></a>
## 4. zerolog ‚Äî le plus rapide en Go

**zerolog** (d√©velopp√© par Olivier Poitrey de Netflix) est le logger Go le plus rapide ‚Äî il alloue z√©ro byte pour les logs d√©sactiv√©s gr√¢ce aux interfaces `io.Writer` et √† l'encodage direct en JSON.

```bash
go get github.com/rs/zerolog
```

### Setup de base

```go
import (
    "os"
    "github.com/rs/zerolog"
    "github.com/rs/zerolog/log"
)

func main() {
    // JSON en production
    zerolog.TimeFieldFormat = zerolog.TimeFormatUnix  // timestamp Unix (plus compact)
    log.Logger = zerolog.New(os.Stdout).With().
        Timestamp().
        Str("service", "api").
        Logger()

    // Pretty print en d√©veloppement
    if os.Getenv("ENV") == "dev" {
        log.Logger = log.Output(zerolog.ConsoleWriter{Out: os.Stderr})
    }
}
```

### Logger des √©v√©nements

```go
// INFO
log.Info().
    Str("step", "optimizer").
    Str("filename", "photo.jpg").
    Int("bytes_in", 2411520).
    Int("bytes_out", 251187).
    Dur("duration", optimizerDur).
    Msg("optimizer response received")

// Output :
// {"level":"info","service":"api","step":"optimizer","filename":"photo.jpg",
//  "bytes_in":2411520,"bytes_out":251187,"duration_ms":312,"time":1708772621,
//  "message":"optimizer response received"}
```

```go
// ERROR avec erreur Go
log.Error().
    Err(err).                         // ajoute le champ "error" avec err.Error()
    Str("step", "redis").
    Str("key", cacheKey[:16]).
    Msg("redis get failed")

// WARN
log.Warn().
    Str("step", "minio").
    Int("attempt", 2).
    Msg("minio put slow, retrying")
```

### Logger avec contexte (sous-logger)

```go
// Cr√©er un sous-logger avec des champs fix√©s pour toute la dur√©e du handler
func handleUpload(w http.ResponseWriter, r *http.Request) {
    requestID := generateRequestID()

    // Tous les logs de ce handler auront request_id et method automatiquement
    logger := log.With().
        Str("request_id", requestID).
        Str("method", r.Method).
        Str("path", r.URL.Path).
        Logger()

    logger.Info().Msg("request received")

    // Plus loin dans le handler...
    logger.Info().
        Str("step", "redis").
        Bool("hit", true).
        Dur("duration", redisDur).
        Msg("cache lookup")
}
```

### Logger dans un context.Context

```go
// Attacher le logger au contexte pour le propager sans le passer en param√®tre
ctx := logger.WithContext(r.Context())

// R√©cup√©rer depuis le contexte
log.Ctx(ctx).Info().Str("step", "minio").Msg("saving original")
```

### Performance zerolog

```
BenchmarkInfo/zerolog  :   89 ns/op   0 B/op   0 allocs/op  ‚Üê z√©ro allocation
BenchmarkInfo/zap      :  131 ns/op   0 B/op   0 allocs/op
BenchmarkInfo/logrus   : 1256 ns/op 1297 B/op  24 allocs/op  ‚Üê 14x plus lent
BenchmarkInfo/slog     :  250 ns/op  48 B/op    2 allocs/op
```

zerolog est 14x plus rapide que logrus et ~3x plus rapide que slog (standard library Go 1.21).

---

<a name="zap"></a>
## 5. zap ‚Äî l'alternative de Uber

**zap** (d√©velopp√© par Uber) est l'autre grand logger Go. L√©g√®rement moins rapide que zerolog mais API plus riche.

```go
import "go.uber.org/zap"

// Logger de production (JSON)
logger, _ := zap.NewProduction()
defer logger.Sync()

// Logger de d√©veloppement (couleurs, lisible)
logger, _ = zap.NewDevelopment()

logger.Info("optimizer response",
    zap.String("step", "optimizer"),
    zap.Int("bytes", 251187),
    zap.Duration("duration", optimizerDur),
)

// SugaredLogger ‚Äî API moins stricte mais l√©g√®rement plus lente
sugar := logger.Sugar()
sugar.Infow("optimizer response",
    "step", "optimizer",
    "bytes", 251187,
)
```

### zerolog vs zap vs slog

| | zerolog | zap | slog (stdlib) |
|---|---|---|---|
| Performances | ‚ö° Meilleur | ‚ö° Tr√®s bon | Bon |
| API | Fluent (cha√Æn√©) | Typ√©e stricte | Standard |
| Int√©gration stdlib | Non | Non | Oui (Go 1.21+) |
| Maintenance | Actif | Actif | Core team Go |
| Recommandation | Nouveaux projets perf-critiques | Projets Uber/enterprise | Projets qui veulent la stdlib |

**Conseil :** utiliser `zerolog` pour les microservices Go haute perf, `slog` si on veut z√©ro d√©pendance externe.

---

<a name="champs"></a>
## 6. Les champs √† toujours inclure

### Champs obligatoires sur chaque log

```go
{
    "level":      "info",                    // niveau
    "time":       "2026-02-24T10:23:41Z",    // timestamp ISO 8601
    "service":    "api",                     // quel microservice
    "request_id": "f47ac10b-58cc-4372",      // identifiant unique de la requ√™te
    "message":    "cache lookup"             // description humaine
}
```

### Champs contextuels selon l'√©tape

```go
// Requ√™te HTTP entrante
{
    "method":     "POST",
    "path":       "/upload",
    "remote_ip":  "192.168.1.42",
    "user_agent": "Mozilla/5.0..."
}

// Op√©ration Redis
{
    "step":       "redis",
    "key":        "a3f8c2d1...",   // les 16 premiers chars suffisent
    "hit":        false,
    "duration_ms": 1.1
}

// Appel optimizer
{
    "step":       "optimizer",
    "filename":   "photo.jpg",
    "bytes_in":   2411520,
    "bytes_out":  251187,
    "duration_ms": 312,
    "wm_position": "bottom-right"
}

// Erreur
{
    "level":     "error",
    "step":      "minio",
    "error":     "connection refused",
    "attempt":   2,
    "will_retry": true
}
```

### Conventions de nommage

```
snake_case pour les cl√©s :  bytes_out  ‚úÖ   bytesOut  ‚ùå
Unit√©s dans le nom       :  duration_ms ‚úÖ  duration  ‚ùå (quelle unit√© ?)
Bool√©ens explicites      :  cache_hit  ‚úÖ   hit       ‚ùå (hit quoi ?)
```

---

<a name="sampling"></a>
## 7. Log sampling ‚Äî ne pas tout logger

**Le probl√®me :** sous forte charge (1000 req/sec), logger chaque requ√™te = 1000 lignes/sec = 86 millions/jour = des Go de logs par jour.

**Le sampling** : ne logger qu'une requ√™te sur N pour les logs fr√©quents et non critiques.

```go
// zerolog : logger 1 requ√™te sur 100 au niveau DEBUG
sampled := log.Sample(&zerolog.BasicSampler{N: 100})
sampled.Debug().
    Str("step", "redis").
    Bool("hit", true).
    Msg("cache hit")

// Logger 1 fois par seconde maximum (burst sampler)
sampled := log.Sample(zerolog.LevelSampler{
    DebugSampler: &zerolog.BurstSampler{
        Burst:       5,
        Period:      time.Second,
        NextSampler: &zerolog.BasicSampler{N: 100},
    },
})
```

### Strat√©gie de sampling par niveau

```
FATAL  : 100% ‚Äî toujours logger (rare et critique)
ERROR  : 100% ‚Äî toujours logger
WARN   : 100% ‚Äî toujours logger
INFO   :  10% ‚Äî 1 sur 10 suffit pour voir les tendances
DEBUG  :   1% ‚Äî 1 sur 100 pour le diagnostic ponctuel
TRACE  :   0% ‚Äî d√©sactiv√© en prod
```

---

<a name="correlation"></a>
## 8. Corr√©lation avec les traces (request ID)

**Le probl√®me :** un upload passe par API ‚Üí Optimizer ‚Üí Redis ‚Üí MinIO. Les logs de ces 4 services sont dans 4 fichiers diff√©rents. Comment reconstituer le parcours d'une requ√™te ?

**Solution : request ID propag√© dans tous les headers et tous les logs.**

```go
// API : g√©n√©rer un request ID
func handleUpload(w http.ResponseWriter, r *http.Request) {
    requestID := r.Header.Get("X-Request-ID")
    if requestID == "" {
        requestID = uuid.New().String()
    }
    w.Header().Set("X-Request-ID", requestID)

    logger := log.With().Str("request_id", requestID).Logger()
    ctx := logger.WithContext(r.Context())

    // Propager vers l'optimizer
    sendToOptimizerWithID(ctx, requestID, ...)
}

// Dans sendToOptimizer : ajouter le header
req, _ := http.NewRequestWithContext(ctx, "POST", url, body)
req.Header.Set("X-Request-ID", requestID)
```

**R√©sultat :** on peut filtrer tous les logs d'une seule requ√™te √† travers tous les services :

```bash
cat api.log optimizer.log | jq 'select(.request_id == "f47ac10b")' | sort_by(.time)

# Output : tous les logs de la requ√™te dans l'ordre chronologique
{"service":"api",       "time":"...001", "step":"read",      "bytes":2411520}
{"service":"api",       "time":"...002", "step":"redis",     "hit":false}
{"service":"api",       "time":"...003", "step":"minio",     "action":"put"}
{"service":"optimizer", "time":"...004", "step":"decode",    "format":"jpeg"}
{"service":"optimizer", "time":"...005", "step":"resize",    "from":"4000x3000","to":"1920x1080"}
{"service":"optimizer", "time":"...006", "step":"watermark", "duration_ms":267}
{"service":"api",       "time":"...007", "step":"redis",     "action":"set"}
```

---

<a name="backends"></a>
## 9. Les backends ‚Äî o√π envoyer les logs

### stdout ‚Üí collecteur ‚Üí stockage

Le pattern standard en prod :

```
Service Go ‚Üí stdout (JSON)
    ‚îÇ
    ‚ñº
Collecteur (Filebeat / Fluent Bit / Vector)
    ‚îÇ
    ‚îú‚îÄ‚îÄ Loki (stockage logs, int√©gr√© Grafana)
    ‚îú‚îÄ‚îÄ Elasticsearch + Kibana (ELK Stack)
    ‚îú‚îÄ‚îÄ Datadog
    ‚îî‚îÄ‚îÄ CloudWatch (AWS)
```

**Pourquoi √©crire sur stdout et non dans un fichier ?**
- Les conteneurs Docker/Kubernetes capturent stdout automatiquement
- Pas de gestion de rotation de fichiers
- Le collecteur s'occupe du reste

### Loki ‚Äî logs pour Grafana

Si on utilise d√©j√† Prometheus + Grafana (section Observabilit√©), Loki s'int√®gre naturellement :

```yaml
# docker-compose.yml
loki:
  image: grafana/loki:latest
  ports:
    - "3100:3100"

promtail:
  image: grafana/promtail:latest
  volumes:
    - /var/lib/docker/containers:/var/lib/docker/containers:ro
  # Collecte les logs Docker et les envoie √† Loki
```

**Requ√™te Loki (LogQL) :**
```
{service="api"} | json | duration_ms > 500
{service="api"} | json | level="error" | error =~ "minio.*"
```

---

<a name="watermark"></a>
## 10. Utilisation dans NWS Watermark

### Migration de log.Printf vers zerolog

**Avant :**
```go
log.Printf("[API] ‚ë§ Optimizer  : ‚úì %s re√ßus en %v", formatBytes(len(result)), optimizerDur)
```

**Apr√®s :**
```go
log.Info().
    Str("step", "optimizer").
    Str("request_id", requestID).
    Int("bytes", len(result)).
    Dur("duration", optimizerDur).
    Bool("success", true).
    Msg("optimizer response")
```

### Setup recommand√© pour le projet

```go
// api/logger.go
package main

import (
    "os"
    "github.com/rs/zerolog"
    "github.com/rs/zerolog/log"
)

func initLogger() {
    zerolog.TimeFieldFormat = time.RFC3339

    log.Logger = zerolog.New(os.Stdout).With().
        Timestamp().
        Str("service", "api").
        Str("version", os.Getenv("VERSION")).
        Logger()

    // Pretty print si ENV=dev
    if os.Getenv("ENV") == "dev" {
        log.Logger = log.Output(zerolog.ConsoleWriter{
            Out:        os.Stderr,
            TimeFormat: "15:04:05",
        })
    }

    level, err := zerolog.ParseLevel(os.Getenv("LOG_LEVEL"))
    if err != nil {
        level = zerolog.InfoLevel
    }
    zerolog.SetGlobalLevel(level)
}
```

### Middleware de logging HTTP

```go
func loggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // G√©n√©rer ou r√©cup√©rer le request ID
        requestID := r.Header.Get("X-Request-ID")
        if requestID == "" {
            requestID = ulid.Make().String()  // ou uuid.New().String()
        }
        w.Header().Set("X-Request-ID", requestID)

        // Sous-logger avec contexte de la requ√™te
        logger := log.With().
            Str("request_id", requestID).
            Str("method", r.Method).
            Str("path", r.URL.Path).
            Str("remote_ip", r.RemoteAddr).
            Logger()

        // Injecter dans le contexte
        ctx := logger.WithContext(r.Context())

        // Wrapper pour capturer le status code
        wrapped := &responseWriter{ResponseWriter: w, status: 200}
        next.ServeHTTP(wrapped, r.WithContext(ctx))

        logger.Info().
            Int("status", wrapped.status).
            Dur("duration", time.Since(start)).
            Msg("request completed")
    })
}

type responseWriter struct {
    http.ResponseWriter
    status int
}
func (rw *responseWriter) WriteHeader(status int) {
    rw.status = status
    rw.ResponseWriter.WriteHeader(status)
}
```

---

<a name="antipatterns"></a>
## 11. Les anti-patterns √† √©viter

### ‚ùå Logger des donn√©es sensibles

```go
// JAMAIS logger des mots de passe, tokens, donn√©es personnelles
log.Info().Str("password", password).Msg("user login")   // ‚ùå
log.Info().Str("token", jwt).Msg("auth success")          // ‚ùå
log.Info().Str("email", user.Email).Msg("user upload")    // ‚ùå RGPD

// ‚úÖ Logger des identifiants anonymis√©s
log.Info().Str("user_id", user.ID).Msg("user upload")
```

### ‚ùå Interpolation de cha√Ænes dans les messages

```go
// ‚ùå Inutilisable ‚Äî l'info est dans la cha√Æne, pas dans des champs
log.Info().Msgf("optimizer took %dms for %s", ms, filename)

// ‚úÖ Champs typ√©s
log.Info().Int("duration_ms", ms).Str("filename", filename).Msg("optimizer done")
```

### ‚ùå Ignorer les erreurs de logging

```go
// La plupart des loggers peuvent √©chouer silencieusement si le writer est ferm√©
// ‚Üí utiliser defer logger.Sync() (zap) ou s'assurer que os.Stdout est ouvert
```

### ‚ùå Logger dans une boucle serr√©e

```go
// ‚ùå Logger chaque pixel ‚Üí des millions de logs/sec
for py := 0; py < height; py++ {
    for px := 0; px < width; px++ {
        log.Debug().Int("px", px).Int("py", py).Msg("processing pixel")  // ‚ùå
    }
}

// ‚úÖ Logger le r√©sum√©
log.Debug().Int("pixels", width*height).Dur("duration", d).Msg("pixels processed")
```

### ‚ùå M√©langer logs texte et structur√©s

```go
log.Printf("erreur Redis")        // ‚ùå texte
log.Error().Msg("erreur Redis")   // ‚úÖ structur√©

// Choisir un format et s'y tenir dans tout le projet
```

---

<a name="r√©sum√©"></a>
## 12. R√©sum√©

### Pourquoi passer au structured logging

```
log.Printf ‚Üí lisible par humain, inutilisable par machine
zerolog    ‚Üí JSON typ√©, requ√™table, z√©ro allocation, 14x plus rapide que logrus
```

### Les r√®gles √† retenir

1. **Toujours JSON en prod** ‚Äî texte lisible uniquement en dev (`ConsoleWriter`)
2. **Champs typ√©s** ‚Äî jamais `Msgf("took %dms")`, toujours `Int("duration_ms", ms)`
3. **request_id partout** ‚Äî propager dans tous les services pour corr√©ler les logs
4. **Sampling en prod** ‚Äî ne pas logger 100% des requ√™tes INFO, 1-10% suffit
5. **Pas de donn√©es sensibles** ‚Äî jamais de password, token, email en clair
6. **Niveau INFO par d√©faut** ‚Äî DEBUG seulement en dev ou diagnostic ponctuel

### Stack recommand√©e

```
zerolog (logging) ‚Üí stdout ‚Üí Promtail/Fluent Bit (collecte) ‚Üí Loki (stockage) ‚Üí Grafana (visualisation)
```

### Comparaison rapide

| | log.Printf (actuel) | zerolog | zap | slog |
|---|---|---|---|---|
| Format | Texte | JSON | JSON | JSON |
| Requ√™table | Non | Oui | Oui | Oui |
| Perf | Moyen | ‚ö° Meilleur | ‚ö° Tr√®s bon | Bon |
| D√©pendance | stdlib | 1 pkg | 1 pkg | stdlib |
| Niveaux | Non | Oui | Oui | Oui |
| Sampling | Non | Oui | Oui | Partiel |
