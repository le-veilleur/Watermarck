# Cours : Redis
## Base de donnÃ©es en mÃ©moire, cache et broker

---

## ğŸ“‹ Table des matiÃ¨res

1. [C'est quoi Redis ?](#intro)
2. [Les structures de donnÃ©es](#structures)
3. [TTL â€” Expiration automatique](#ttl)
4. [Persistance â€” Ne pas perdre les donnÃ©es](#persistance)
5. [Cache â€” Les patterns classiques](#cache)
6. [Pub/Sub â€” Messagerie lÃ©gÃ¨re](#pubsub)
7. [Transactions â€” MULTI/EXEC](#transactions)
8. [Pipelines â€” Grouper les commandes](#pipelines)
9. [Redis Sentinel â€” Haute disponibilitÃ©](#sentinel)
10. [Redis Cluster â€” ScalabilitÃ© horizontale](#cluster)
11. [RÃ©sumÃ© et cas d'usage](#rÃ©sumÃ©)

---

<a name="intro"></a>
## 1. C'est quoi Redis ?

**Redis** = **RE**mote **DI**ctionary **S**erver

C'est une base de donnÃ©es **clÃ©-valeur** qui stocke tout **en RAM**.

**Analogie :** C'est comme un dictionnaire gÃ©ant ultra-rapide posÃ© sur la table devant toi â€” au lieu d'aller chercher l'info dans une armoire (disque), tu la prends directement devant toi (RAM).

```
RAM   : ~0.1 Âµs pour lire 1 KB  â† Redis
Disque SSD : ~100 Âµs pour lire 1 KB  â† MySQL, PostgreSQL
```

**RAM = 1000x plus rapide que le disque**

---

### Ce que Redis n'est pas

Redis n'est **pas** une base de donnÃ©es relationnelle. Pas de tables, pas de SQL, pas de JOIN.

| | Redis | PostgreSQL |
|---|-------|-----------|
| Stockage | RAM | Disque |
| Structure | ClÃ©-valeur | Tables relationnelles |
| RequÃªtes | Commandes simples | SQL |
| Vitesse | < 1ms | ~5-50ms |
| Persistance | Optionnelle | Oui |
| Use case | Cache, sessions, compteurs | DonnÃ©es mÃ©tier complexes |

---

### DÃ©marrer Redis

```bash
# Lancer Redis avec Docker
docker run -d -p 6379:6379 redis:alpine

# Se connecter en CLI
redis-cli

# Commandes de base
SET nom "Alice"       # stocker
GET nom               # lire       â†’ "Alice"
DEL nom               # supprimer
EXISTS nom            # existe ?   â†’ 0 ou 1
KEYS *                # toutes les clÃ©s (âš  jamais en prod)
```

---

<a name="structures"></a>
## 2. Les structures de donnÃ©es

Redis ne stocke pas que des chaÃ®nes. Il supporte 7 types de donnÃ©es natifs.

---

### 2a. String â€” La base

Le type le plus simple : une clÃ© â†’ une valeur (texte, nombre, binaire).

```bash
SET user:1:name "Alice"
GET user:1:name            # â†’ "Alice"

SET compteur 0
INCR compteur              # â†’ 1  (atomique !)
INCR compteur              # â†’ 2
INCRBY compteur 10         # â†’ 12
DECR compteur              # â†’ 11

# Stocker un JSON
SET user:1 '{"name":"Alice","age":30}'
GET user:1                 # â†’ '{"name":"Alice","age":30}'

# Stocker avec expiration
SETEX session:abc123 3600 "user_id=42"   # expire dans 3600s
```

**Use case :** Cache de requÃªtes, compteurs de vues, sessions utilisateur.

---

### 2b. List â€” File et pile

Une liste ordonnÃ©e de chaÃ®nes. On peut ajouter/retirer **au dÃ©but ou Ã  la fin** en O(1).

```bash
# Ajouter Ã  droite (fin de liste)
RPUSH notifications "Nouveau message"
RPUSH notifications "Commande livrÃ©e"
RPUSH notifications "Paiement reÃ§u"

# Lire la liste (0 = dÃ©but, -1 = fin)
LRANGE notifications 0 -1
# â†’ 1) "Nouveau message"
#    2) "Commande livrÃ©e"
#    3) "Paiement reÃ§u"

# Retirer le premier Ã©lÃ©ment (FIFO)
LPOP notifications    # â†’ "Nouveau message"

# Retirer le dernier (LIFO / pile)
RPOP notifications    # â†’ "Paiement reÃ§u"

# Taille de la liste
LLEN notifications    # â†’ 1
```

**LPUSH + RPOP = file d'attente (FIFO)**
**LPUSH + LPOP = pile (LIFO)**

**Use case :** File de tÃ¢ches lÃ©gÃ¨res, historique d'activitÃ©, notifications.

```go
// Producteur
redisClient.RPush(ctx, "tasks", `{"type":"email","to":"alice@example.com"}`)

// Consommateur (bloque jusqu'Ã  un message)
result, err := redisClient.BLPop(ctx, 0, "tasks").Result()
if err == nil {
    fmt.Println(result[1]) // result[0] = nom de la queue, result[1] = valeur
}
```

---

### 2c. Hash â€” Objet structurÃ©

Un hash est une **map de champs** sous une seule clÃ©. IdÃ©al pour reprÃ©senter un objet.

```bash
# Stocker un utilisateur
HSET user:42 name "Alice" email "alice@example.com" age 30 role "admin"

# Lire un champ
HGET user:42 name          # â†’ "Alice"

# Lire tous les champs
HGETALL user:42
# â†’ 1) "name"
#    2) "Alice"
#    3) "email"
#    4) "alice@example.com"
#    5) "age"
#    6) "30"
#    7) "role"
#    8) "admin"

# Modifier un champ
HSET user:42 age 31

# IncrÃ©menter un champ numÃ©rique
HINCRBY user:42 age 1      # â†’ 32

# Supprimer un champ
HDEL user:42 role

# VÃ©rifier l'existence d'un champ
HEXISTS user:42 email      # â†’ 1
```

**Avantage vs String :** Modifier un champ ne nÃ©cessite pas de lire/rÃ©Ã©crire tout l'objet.

**Use case :** Profils utilisateur, paramÃ¨tres de configuration, Ã©tat de session dÃ©taillÃ©.

---

### 2d. Set â€” Ensemble sans doublons

Un set est une **collection non ordonnÃ©e** de chaÃ®nes uniques.

```bash
# Ajouter des membres
SADD tags:article:1 "go" "performance" "backend"
SADD tags:article:1 "go"  # doublon â†’ ignorÃ©

# VÃ©rifier l'appartenance
SISMEMBER tags:article:1 "go"        # â†’ 1
SISMEMBER tags:article:1 "python"    # â†’ 0

# Tous les membres
SMEMBERS tags:article:1
# â†’ 1) "go"
#    2) "performance"
#    3) "backend"

# OpÃ©rations ensemblistes
SADD tags:article:2 "go" "cloud" "docker"

SINTER tags:article:1 tags:article:2   # intersection â†’ "go"
SUNION tags:article:1 tags:article:2   # union â†’ tous les tags
SDIFF  tags:article:1 tags:article:2   # diffÃ©rence â†’ "performance", "backend"
```

**Use case :** Tags, liste d'amis communs, IPs uniques par jour, permissions.

---

### 2e. Sorted Set â€” Ensemble ordonnÃ© par score

Comme un Set, mais chaque membre a un **score numÃ©rique**. L'ordre est maintenu automatiquement.

```bash
# Ajouter avec score
ZADD leaderboard 1500 "Alice"
ZADD leaderboard 2300 "Bob"
ZADD leaderboard 1800 "Charlie"
ZADD leaderboard 2100 "Diana"

# Classement (ordre croissant)
ZRANGE leaderboard 0 -1 WITHSCORES
# â†’ Alice 1500, Charlie 1800, Diana 2100, Bob 2300

# Classement (ordre dÃ©croissant = du meilleur)
ZREVRANGE leaderboard 0 -1 WITHSCORES
# â†’ Bob 2300, Diana 2100, Charlie 1800, Alice 1500

# Top 3
ZREVRANGE leaderboard 0 2

# Score d'un membre
ZSCORE leaderboard "Alice"     # â†’ 1500

# Rang d'un membre (0-indexed)
ZREVRANK leaderboard "Bob"     # â†’ 0 (1er)
ZREVRANK leaderboard "Alice"   # â†’ 3 (4Ã¨me)

# IncrÃ©menter le score
ZINCRBY leaderboard 500 "Alice"  # Alice passe Ã  2000
```

**Use case :** Classements, prioritÃ©s de tÃ¢ches, timeline triÃ©e par timestamp, rate limiting.

---

### 2f. Stream â€” Journal d'Ã©vÃ©nements

Un stream est un **log immuable** d'entrÃ©es horodatÃ©es. C'est Redis en mode "Kafka lÃ©ger".

```bash
# Ajouter un Ã©vÃ©nement (ID auto-gÃ©nÃ©rÃ©)
XADD events * action "login" user "alice" ip "192.168.1.1"
# â†’ "1706789012345-0"  (timestamp-sÃ©quence)

XADD events * action "purchase" user "alice" amount "99.90"

# Lire les Ã©vÃ©nements
XRANGE events - +      # tous les Ã©vÃ©nements
XRANGE events - + COUNT 10  # 10 premiers

# Lire en temps rÃ©el (attend les nouveaux messages)
XREAD BLOCK 0 STREAMS events $

# Groupes de consommateurs (comme RabbitMQ)
XGROUP CREATE events processors $ MKSTREAM
XREADGROUP GROUP processors worker1 COUNT 1 STREAMS events >
```

**Use case :** Audit log, Ã©vÃ©nements temps rÃ©el, remplacement lÃ©ger de Kafka.

---

### ğŸ“Š Comparaison des structures

| Structure | OpÃ©rations clÃ©s | Use case |
|-----------|----------------|----------|
| **String** | GET/SET/INCR | Cache, compteurs, sessions |
| **List** | LPUSH/RPOP/LRANGE | Files de tÃ¢ches, historique |
| **Hash** | HGET/HSET/HGETALL | Objets, profils utilisateur |
| **Set** | SADD/SISMEMBER/SINTER | Tags, dÃ©doublonnage, permissions |
| **Sorted Set** | ZADD/ZRANGE/ZSCORE | Classements, rate limiting |
| **Stream** | XADD/XRANGE/XREAD | Ã‰vÃ©nements, audit log |

---

<a name="ttl"></a>
## 3. TTL â€” Expiration automatique

Redis peut **supprimer automatiquement** une clÃ© aprÃ¨s un dÃ©lai. C'est le TTL (Time To Live).

```bash
# DÃ©finir un TTL en secondes
EXPIRE session:abc123 3600       # expire dans 1 heure

# DÃ©finir lors de la crÃ©ation
SETEX cache:user:42 300 "donnÃ©es"  # expire dans 5 minutes

# Voir le TTL restant
TTL session:abc123    # â†’ 3542 (secondes restantes)
TTL session:xyz       # â†’ -1  (pas d'expiration)
TTL session:old       # â†’ -2  (clÃ© inexistante ou expirÃ©e)

# Supprimer l'expiration
PERSIST session:abc123   # â†’ clÃ© devient permanente

# TTL en millisecondes
PEXPIRE clÃ© 5000         # expire dans 5000ms
PTTL clÃ©                 # TTL restant en ms
```

---

### Comment fonctionne l'expiration ?

Redis utilise deux stratÃ©gies combinÃ©es :

**1. Lazy expiration :** La clÃ© est supprimÃ©e seulement quand on essaie d'y accÃ©der.
```
GET session:expired â†’ Redis vÃ©rifie le TTL â†’ clÃ© expirÃ©e â†’ supprime â†’ retourne nil
```

**2. Active expiration :** Redis scanne rÃ©guliÃ¨rement un Ã©chantillon de clÃ©s pour supprimer celles expirÃ©es en arriÃ¨re-plan.

**ConsÃ©quence :** Une clÃ© expirÃ©e n'est pas forcÃ©ment supprimÃ©e immÃ©diatement â€” mais elle n'est plus accessible.

---

<a name="persistance"></a>
## 4. Persistance â€” Ne pas perdre les donnÃ©es

Par dÃ©faut Redis stocke tout en RAM. Si Redis redÃ©marre â†’ **tout est perdu**. Deux mÃ©canismes permettent de persister sur disque.

---

### 4a. RDB â€” Snapshot (photo instantanÃ©e)

Redis prend une **photo de toutes les donnÃ©es** Ã  intervalles rÃ©guliers et l'Ã©crit sur disque.

```
t=0h    DonnÃ©es en RAM : {A, B, C}
t=1h    RDB snapshot â†’ dump.rdb Ã©crit sur disque
t=2h    Nouvelles donnÃ©es : {A, B, C, D, E}
t=2h30  CRASH
t=2h31  Redis redÃ©marre â†’ charge dump.rdb â†’ {A, B, C} â† D et E sont perdus !
```

**Configuration (redis.conf) :**
```
save 3600 1     # snapshot si 1 changement en 1h
save 300 100    # snapshot si 100 changements en 5min
save 60 10000   # snapshot si 10000 changements en 1min
```

**Avantages :** Compact, rapide au redÃ©marrage, idÃ©al pour les sauvegardes.
**InconvÃ©nient :** Perte des donnÃ©es entre deux snapshots.

---

### 4b. AOF â€” Append Only File (journal)

Redis enregistre **chaque commande d'Ã©criture** dans un fichier log.

```
Commande SET user:1 "Alice" â†’ Ã©crite dans appendonly.aof
Commande SET user:2 "Bob"   â†’ Ã©crite dans appendonly.aof
Commande DEL user:1          â†’ Ã©crite dans appendonly.aof

Au redÃ©marrage : Redis rejoue toutes les commandes du fichier
â†’ Aucune perte de donnÃ©es !
```

**Modes de synchronisation :**
```
appendfsync always    # Ã©crit Ã  chaque commande â†’ 0 perte, lent
appendfsync everysec  # Ã©crit toutes les secondes â†’ max 1s de perte, rapide âœ…
appendfsync no        # laisse l'OS dÃ©cider â†’ rapide, risquÃ©
```

**RÃ©Ã©criture AOF :** Le fichier grossit indÃ©finiment â†’ Redis le compacte rÃ©guliÃ¨rement.
```
BGREWRITEAOF  # dÃ©clenche manuellement la rÃ©Ã©criture
```

---

### 4c. Comparaison RDB vs AOF

| CritÃ¨re | RDB | AOF |
|---------|-----|-----|
| Perte de donnÃ©es max | Depuis le dernier snapshot | ~1 seconde (everysec) |
| Vitesse de redÃ©marrage | Rapide | Lent (rejoue les commandes) |
| Taille fichier | Compact | Plus volumineux |
| Impact performance | Faible | TrÃ¨s faible (everysec) |
| Use case | Sauvegardes, dev | Production critique |

**Recommandation :** Activer **les deux** en production â€” RDB pour les sauvegardes, AOF pour la durabilitÃ©.

```bash
# Dans notre docker-compose, Redis est configurÃ© sans persistance
# car utilisÃ© uniquement comme cache (les donnÃ©es peuvent Ãªtre perdues)
command: redis-server --save "" --appendonly no
```

---

<a name="cache"></a>
## 5. Cache â€” Les patterns classiques

---

### 5a. Cache-Aside (Lazy Loading)

Le pattern le plus courant. L'application gÃ¨re elle-mÃªme le cache.

```
Lecture :
  App â†’ Redis.Get(clÃ©)
    â”œâ”€â”€ HIT  â†’ retourne la valeur depuis Redis
    â””â”€â”€ MISS â†’ App lit depuis la DB â†’ App.Set(clÃ©, valeur, TTL) â†’ retourne

Ã‰criture :
  App â†’ DB.Update(donnÃ©e) â†’ Redis.Del(clÃ©)  â† invalide le cache
```

```go
// Notre implÃ©mentation dans api/main.go
cached, err := redisClient.Get(ctx, cacheKey).Bytes()
if err == nil {
    return cached  // HIT
}
// MISS â†’ traitement â†’ stockage
result := processImage(data)
redisClient.Set(ctx, cacheKey, result, 24*time.Hour)
return result
```

**Avantages :** Simple, flexible, le cache ne contient que ce qui est demandÃ©.
**InconvÃ©nient :** La 1Ã¨re requÃªte est toujours lente (cache miss).

---

### 5b. Write-Through

Ã€ chaque Ã©criture en base, on met Ã  jour le cache **simultanÃ©ment**.

```
App â†’ DB.Write(donnÃ©e) â†’ Redis.Set(clÃ©, donnÃ©e)
```

**Avantage :** Cache toujours Ã  jour, jamais de miss sur des donnÃ©es rÃ©centes.
**InconvÃ©nient :** Ã‰criture plus lente, cache peut contenir des donnÃ©es jamais relues.

---

### 5c. Write-Behind (Write-Back)

L'application Ã©crit **d'abord dans Redis**, puis Redis persiste en DB de faÃ§on asynchrone.

```
App â†’ Redis.Set(clÃ©, donnÃ©e) â†’ retourne immÃ©diatement
                              â†“ (asynchrone)
                          DB.Write(donnÃ©e)
```

**Avantage :** Ã‰criture ultra-rapide.
**InconvÃ©nient :** Risque de perte si Redis crashe avant la persistence.

---

### 5d. Cache Stampede (thundering herd)

**Le problÃ¨me :** 1000 requÃªtes arrivent au mÃªme moment sur une clÃ© expirÃ©e â†’ 1000 requÃªtes vont en DB simultanÃ©ment â†’ surcharge.

```
TTL expire Ã  t=10h00
1000 requÃªtes Ã  t=10h00:001 â†’ toutes font Redis.Get â†’ MISS
                            â†’ toutes vont en DB â†’ ğŸ’¥
```

**Solution : mutex ou probabilistic early expiration**

```go
// Mutex simple avec SETNX (Set if Not eXists)
locked := redisClient.SetNX(ctx, cacheKey+":lock", "1", 10*time.Second)
if locked.Val() {
    // Seul ce thread recalcule
    result := processImage(data)
    redisClient.Set(ctx, cacheKey, result, 24*time.Hour)
    redisClient.Del(ctx, cacheKey+":lock")
} else {
    // Les autres attendent
    time.Sleep(100 * time.Millisecond)
    result = redisClient.Get(ctx, cacheKey).Bytes()
}
```

---

<a name="pubsub"></a>
## 6. Pub/Sub â€” Messagerie lÃ©gÃ¨re

Redis permet de faire de la messagerie **publish/subscribe** en temps rÃ©el.

```
Subscriber A â”€â”
Subscriber B â”€â”¼â”€â”€ Ã©coute canal "notifications"
Subscriber C â”€â”˜

Publisher â”€â”€â–º PUBLISH notifications "Nouveau message"
             â†’ reÃ§u instantanÃ©ment par A, B et C
```

```bash
# Subscriber (terminal 1)
SUBSCRIBE notifications
# â†’ Waiting for messages...

# Publisher (terminal 2)
PUBLISH notifications "Bonjour !"
# â†’ Subscriber reÃ§oit : "Bonjour !"
```

```go
// Subscriber
pubsub := redisClient.Subscribe(ctx, "notifications")
defer pubsub.Close()

ch := pubsub.Channel()
for msg := range ch {
    fmt.Println(msg.Payload) // message reÃ§u
}

// Publisher
redisClient.Publish(ctx, "notifications", "Bonjour !")
```

---

### Pattern matching sur les canaux

```bash
PSUBSCRIBE order.*        # Ã©coute order.created, order.paid, order.shipped...
PSUBSCRIBE log.*error*    # tous les canaux contenant "error"
```

---

### âš ï¸ Limitations du Pub/Sub Redis

| Limitation | ConsÃ©quence |
|-----------|-------------|
| Pas de persistance | Si le subscriber est offline â†’ message perdu |
| Pas d'ACK | Pas de garantie de livraison |
| Pas d'historique | Impossible de rejouer les messages |

**Pour des messages critiques â†’ utiliser Redis Streams ou RabbitMQ.**
**Redis Pub/Sub = notifications temps rÃ©el non critiques** (ex: mise Ã  jour live d'une UI).

---

<a name="transactions"></a>
## 7. Transactions â€” MULTI/EXEC

Redis permet d'exÃ©cuter un **groupe de commandes de faÃ§on atomique** â€” soit toutes rÃ©ussissent, soit aucune n'est exÃ©cutÃ©e.

```bash
MULTI           # dÃ©but de transaction
SET compte:alice 100
SET compte:bob 200
INCRBY compte:alice -50
INCRBY compte:bob 50
EXEC            # exÃ©cute toutes les commandes atomiquement
```

```
Sans transaction :
  INCRBY compte:alice -50   â†’ alice = 50
  [CRASH]
  INCRBY compte:bob 50      â†’ jamais exÃ©cutÃ© â†’ 50â‚¬ disparaissent ğŸ’€

Avec transaction :
  MULTI
  INCRBY compte:alice -50
  INCRBY compte:bob 50
  EXEC â†’ les deux s'exÃ©cutent ou aucun
```

---

### WATCH â€” Transaction optimiste

`WATCH` permet d'annuler la transaction si une clÃ© a Ã©tÃ© modifiÃ©e entre-temps.

```bash
WATCH compte:alice         # surveille la clÃ©
MULTI
INCRBY compte:alice -50    # si alice a Ã©tÃ© modifiÃ© par quelqu'un d'autre...
INCRBY compte:bob 50
EXEC                       # â†’ nil (transaction annulÃ©e) ou succÃ¨s
```

**Analogie :** C'est comme un optimistic lock en base de donnÃ©es.

---

<a name="pipelines"></a>
## 8. Pipelines â€” Grouper les commandes

Par dÃ©faut, chaque commande Redis fait un **aller-retour rÃ©seau** :

```
Client â”€â”€â–º GET clÃ©1 â”€â”€â–º Redis â”€â”€â–º rÃ©ponse1 â”€â”€â–º Client  (~1ms)
Client â”€â”€â–º GET clÃ©2 â”€â”€â–º Redis â”€â”€â–º rÃ©ponse2 â”€â”€â–º Client  (~1ms)
Client â”€â”€â–º GET clÃ©3 â”€â”€â–º Redis â”€â”€â–º rÃ©ponse3 â”€â”€â–º Client  (~1ms)
Total : ~3ms
```

Avec un pipeline, toutes les commandes sont **envoyÃ©es en une seule fois** :

```
Client â”€â”€â–º GET clÃ©1, GET clÃ©2, GET clÃ©3 â”€â”€â–º Redis â”€â”€â–º rÃ©ponse1, rÃ©ponse2, rÃ©ponse3 â”€â”€â–º Client
Total : ~1ms
```

```go
// Sans pipeline : 3 allers-retours rÃ©seau
redisClient.Get(ctx, "clÃ©1")
redisClient.Get(ctx, "clÃ©2")
redisClient.Get(ctx, "clÃ©3")

// Avec pipeline : 1 seul aller-retour rÃ©seau
pipe := redisClient.Pipeline()
get1 := pipe.Get(ctx, "clÃ©1")
get2 := pipe.Get(ctx, "clÃ©2")
get3 := pipe.Get(ctx, "clÃ©3")
pipe.Exec(ctx)

fmt.Println(get1.Val(), get2.Val(), get3.Val())
```

**Gain :** Sur 100 commandes â†’ **100x moins d'allers-retours rÃ©seau**.

---

<a name="sentinel"></a>
## 9. Redis Sentinel â€” Haute disponibilitÃ©

En production, un seul Redis est un **point de dÃ©faillance unique** (SPOF). Redis Sentinel surveille le serveur et bascule automatiquement en cas de panne.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    surveille    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentinel 1 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Redis Master â”‚â—„â”€â”€ Ã‰criture
â”‚  Sentinel 2 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (primaire)   â”‚
â”‚  Sentinel 3 â”‚                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚ rÃ©plication
                                       â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  Redis Replica â”‚â—„â”€â”€ Lecture
                               â”‚  (secondaire)  â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**En cas de panne du Master :**

```
Master KO â†’ Sentinels dÃ©tectent la panne (quorum)
          â†’ Sentinel Ã©lit un nouveau Master parmi les Replicas
          â†’ Clients redirigÃ©s vers le nouveau Master
          â†’ DurÃ©e de basculement : ~30 secondes
```

**Configuration minimale :** 3 Sentinels (quorum = 2).

---

<a name="cluster"></a>
## 10. Redis Cluster â€” ScalabilitÃ© horizontale

Redis est **mono-thread** pour les commandes â€” il ne peut utiliser qu'un seul cÅ“ur CPU. Redis Cluster permet de **distribuer les donnÃ©es sur plusieurs nÅ“uds**.

### Sharding par hash slot

Redis Cluster divise les donnÃ©es en **16 384 hash slots**.

```
Hash slot d'une clÃ© : CRC16(clÃ©) % 16384

NÅ“ud A : slots 0     â†’ 5460     (1/3 des donnÃ©es)
NÅ“ud B : slots 5461  â†’ 10922    (1/3 des donnÃ©es)
NÅ“ud C : slots 10923 â†’ 16383    (1/3 des donnÃ©es)
```

```
SET user:42 "Alice"
â†’ CRC16("user:42") % 16384 = 4821
â†’ stockÃ© sur NÅ“ud A (slots 0-5460) âœ…
```

### Architecture Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â† Masters
â”‚  NÅ“ud A  â”‚  â”‚  NÅ“ud B  â”‚  â”‚  NÅ“ud C  â”‚
â”‚ slots    â”‚  â”‚ slots    â”‚  â”‚ slots    â”‚
â”‚ 0-5460   â”‚  â”‚ 5461-10922â”‚  â”‚10923-16383â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚          â† RÃ©plication
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Replica Aâ”‚  â”‚ Replica Bâ”‚  â”‚ Replica Câ”‚   â† Replicas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Minimum :** 3 masters + 3 replicas = 6 nÅ“uds.

---

### Sentinel vs Cluster

| | Sentinel | Cluster |
|---|---------|---------|
| Objectif | Haute disponibilitÃ© | ScalabilitÃ© + disponibilitÃ© |
| Sharding | Non (1 nÅ“ud = toutes les donnÃ©es) | Oui (donnÃ©es distribuÃ©es) |
| ComplexitÃ© | Faible | Ã‰levÃ©e |
| Quand l'utiliser | â‰¤ quelques GB de donnÃ©es | > RAM d'un seul serveur |

---

<a name="rÃ©sumÃ©"></a>
## 11. ğŸ“Š RÃ©sumÃ© et cas d'usage

### Les structures en un coup d'Å“il

```
String     â†’ clÃ© : valeur simple
             SET user:1 "Alice" / GET user:1

List       â†’ clÃ© : [v1, v2, v3, ...]   (file / pile)
             RPUSH tasks "job" / LPOP tasks

Hash       â†’ clÃ© : {champ: valeur}     (objet)
             HSET user:1 name "Alice" age 30

Set        â†’ clÃ© : {v1, v2, v3}        (unique, non ordonnÃ©)
             SADD tags "go" "backend"

Sorted Set â†’ clÃ© : {membre: score}     (unique, ordonnÃ©)
             ZADD scores 1500 "Alice"

Stream     â†’ clÃ© : [(id, champs), ...]  (log immuable)
             XADD events * action "login"
```

---

### Cas d'usage classiques

| Cas d'usage | Structure | Commandes clÃ©s |
|-------------|-----------|----------------|
| Cache de requÃªtes API | String | GET / SET + TTL |
| Session utilisateur | Hash | HGETALL / HSET |
| File de tÃ¢ches | List | RPUSH / BLPOP |
| Compteur de vues | String | INCR |
| Classement temps rÃ©el | Sorted Set | ZADD / ZREVRANGE |
| DÃ©doublonnage | Set | SADD / SISMEMBER |
| Rate limiting | String + TTL | INCR / EXPIRE |
| Pub/Sub temps rÃ©el | Pub/Sub | PUBLISH / SUBSCRIBE |
| Audit log | Stream | XADD / XRANGE |
| Lock distribuÃ© | String | SETNX + TTL |

---

### Rate Limiting avec Redis

Un cas d'usage trÃ¨s courant : limiter les requÃªtes d'un utilisateur.

```go
// Max 100 requÃªtes par minute par IP
func isRateLimited(ip string) bool {
    key := "rate:" + ip
    count, _ := redisClient.Incr(ctx, key).Result()
    if count == 1 {
        redisClient.Expire(ctx, key, time.Minute)  // dÃ©marre le compteur
    }
    return count > 100
}
```

```
1Ã¨re requÃªte : INCR rate:192.168.1.1 â†’ 1, EXPIRE 60s
50Ã¨me requÃªte : INCR â†’ 50
100Ã¨me requÃªte : INCR â†’ 100
101Ã¨me requÃªte : INCR â†’ 101 â†’ bloquÃ© âŒ
t+60s : clÃ© expire â†’ compteur reset â†’ autorisÃ© âœ…
```

---

### Lock distribuÃ© (Redlock)

EmpÃªcher deux instances de faire la mÃªme chose en parallÃ¨le.

```go
// AcquÃ©rir le lock (SETNX = SET if Not eXists)
acquired := redisClient.SetNX(ctx, "lock:job:42", "worker-1", 30*time.Second)

if acquired.Val() {
    // On a le lock â†’ on fait le travail
    processJob(42)
    // LibÃ©rer le lock
    redisClient.Del(ctx, "lock:job:42")
} else {
    // Quelqu'un d'autre traite dÃ©jÃ  ce job
    log.Println("Job 42 dÃ©jÃ  en cours de traitement")
}
```

---

### Commandes d'inspection utiles

```bash
# Info gÃ©nÃ©rale
INFO server
INFO memory
INFO stats

# MÃ©moire utilisÃ©e
INFO memory | grep used_memory_human

# Nombre de clÃ©s
DBSIZE

# Surveiller en temps rÃ©el
MONITOR          # âš  trÃ¨s verbeux, jamais en prod

# Statistiques de latence
LATENCY LATEST

# ClÃ©s par pattern (âš  bloquant sur gros datasets, utiliser SCAN)
SCAN 0 MATCH user:* COUNT 100

# Supprimer toutes les donnÃ©es (âš  irrÃ©versible)
FLUSHDB          # vide la base courante
FLUSHALL         # vide toutes les bases
```

---

### Concepts clÃ©s Ã  retenir

#### 1. **RAM = vitesse**
Redis est rapide parce qu'il lit et Ã©crit en mÃ©moire. La persistance (RDB/AOF) est optionnelle et dÃ©couplÃ©e.

#### 2. **Choisir la bonne structure**
Chaque structure a ses opÃ©rations optimales. Un Hash pour un objet, un Sorted Set pour un classement, une List pour une queue.

#### 3. **TTL = gestion de la mÃ©moire**
Sans TTL, Redis remplit la RAM indÃ©finiment. Toujours dÃ©finir une expiration sur les donnÃ©es temporaires.

#### 4. **Cache-Aside = le pattern universel**
Lire depuis Redis, fallback sur la DB si miss, stocker dans Redis avec TTL. C'est le pattern le plus utilisÃ©.

#### 5. **Atomic = thread-safe**
INCR, SETNX, GETSET... Ces commandes sont atomiques. Exploite-les pour les compteurs et les locks sans avoir besoin de mutex applicatif.

---

## ğŸ“š Pour aller plus loin

- **RedisInsight** : UI desktop pour visualiser et dÃ©boguer Redis
- **Redis modules** : RedisSearch (full-text), RedisJSON (stockage JSON natif), RedisTimeSeries
- **ioredis / go-redis** : clients Redis pour Node.js et Go
- **Lettuce** : client Redis rÃ©actif pour Java
- **RESP3** : nouveau protocole Redis avec des types de donnÃ©es enrichis

---

**ğŸ“ Fin du cours â€” Redis**
