# Cours : Architecture DistribuÃ©e
## Scaler horizontalement â€” Load Balancing, DLQ, Consistent Hashing, CQRS

---

## ğŸ“‹ Table des matiÃ¨res

1. [C'est quoi l'architecture distribuÃ©e ?](#intro)
2. [Le thÃ©orÃ¨me CAP](#cap)
3. [Scaling vertical vs horizontal](#scaling)
4. [Load Balancing â€” distribuer la charge](#load-balancing)
5. [Service Discovery â€” trouver les services](#discovery)
6. [Dead Letter Queue â€” ne pas perdre les messages](#dlq)
7. [Consistent Hashing â€” distribuer sans tout casser](#hashing)
8. [Distributed Locks â€” synchronisation cross-services](#locks)
9. [Saga Pattern â€” transactions distribuÃ©es](#saga)
10. [CQRS â€” sÃ©parer lectures et Ã©critures](#cqrs)
11. [Event Sourcing â€” stocker les Ã©vÃ©nements](#event-sourcing)
12. [Utilisation dans NWS Watermark](#watermark)
13. [RÃ©sumÃ©](#rÃ©sumÃ©)

---

<a name="intro"></a>
## 1. C'est quoi l'architecture distribuÃ©e ?

Un systÃ¨me distribuÃ© = plusieurs processus sur plusieurs machines qui coopÃ¨rent pour accomplir une tÃ¢che.

**Analogie :** une chaÃ®ne de restaurants.
- Un seul restaurant = systÃ¨me centralisÃ© (si Ã§a ferme, plus rien)
- 50 restaurants dans la ville = systÃ¨me distribuÃ© (si l'un ferme, les autres servent)

```
SystÃ¨me centralisÃ© :              SystÃ¨me distribuÃ© :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
â”‚   API monolithiqueâ”‚              â”‚API â”‚ â”‚API â”‚ â”‚API â”‚
â”‚   + Optimizer     â”‚              â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
â”‚   + Cache         â”‚              â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
â”‚   + Storage       â”‚              â”‚OPT â”‚ â”‚OPT â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
1 point de dÃ©faillance            RÃ©silience, scalabilitÃ©
```

### Les dÃ©fis propres aux systÃ¨mes distribuÃ©s

1. **Latence rÃ©seau** â€” les appels rÃ©seau sont 1000x plus lents que la mÃ©moire
2. **DÃ©faillances partielles** â€” un service peut Ãªtre lent sans Ãªtre mort
3. **DonnÃ©es incohÃ©rentes** â€” deux services peuvent avoir des visions diffÃ©rentes de la rÃ©alitÃ©
4. **Ordre des Ã©vÃ©nements** â€” deux Ã©vÃ©nements simultanÃ©s peuvent arriver dans n'importe quel ordre
5. **Split brain** â€” deux parties du systÃ¨me peuvent se croire chacune "le vrai leader"

---

<a name="cap"></a>
## 2. Le thÃ©orÃ¨me CAP

**Eric Brewer, 2000 :** un systÃ¨me distribuÃ© ne peut garantir que **2 des 3 propriÃ©tÃ©s** suivantes simultanÃ©ment.

```
         CohÃ©rence (C)
         "tous les noeuds voient la mÃªme donnÃ©e"
              /\
             /  \
            /    \
           /      \
          /        \
DisponibilitÃ© â”€â”€â”€â”€ TolÃ©rance aux partitions
     (A)                  (P)
"rÃ©pond toujours"    "rÃ©siste aux coupures rÃ©seau"
```

**CP â€” CohÃ©rence + Partition tolerance (pas toujours disponible)**
- Redis Cluster en mode strict
- HBase, Zookeeper
- PrÃ©fÃ©rer quand : donnÃ©es financiÃ¨res, stock

**AP â€” DisponibilitÃ© + Partition tolerance (Ã©ventuellement cohÃ©rent)**
- Cassandra, CouchDB, DynamoDB
- Notre Redis (un seul noeud â†’ pas de partition possible)
- PrÃ©fÃ©rer quand : disponibilitÃ© > cohÃ©rence stricte (rÃ©seaux sociaux, cache)

**CA â€” CohÃ©rence + DisponibilitÃ© (pas de tolÃ©rance aux partitions)**
- Impossible en pratique sur un rÃ©seau non fiable
- MySQL en mode single-node (fonctionne mais sans distribuÃ©)

### En pratique sur NWS Watermark

```
Redis (cache) :    AP â†’ si Redis est down, on continue sans cache (dÃ©gradation gracieuse)
MinIO (storage) :  CP â†’ on prÃ©fÃ¨re Ã©chouer que stocker un fichier corrompu
RabbitMQ (queue) : AP â†’ les messages persistent mÃªme si le consumer est down
```

---

<a name="scaling"></a>
## 3. Scaling vertical vs horizontal

**Scaling vertical** = ajouter des ressources Ã  un seul serveur.

```
Serveur 1 : 4 CPU, 8 GB RAM
     â†“
Serveur 1 : 16 CPU, 64 GB RAM  â† scaling vertical

Limites :
- Le serveur le plus puissant du monde a des limites physiques
- Un seul point de dÃ©faillance
- Temps d'arrÃªt pour upgrader le hardware
```

**Scaling horizontal** = ajouter des serveurs.

```
Serveur 1 : 4 CPU, 8 GB RAM
     â†“
Serveur 1 + Serveur 2 + Serveur 3 : chacun 4 CPU, 8 GB RAM

Avantages :
- ThÃ©oriquement infini (ajouter des serveurs)
- Pas de temps d'arrÃªt
- RÃ©silience (si 1 serveur tombe, les 2 autres continuent)

DÃ©fis :
- Besoin d'un load balancer
- Ã‰tat partagÃ© complexe (sessions, cache)
- CohÃ©rence des donnÃ©es
```

### Notre optimizer est stateless â†’ easy to scale

```yaml
# docker compose scale optimizer=3
optimizer:
  build: ./optimizer
  deploy:
    replicas: 3
  # Pas d'Ã©tat local â†’ n'importe quelle instance peut traiter n'importe quelle requÃªte
```

**Stateless = chaque requÃªte est indÃ©pendante.** L'optimizer ne garde rien en mÃ©moire entre les requÃªtes â†’ n'importe quelle instance peut traiter n'importe quelle requÃªte.

---

<a name="load-balancing"></a>
## 4. Load Balancing â€” distribuer la charge

### Les algorithmes

**Round Robin :** distribuer Ã  tour de rÃ´le.
```
RequÃªte 1 â†’ Optimizer A
RequÃªte 2 â†’ Optimizer B
RequÃªte 3 â†’ Optimizer C
RequÃªte 4 â†’ Optimizer A
...

ProblÃ¨me : une image 8K prend 1s, une image 100KB prend 50ms
â†’ Optimizer A peut avoir 10 jobs lourds pendant qu'Optimizer B est libre
```

**Least Connections :** envoyer au moins chargÃ©.
```
Optimizer A : 5 connexions actives
Optimizer B : 2 connexions actives  â† choisir celui-ci
Optimizer C : 3 connexions actives

â†’ Mieux pour des jobs de durÃ©e variable
```

**Weighted Round Robin :** certains serveurs reÃ§oivent plus de trafic.
```
Optimizer A (4 CPU) : poids 4
Optimizer B (2 CPU) : poids 2
â†’ A reÃ§oit 2x plus de trafic que B
```

**IP Hash :** mÃªme client â†’ mÃªme serveur (sticky sessions).
```
IP 192.168.1.1 â†’ toujours Optimizer A
IP 192.168.1.2 â†’ toujours Optimizer B
â†’ Utile si l'optimizer garde un Ã©tat par client (notre cas : non)
```

### ImplÃ©mentation avec nginx

```nginx
upstream optimizers {
    least_conn;                       # algorithme least connections

    server optimizer_1:3001 weight=2; # plus puissant â†’ plus de trafic
    server optimizer_2:3001 weight=1;
    server optimizer_3:3001 weight=1;

    keepalive 32;                     # pool de connexions persistantes
}

server {
    location /optimize {
        proxy_pass         http://optimizers;
        proxy_next_upstream error timeout;  # retry si un serveur est down
        proxy_connect_timeout 3s;
        proxy_read_timeout    15s;
    }
}
```

### Health checks du load balancer

```nginx
upstream optimizers {
    server optimizer_1:3001;
    server optimizer_2:3001;

    # Retirer un serveur du pool s'il Ã©choue 3 fois en 30s
    # Le remettre aprÃ¨s 1 succÃ¨s
}
```

---

<a name="discovery"></a>
## 5. Service Discovery â€” trouver les services

### Le problÃ¨me

Dans un systÃ¨me distribuÃ©, les services dÃ©marrent et s'arrÃªtent dynamiquement. On ne peut pas hardcoder des IPs.

```
HardcodÃ© : OPTIMIZER_URL=http://192.168.1.42:3001
  â†’ Que faire si l'optimizer est sur 192.168.1.43 aprÃ¨s un redÃ©marrage ?
  â†’ Que faire si on a 3 optimizers ?
```

### Solutions

**DNS-based (Docker Compose, notre cas actuel) :**
```yaml
# Docker Compose rÃ©sout "optimizer" automatiquement vers le bon conteneur
environment:
  - OPTIMIZER_URL=http://optimizer:3001
```

**Consul :**
```go
// Les services s'enregistrent dans Consul au dÃ©marrage
// Les clients interrogent Consul pour trouver les IPs actives
services, _ := consulClient.Health().Service("optimizer", "", true, nil)
optimizerURL := services[0].Service.Address
```

**Kubernetes (niveau supÃ©rieur) :**
```yaml
# Un Service Kubernetes = DNS stable + load balancing automatique
# optimizer-service â†’ plusieurs pods optimizer
apiVersion: v1
kind: Service
metadata:
  name: optimizer
spec:
  selector:
    app: optimizer  # correspond Ã  tous les pods avec ce label
  ports:
    - port: 3001
```

---

<a name="dlq"></a>
## 6. Dead Letter Queue â€” ne pas perdre les messages

### Le problÃ¨me actuel

```go
// âŒ Si un job Ã©choue trop de fois â†’ NACK â†’ requeue â†’ boucle infinie
msg.Nack(false, true)  // requeue=true
time.Sleep(10 * time.Second)
// â†’ ce job tourne en boucle pour toujours, consomme des ressources
```

**Poison pill** : un message qui fait toujours planter le consumer (image corrompue, format inconnu, bug dans le code). Sans DLQ, il bloque la queue pour toujours.

### Dead Letter Queue (DLQ)

```
Queue normale : watermark_retry
  â†“ aprÃ¨s N NACKs ou TTL dÃ©passÃ©
DLQ : watermark_failed
  â†’ stocke les messages problÃ©matiques
  â†’ peut Ãªtre analysÃ©e, rejouÃ©e manuellement, alertÃ©e
```

### Configurer RabbitMQ avec DLQ

```go
// DÃ©clarer la DLQ d'abord
amqpChan.QueueDeclare("watermark_failed", true, false, false, false, nil)

// DÃ©clarer la queue principale avec un lien vers la DLQ
args := amqp.Table{
    // Si un message est NACK sans requeue â†’ aller en DLQ
    "x-dead-letter-exchange":    "",
    "x-dead-letter-routing-key": "watermark_failed",

    // TTL : message expirÃ© aprÃ¨s 24h â†’ aller en DLQ
    "x-message-ttl": int64(24 * 60 * 60 * 1000),  // 24h en ms

    // Max retries : aprÃ¨s 5 NACKs â†’ aller en DLQ
    "x-delivery-limit": 5,
}
amqpChan.QueueDeclare("watermark_retry", true, false, false, false, args)
```

### Traitement avec compteur de tentatives

```go
func processRetryJob(msg amqp.Delivery, optimizerURL string) {
    // Compter les tentatives via le header "x-death"
    var attempts int32
    if deaths, ok := msg.Headers["x-death"].([]interface{}); ok {
        for _, d := range deaths {
            if death, ok := d.(amqp.Table); ok {
                if count, ok := death["count"].(int64); ok {
                    attempts += int32(count)
                }
            }
        }
    }

    log.Info().Int32("attempt", attempts).Msg("processing retry job")

    result, err := sendToOptimizer(...)
    if err != nil {
        if attempts >= 4 {
            // 5Ã¨me tentative â†’ laisser aller en DLQ (NACK sans requeue)
            log.Error().Int32("attempt", attempts).Msg("max retries exceeded â†’ DLQ")
            msg.Nack(false, false)  // false = ne pas requeue â†’ DLQ
            return
        }
        // Pas encore max â†’ requeue avec backoff
        wait := equalJitter(int(attempts))
        msg.Nack(false, true)
        time.Sleep(wait)
        return
    }

    msg.Ack(false)
}
```

### Worker pour monitorer la DLQ

```go
func dlqMonitor() {
    msgs, _ := amqpChan.Consume("watermark_failed", "dlq-monitor", false, false, false, false, nil)

    for msg := range msgs {
        var job RetryJob
        json.Unmarshal(msg.Body, &job)

        // Alerter (Slack, PagerDuty, email...)
        log.Error().
            Str("hash", job.Hash).
            Str("filename", job.Filename).
            Msg("job in DLQ â€” manual intervention required")

        // ACK pour vider la DLQ (ou stocker dans une DB pour analyse)
        msg.Ack(false)
    }
}
```

---

<a name="hashing"></a>
## 7. Consistent Hashing â€” distribuer sans tout casser

### Le problÃ¨me du sharding naÃ¯f

```
3 noeuds Redis :  hash(key) % 3 â†’ noeud 0, 1, ou 2

hash("photo_abc") % 3 = 1  â†’ noeud 1
hash("photo_xyz") % 3 = 0  â†’ noeud 0

On ajoute un 4Ã¨me noeud : hash(key) % 4

hash("photo_abc") % 4 = 3  â†’ noeud 3  â† CHANGÃ‰
hash("photo_xyz") % 4 = 0  â†’ noeud 0  â† identique

â†’ Presque toutes les clÃ©s changent de noeud
â†’ 100% de cache miss pendant plusieurs heures
â†’ TempÃªte de requÃªtes sur l'origine
```

### Consistent Hashing â€” l'anneau

```
Anneau de 0 Ã  2^32 (4 milliards de positions)

      0
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Noeud A (position 1000)       â”‚
    â”‚    â†—                            â†˜     â”‚
 4294967295                          1500   â”‚ â† clÃ© "photo_abc" (1400) â†’ Noeud A
    â”‚    â†–                            â†™    â”‚
    â”‚         Noeud B (position 2000)       â”‚
    â”‚    â†—                            â†˜     â”‚
    â”‚                                3000   â”‚ â† clÃ© "photo_xyz" (2800) â†’ Noeud B
    â”‚         Noeud C (position 3500)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RÃ¨gle : une clÃ© va au noeud dont la position est immÃ©diatement supÃ©rieure sur l'anneau
```

**Ajouter un noeud :** seules les clÃ©s entre le nouveau noeud et son prÃ©dÃ©cesseur migrent.

```
Avant (3 noeuds) : chaque noeud gÃ¨re ~33% des clÃ©s
Ajouter noeud D entre A et B : seules les clÃ©s de la portion Aâ†’D migrent (~16%)
â†’ 84% du cache reste valide
```

**Virtual nodes** : pour Ã©quilibrer la charge, chaque noeud physique occupe plusieurs positions sur l'anneau.

```
Noeud A physique â†’ virtual node A_1 (position 500), A_2 (1800), A_3 (3200)...
â†’ distribution plus uniforme mÃªme avec des noeuds de tailles diffÃ©rentes
```

### Redis Cluster â€” implÃ©mentation rÃ©elle

Redis Cluster utilise **16384 hash slots** (pas un anneau infini) pour sa version du consistent hashing :

```
hash_slot = CRC16(key) % 16384

Cluster Ã  3 noeuds :
  Noeud 1 : slots 0 Ã  5460
  Noeud 2 : slots 5461 Ã  10922
  Noeud 3 : slots 10923 Ã  16383

Ajouter un noeud 4 :
  DÃ©placer ~1/4 des slots de chaque noeud vers le noeud 4
  â†’ seulement ~25% des clÃ©s migrent
```

---

<a name="locks"></a>
## 8. Distributed Locks â€” synchronisation cross-services

### Le problÃ¨me

```
2 instances API reÃ§oivent la mÃªme image en mÃªme temps :
  Instance 1 : Redis MISS â†’ commence Ã  traiter
  Instance 2 : Redis MISS â†’ commence Ã  traiter (0.5ms plus tard)

â†’ 2 fois l'optimizer appelÃ© pour rien
â†’ 2 fois Redis.Set avec le mÃªme rÃ©sultat
â†’ Gaspillage de ressources
```

### Redlock â€” algorithme de verrou distribuÃ© Redis

```go
import "github.com/go-redsync/redsync/v4"

rs := redsync.New(pool)

// AcquÃ©rir un verrou sur la clÃ© de cache
mutex := rs.NewMutex("lock:"+cacheKey,
    redsync.WithExpiry(30*time.Second),   // verrou expire aprÃ¨s 30s (Ã©vite les deadlocks)
    redsync.WithTries(3),                 // 3 tentatives
)

if err := mutex.LockContext(ctx); err != nil {
    // Une autre instance traite dÃ©jÃ  cette image
    // Attendre un peu et rÃ©essayer (elle aura peut-Ãªtre fini)
    time.Sleep(100 * time.Millisecond)
    cached, _, hit := getFromCache(ctx, cacheKey)
    if hit {
        return sendResponse(w, r, cached), nil
    }
}
defer mutex.Unlock()

// On est le seul Ã  traiter cette image maintenant
result, err := sendToOptimizer(...)
```

**Note :** `singleflight` (section Cache avancÃ© dans ROADMAP.md) est plus simple et suffisant si on n'a qu'une seule instance API. Redlock est nÃ©cessaire pour plusieurs instances.

---

<a name="saga"></a>
## 9. Saga Pattern â€” transactions distribuÃ©es

### Le problÃ¨me

Une transaction qui touche plusieurs services ne peut pas utiliser un ACID transaction classique :

```
Upload image :
  1. Sauvegarder original â†’ MinIO
  2. Appliquer watermark  â†’ Optimizer
  3. Stocker rÃ©sultat     â†’ Redis
  4. Enregistrer metadata â†’ PostgreSQL (si on en avait un)

Si l'Ã©tape 4 Ã©choue : comment annuler les Ã©tapes 1-3 ?
â†’ MinIO et Redis n'ont pas de "ROLLBACK"
```

### Saga â€” une sÃ©quence de transactions locales

```
Saga choreography (via Ã©vÃ©nements) :

ImageUploaded (MinIO OK)
  â†’ WatermarkRequested (Optimizer)
    â†’ WatermarkCompleted (Redis OK)
      â†’ MetadataStored (succÃ¨s total)

Si MetadataStored Ã©choue :
  â†’ MetadataFailed
    â†’ ResultDeleted (Redis) â† transaction compensatoire
      â†’ OriginalDeleted (MinIO) â† transaction compensatoire
```

**Transaction compensatoire** = l'inverse logique d'une transaction. Ce n'est pas un ROLLBACK (les changements ont eu lieu), c'est une nouvelle opÃ©ration qui annule l'effet.

### ImplÃ©mentation simple avec RabbitMQ

```go
// Chaque Ã©tape publie un Ã©vÃ©nement de succÃ¨s ou d'Ã©chec
type ImageEvent struct {
    Type     string `json:"type"`     // "uploaded", "watermarked", "stored", "failed"
    Hash     string `json:"hash"`
    Step     string `json:"step"`     // "minio", "optimizer", "redis"
    Error    string `json:"error,omitempty"`
}

// Si Redis.Set Ã©choue â†’ publier un Ã©vÃ©nement de compensation
if err := redisClient.Set(ctx, cacheKey, result, 24*time.Hour).Err(); err != nil {
    publishEvent(ImageEvent{
        Type:  "failed",
        Hash:  cacheKey,
        Step:  "redis",
        Error: err.Error(),
    })
    // Un compensating service Ã©coute et nettoie MinIO si nÃ©cessaire
}
```

---

<a name="cqrs"></a>
## 10. CQRS â€” sÃ©parer lectures et Ã©critures

**CQRS** = Command Query Responsibility Segregation.

**Principe :** sÃ©parer les opÃ©rations qui **modifient** l'Ã©tat (Commands) des opÃ©rations qui **lisent** l'Ã©tat (Queries).

```
Sans CQRS (actuel) :
  POST /upload  â†’ lit le cache ET Ã©crit le rÃ©sultat
  GET /image    â†’ lit le cache
  GET /status   â†’ lit le cache
  â†’ mÃªme modÃ¨le pour tout

Avec CQRS :
  Commands : POST /upload â†’ writes vers Redis, MinIO, RabbitMQ
  Queries  : GET /image, GET /status â†’ reads depuis Redis (ou un replica)

â†’ Les lectures peuvent utiliser un cache / replica diffÃ©rent
â†’ Les Ã©critures peuvent Ãªtre async (RabbitMQ)
â†’ On peut scaler lectures et Ã©critures indÃ©pendamment
```

### Sur NWS Watermark

```
Command side (Ã©criture) :
  POST /upload
  â†’ RabbitMQ pour le processing async
  â†’ MinIO pour le stockage permanent
  â†’ Redis pour le cache du rÃ©sultat

Query side (lecture) :
  GET /image/{hash}  â†’ Redis (cache L1 ou L2)
  GET /status/{hash} â†’ Redis
  â†’ pourrait pointer vers un Redis replica read-only
  â†’ lectures Ã  0 impact sur le processing
```

---

<a name="event-sourcing"></a>
## 11. Event Sourcing â€” stocker les Ã©vÃ©nements

### L'idÃ©e centrale

**Au lieu de stocker l'Ã©tat final**, on stocke tous les Ã©vÃ©nements qui ont conduit Ã  cet Ã©tat.

```
Base de donnÃ©es classique :
  images table : {hash: "abc", status: "done", wm_text: "NWS", created_at: ...}
  â†’ snapshot de l'Ã©tat actuel

Event Sourcing :
  events stream : [
    {type: "ImageUploaded",   hash: "abc", filename: "photo.jpg", ts: T1},
    {type: "WatermarkApplied", hash: "abc", wm_text: "NWS", wm_position: "br", ts: T2},
    {type: "ResultCached",    hash: "abc", size: 245187, ts: T3},
    {type: "ImageServed",     hash: "abc", client_ip: "...", ts: T4},
  ]
  â†’ Ã©tat actuel = rejouer tous les Ã©vÃ©nements
```

### Avantages

1. **Audit log complet** â€” on sait exactement ce qui s'est passÃ© et quand
2. **Time-travel debugging** â€” rejouer jusqu'Ã  T2 pour voir l'Ã©tat Ã  ce moment
3. **Projections multiples** â€” construire diffÃ©rentes vues depuis les mÃªmes Ã©vÃ©nements
4. **Replay** â€” si le processing a eu un bug â†’ rejouer tous les Ã©vÃ©nements avec le fix

### ImplÃ©mentation avec Kafka (le backend naturel pour l'event sourcing)

```go
// Produire un Ã©vÃ©nement
producer.Produce(&kafka.Message{
    TopicPartition: kafka.TopicPartition{Topic: &"watermark-events"},
    Value: json.Marshal(ImageEvent{
        Type:       "ImageUploaded",
        Hash:       cacheKey,
        Filename:   header.Filename,
        Timestamp:  time.Now(),
    }),
})

// Consumer qui construit une projection "stats par heure"
for msg := range messages {
    var event ImageEvent
    json.Unmarshal(msg.Value, &event)

    switch event.Type {
    case "ResultCached":
        statsDB.IncrBy("uploads:"+event.Timestamp.Format("2006-01-02-15"), 1)
    case "WatermarkApplied":
        statsDB.HIncrBy("positions", event.WmPosition, 1)
    }
}
```

---

<a name="watermark"></a>
## 12. Utilisation dans NWS Watermark

### Ce qui est dÃ©jÃ  distribuÃ© âœ…

```
âœ… API stateless â†’ scalable horizontalement
âœ… Optimizer stateless â†’ scalable horizontalement
âœ… Redis â†’ cache partagÃ© entre plusieurs instances API
âœ… MinIO â†’ stockage partagÃ©
âœ… RabbitMQ â†’ queue partagÃ©e pour les retries
```

### Ce qui manque pour passer en prod âŒ

```
âŒ Load Balancer (nginx) devant l'optimizer
âŒ Dead Letter Queue pour les jobs qui bouclent
âŒ Health checks (requis pour le LB)
âŒ Graceful shutdown (requis pour le rolling deploy)
âŒ Distributed lock (si > 1 instance API avec mÃªme image simultanÃ©e)
âŒ Redis Cluster (si le cache dÃ©passe la RAM d'un seul serveur)
```

### Ordre d'implÃ©mentation pour scaler

```
Phase 1 â€” PrÃªt Ã  scaler :
  1. Health checks + graceful shutdown
  2. Dead Letter Queue RabbitMQ
  3. Monitoring (Prometheus + Grafana)

Phase 2 â€” Scaling horizontal :
  4. nginx load balancer devant l'optimizer
  5. docker compose scale optimizer=3
  6. Tester avec k6 load test

Phase 3 â€” Haute disponibilitÃ© :
  7. Redis Sentinel (failover automatique)
  8. MinIO multi-noeuds (erasure coding)
  9. RabbitMQ cluster (mirrored queues)
```

---

<a name="rÃ©sumÃ©"></a>
## 13. RÃ©sumÃ©

### Les patterns distribuÃ©s en un coup d'Å“il

| Pattern | ProblÃ¨me rÃ©solu | Quand l'utiliser |
|---|---|---|
| Load Balancing | Saturation d'un seul serveur | DÃ¨s qu'on a > 1 instance |
| Service Discovery | IPs qui changent dynamiquement | Kubernetes, cloud |
| Dead Letter Queue | Poison pills, jobs qui bouclent | Toujours avec RabbitMQ |
| Consistent Hashing | Migration de cache coÃ»teuse | Redis Cluster, sharding |
| Distributed Lock | Race conditions cross-instances | Multiple API instances |
| Saga | Transactions multi-services | Workflows complexes |
| CQRS | Lecture/Ã©criture diffÃ©rents besoins | Scale lecture >> Ã©criture |
| Event Sourcing | Audit, replay, debugging | SystÃ¨mes financiers, compliance |

### Le thÃ©orÃ¨me CAP en pratique

```
DonnÃ©es financiÃ¨res     â†’ CP  (cohÃ©rence avant disponibilitÃ©)
Cache images            â†’ AP  (disponibilitÃ© avant cohÃ©rence stricte)
Queue de messages       â†’ AP  (on peut avoir des doublons, c'est OK)
```

### RÃ¨gles Ã  retenir

1. **Commencer simple** â€” ne pas distribuer ce qui peut Ãªtre centralisÃ©
2. **Stateless d'abord** â€” un service stateless se scale horizontalement sans friction
3. **Toujours une DLQ** â€” ne jamais laisser des messages en boucle infinie
4. **CAP conscious** â€” choisir dÃ©libÃ©rÃ©ment CP ou AP selon le besoin
5. **Mesurer avant de distribuer** â€” un seul serveur bien optimisÃ© peut aller trÃ¨s loin
