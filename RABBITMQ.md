# Cours : RabbitMQ
## Messagerie asynchrone et architecture Ã©vÃ©nementielle

---

## ğŸ“‹ Table des matiÃ¨res

1. [C'est quoi RabbitMQ ?](#intro)
2. [Les concepts fondamentaux](#concepts)
3. [Les Exchanges â€” Routage des messages](#exchanges)
4. [Les Queues â€” File d'attente](#queues)
5. [Les Bindings â€” Connexions entre exchanges et queues](#bindings)
6. [Acknowledgements â€” AccusÃ©s de rÃ©ception](#ack)
7. [Publisher Confirms â€” Garantie cÃ´tÃ© producteur](#confirms)
8. [Dead Letter Queue â€” Gestion des erreurs](#dlq)
9. [DurabilitÃ© et persistance](#durabilite)
10. [Prefetch et QoS â€” ContrÃ´le de charge](#prefetch)
11. [RÃ©sumÃ© et cas d'usage](#rÃ©sumÃ©)
12. [ImplÃ©mentation dans NWS Watermark â€” Option B](#implementation)

---

<a name="intro"></a>
## 1. C'est quoi RabbitMQ ?

RabbitMQ est un **message broker** â€” un intermÃ©diaire qui reÃ§oit des messages d'un service et les distribue Ã  d'autres.

**Analogie :** C'est comme La Poste.
- Le **producteur** = celui qui envoie une lettre
- RabbitMQ = La Poste (trie et achemine)
- Le **consommateur** = celui qui reÃ§oit la lettre

```
Producteur â”€â”€â–º RabbitMQ â”€â”€â–º Consommateur
(envoie)       (stocke)      (traite)
```

---

### ğŸ¯ Le problÃ¨me sans RabbitMQ

Sans message broker, les services se parlent **directement** :

```
Service A â”€â”€â–º POST /api â”€â”€â–º Service B
```

**ProblÃ¨mes :**
- Si B est down â†’ A reÃ§oit une erreur, le message est perdu
- Si B est lent â†’ A attend bloquÃ©
- Si 1000 requÃªtes arrivent â†’ B est submergÃ©

---

### âœ… La solution avec RabbitMQ

```
Service A â”€â”€â–º RabbitMQ â”€â”€â–º Service B
              (stocke si B est down)
              (rÃ©gule le dÃ©bit)
              (redistribue Ã  plusieurs B)
```

**Avantages :**
- **DÃ©couplage** : A et B ne se connaissent pas
- **RÃ©silience** : si B est down, les messages attendent dans la queue
- **ScalabilitÃ©** : on peut ajouter plusieurs instances de B
- **DÃ©bit** : RabbitMQ absorbe les pics de charge

---

### ğŸ†š RabbitMQ vs Redis (pub/sub)

| CritÃ¨re | RabbitMQ | Redis Pub/Sub |
|---------|----------|---------------|
| Persistance des messages | âœ… Oui | âŒ Non (fire & forget) |
| AccusÃ© de rÃ©ception | âœ… Oui (ACK) | âŒ Non |
| Routage avancÃ© | âœ… Exchanges | âŒ Non |
| Rejeu des messages | âœ… Oui | âŒ Non |
| Use case | TÃ¢ches critiques | Notifications temps rÃ©el |

---

<a name="concepts"></a>
## 2. Les concepts fondamentaux

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    publish     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   route    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producteur â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Exchange â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Queue   â”‚
â”‚ (Publisher) â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚ consume
                                                             â–¼
                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚  Consommateur   â”‚
                                                    â”‚  (Consumer)     â”‚
                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Ã‰lÃ©ment | RÃ´le |
|---------|------|
| **Producer** | Envoie des messages Ã  un exchange |
| **Exchange** | ReÃ§oit les messages et les route vers les queues selon des rÃ¨gles |
| **Queue** | Stocke les messages en attendant qu'un consommateur les traite |
| **Consumer** | Lit et traite les messages depuis une queue |
| **Binding** | RÃ¨gle qui connecte un exchange Ã  une queue |
| **Routing Key** | Ã‰tiquette sur le message utilisÃ©e par l'exchange pour router |

---

### ğŸ“¦ Le message

Un message contient :
- **Body** : le contenu (JSON, bytes, texte...)
- **Headers** : mÃ©tadonnÃ©es (content-type, priority...)
- **Routing key** : Ã©tiquette pour le routage
- **Properties** : delivery_mode, expiration, reply-to...

```json
{
  "routing_key": "order.created",
  "body": { "order_id": 42, "user": "alice", "total": 99.90 },
  "properties": {
    "content_type": "application/json",
    "delivery_mode": 2
  }
}
```

---

<a name="exchanges"></a>
## 3. Les Exchanges â€” Routage des messages

L'exchange est le **chef d'orchestre** : il reÃ§oit chaque message du producteur et dÃ©cide dans quelle(s) queue(s) l'envoyer.

Il existe 4 types d'exchanges.

> Les exemples utilisent `github.com/rabbitmq/amqp091-go`, le client officiel Go pour RabbitMQ.

```go
import amqp "github.com/rabbitmq/amqp091-go"

conn, _ := amqp.Dial("amqp://guest:guest@localhost:5672/")
defer conn.Close()

ch, _ := conn.Channel()
defer ch.Close()
```

---

### 3a. Direct Exchange

**RÃ¨gle :** Le message est envoyÃ© dans la queue dont la **routing key correspond exactement**.

```
Producteur envoie routing_key="order.paid"
                        â”‚
                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                   â”‚ Exchange  â”‚
                   â”‚ (direct) â”‚
                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    "order.paid"   "order.new"   "order.cancelled"
          â–¼               â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Queue    â”‚   â”‚ Queue    â”‚   â”‚ Queue        â”‚
   â”‚ payment  â”‚   â”‚ notify   â”‚   â”‚ refund       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        âœ…               âŒ               âŒ
```

**Use case :** Traitement de tÃ¢ches spÃ©cifiques par type.

```go
// DÃ©clarer l'exchange
ch.ExchangeDeclare("orders", "direct", true, false, false, false, nil)

// Binding : queue "payment" reÃ§oit les messages "order.paid"
ch.QueueDeclare("payment", true, false, false, false, nil)
ch.QueueBind("payment", "order.paid", "orders", false, nil)

// Producteur : publier avec routing key exacte
body, _ := json.Marshal(order)
ch.Publish("orders", "order.paid", false, false, amqp.Publishing{
    ContentType: "application/json",
    Body:        body,
})
```

---

### 3b. Fanout Exchange

**RÃ¨gle :** Le message est envoyÃ© dans **toutes les queues** liÃ©es, peu importe la routing key.

```
Producteur envoie un message
                â”‚
           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
           â”‚ Exchange  â”‚
           â”‚ (fanout) â”‚
           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ emails â”‚ â”‚ logs   â”‚ â”‚ analyticsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    âœ…          âœ…          âœ…
```

**Use case :** Notifications broadcast â€” un Ã©vÃ©nement doit dÃ©clencher plusieurs actions en parallÃ¨le.

```go
ch.ExchangeDeclare("notifications", "fanout", true, false, false, false, nil)

// Routing key ignorÃ©e en fanout â€” on passe une chaÃ®ne vide
ch.Publish("notifications", "", false, false, amqp.Publishing{
    ContentType: "application/json",
    Body:        body,
})
```

**Exemple :** Un utilisateur s'inscrit â†’ envoyer un email de bienvenue + crÃ©er un log + mettre Ã  jour les stats, tout en mÃªme temps.

---

### 3c. Topic Exchange

**RÃ¨gle :** Routage par **pattern avec wildcards** sur la routing key.

```
Wildcards :
  *  = exactement un mot
  #  = zÃ©ro ou plusieurs mots
```

```
Routing keys envoyÃ©es :
  "log.error.database"
  "log.warn.api"
  "log.info.user"

Bindings :
  "log.error.*"  â”€â”€â–º Queue : alertes critiques
  "log.#"        â”€â”€â–º Queue : tous les logs
  "*.warn.*"     â”€â”€â–º Queue : avertissements
```

```
"log.error.database"
        â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚  Exchange  â”‚
   â”‚  (topic)  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â† correspond Ã  "log.error.*" âœ…
   â”‚ alertes       â”‚  â† correspond Ã  "log.#"       âœ…
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â† correspond Ã  "*.warn.*"    âŒ
   â”‚ avertissementsâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Use case :** Logging centralisÃ© avec filtrage par niveau et service.

```go
ch.ExchangeDeclare("logs", "topic", true, false, false, false, nil)

ch.QueueBind("alertes",   "log.error.*", "logs", false, nil)
ch.QueueBind("tous_logs", "log.#",       "logs", false, nil)
ch.QueueBind("warns",     "*.warn.*",    "logs", false, nil)

// Publier un log d'erreur
ch.Publish("logs", "log.error.database", false, false, amqp.Publishing{
    Body: []byte(`{"msg":"connexion DB perdue"}`),
})
// â†’ reÃ§u par "alertes" et "tous_logs", pas par "warns"
```

---

### 3d. Headers Exchange

**RÃ¨gle :** Routage basÃ© sur les **headers du message** (pas la routing key).

```go
ch.ExchangeDeclare("reports", "headers", true, false, false, false, nil)

// Binding : queue "pdf-eu" reÃ§oit si format=pdf ET region=eu
ch.QueueBind("pdf-eu", "", "reports", false, amqp.Table{
    "x-match": "all",   // "all" = tous les headers doivent correspondre
    "format":  "pdf",   // "any" = au moins un
    "region":  "eu",
})

// Producteur
ch.Publish("reports", "", false, false, amqp.Publishing{
    Headers:     amqp.Table{"format": "pdf", "region": "eu"},
    ContentType: "application/octet-stream",
    Body:        reportData,
})
```

**Use case :** Routage complexe basÃ© sur plusieurs critÃ¨res mÃ©tier.

---

### ğŸ“Š Comparaison des exchanges

| Type | Routing | Use case typique |
|------|---------|-----------------|
| **Direct** | ClÃ© exacte | TÃ¢ches par type (email, SMS, push) |
| **Fanout** | Tout le monde | Notifications broadcast, invalidation de cache |
| **Topic** | Pattern wildcard | Logs, Ã©vÃ©nements hiÃ©rarchiques |
| **Headers** | Attributs mÃ©tier | Routage multi-critÃ¨res |

---

<a name="queues"></a>
## 4. Les Queues â€” File d'attente

La queue est le **buffer** entre le producteur et le consommateur. Les messages s'y accumulent en attendant d'Ãªtre traitÃ©s.

```
Queue "orders" :
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ M5  â”‚ M4  â”‚ M3  â”‚ M2  â”‚ M1  â”‚  â† Messages en attente
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
                              â–²                    â–¼
                           Producteur          Consommateur
                           (ajoute Ã  la fin)   (prend au dÃ©but)
```

**FIFO :** First In, First Out â€” le premier message arrivÃ© est le premier traitÃ©.

---

### DÃ©clarer une queue

```go
q, err := ch.QueueDeclare(
    "orders", // nom
    true,     // durable : survit au redÃ©marrage de RabbitMQ
    false,    // auto-delete : supprime si plus aucun consommateur
    false,    // exclusive : rÃ©servÃ©e Ã  cette connexion uniquement
    false,    // no-wait
    nil,      // arguments
)
```

---

### Plusieurs consommateurs sur une queue

Si plusieurs instances du mÃªme service Ã©coutent la mÃªme queue, RabbitMQ distribue les messages en **round-robin** :

```
Queue "orders" : [M1, M2, M3, M4, M5, M6]

Consommateur A â”€â”€â–º reÃ§oit M1, M3, M5
Consommateur B â”€â”€â–º reÃ§oit M2, M4, M6
```

**C'est le mÃ©canisme de scalabilitÃ© horizontale :** pour traiter plus vite, on ajoute des consommateurs.

---

<a name="bindings"></a>
## 5. Les Bindings â€” Connexions

Un binding est la **rÃ¨gle** qui relie un exchange Ã  une queue. Sans binding, les messages arrivent dans l'exchange mais ne vont nulle part.

```go
err := ch.QueueBind(
    "payment-service", // queue
    "order.paid",      // routing key
    "orders",          // exchange
    false,
    nil,
)
```

**Analogie :** L'exchange est un carrefour, le binding est le panneau de direction.

---

<a name="ack"></a>
## 6. Acknowledgements â€” AccusÃ©s de rÃ©ception

### ğŸ¯ Le problÃ¨me

Sans ACK, si un consommateur reÃ§oit un message et crashe en plein traitement, le message est **perdu**.

```
Queue â†’ Consommateur reÃ§oit message â†’ CRASH â†’ message perdu ğŸ’€
```

---

### âœ… La solution : ACK manuel

Le message reste dans la queue jusqu'Ã  ce que le consommateur envoie un ACK.

```
Queue â”€â”€â–º Consommateur
          â”‚ traitement...
          â”‚ traitement...
          â”œâ”€â”€ succÃ¨s â†’ ch.Ack()   â†’ message supprimÃ© de la queue âœ…
          â””â”€â”€ Ã©chec  â†’ ch.Nack()  â†’ message remis dans la queue ğŸ”„
```

```go
msgs, _ := ch.Consume(
    "orders", // queue
    "",       // consumer tag
    false,    // auto-ack : false = ACK manuel âœ…
    false, false, false, nil,
)

for msg := range msgs {
    err := processOrder(msg.Body)
    if err == nil {
        msg.Ack(false)             // âœ… succÃ¨s â†’ supprime le message
    } else {
        msg.Nack(false, true)      // âŒ Ã©chec â†’ requeue=true : remet dans la queue
    }
}
```

---

### Les 3 rÃ©ponses possibles

| RÃ©ponse | MÃ©thode Go | Effet |
|---------|------------|-------|
| SuccÃ¨s | `msg.Ack(false)` | Message supprimÃ© de la queue |
| Ã‰chec + retry | `msg.Nack(false, true)` | Message remis en tÃªte de queue |
| Ã‰chec dÃ©finitif | `msg.Nack(false, false)` | Message envoyÃ© en Dead Letter Queue |

---

### Auto-ACK vs Manuel

```go
// âŒ Auto-ACK : message supprimÃ© dÃ¨s rÃ©ception (dangereux)
ch.Consume("orders", "", true, false, false, false, nil)

// âœ… ACK manuel : message supprimÃ© seulement aprÃ¨s traitement rÃ©ussi
ch.Consume("orders", "", false, false, false, false, nil)
```

**Toujours utiliser l'ACK manuel pour les tÃ¢ches critiques.**

---

<a name="confirms"></a>
## 7. Publisher Confirms â€” Garantie cÃ´tÃ© producteur

### ğŸ¯ Le problÃ¨me

Par dÃ©faut, `Publish` ne confirme pas que le message a bien Ã©tÃ© reÃ§u par RabbitMQ. En cas de rÃ©seau instable, le message peut Ãªtre perdu **avant mÃªme d'entrer dans la queue**.

---

### âœ… La solution : Publisher Confirms

RabbitMQ envoie un ACK/NACK au **producteur** pour confirmer la rÃ©ception.

```go
// Activer le mode confirms
if err := ch.Confirm(false); err != nil {
    log.Fatal("Impossible d'activer les confirms")
}

// Canal de confirmation
confirms := ch.NotifyPublish(make(chan amqp.Confirmation, 1))

body, _ := json.Marshal(order)
ch.Publish("orders", "order.paid", true, false, amqp.Publishing{
    DeliveryMode: amqp.Persistent,
    ContentType:  "application/json",
    Body:         body,
})

// Attendre la confirmation de RabbitMQ
confirm := <-confirms
if confirm.Ack {
    log.Println("âœ… Message confirmÃ© par RabbitMQ")
} else {
    log.Println("âŒ RabbitMQ a refusÃ© le message (NACK)")
}
```

---

### Garanties de livraison

| Mode | Garantie | Performance |
|------|----------|-------------|
| Fire & forget | Aucune | Maximum |
| Publisher Confirms | ReÃ§u par RabbitMQ | Bonne |
| Confirms + ACK consommateur | TraitÃ© avec succÃ¨s | Plus lente |

---

<a name="dlq"></a>
## 8. Dead Letter Queue â€” Gestion des erreurs

### ğŸ¯ Le problÃ¨me

Un message peut Ã©chouer plusieurs fois. Si on le remet en queue indÃ©finiment, il bloque les autres messages et le consommateur tourne en boucle.

```
Message M â†’ Ã©chec â†’ requeue â†’ Ã©chec â†’ requeue â†’ ... â™¾ï¸ boucle infinie
```

---

### âœ… La solution : Dead Letter Queue (DLQ)

AprÃ¨s N Ã©checs, le message est envoyÃ© dans une queue spÃ©ciale pour analyse.

```
Queue normale â”€â”€â–º Consommateur
                  â”‚
                  â””â”€â”€ Nack(requeue=false)
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Dead Letter    â”‚
                  â”‚  Queue (DLQ)    â”‚  â† messages problÃ©matiques
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  Analyse / alerte / replay manuel
```

```go
// DÃ©clarer la DLQ
ch.QueueDeclare("orders.dlq", true, false, false, false, nil)

// DÃ©clarer la queue normale avec redirection vers la DLQ
ch.QueueDeclare("orders", true, false, false, false, amqp.Table{
    "x-dead-letter-exchange":    "",            // exchange par dÃ©faut
    "x-dead-letter-routing-key": "orders.dlq", // queue de destination
    "x-message-ttl":             int32(30000),  // expire aprÃ¨s 30s
    "x-max-length":              int32(10000),  // max 10 000 messages
})

// Dans le consommateur
for msg := range msgs {
    if err := processOrder(msg.Body); err != nil {
        // requeue=false â†’ part automatiquement en DLQ
        msg.Nack(false, false)
    } else {
        msg.Ack(false)
    }
}
```

---

### Retry avec dÃ©lai (pattern Retry Queue)

Pour rÃ©essayer avec un dÃ©lai exponentiel :

```
Queue normale â”€â”€â–º Ã©chec â”€â”€â–º Queue retry (TTL 5s) â”€â”€â–º Queue normale
                                                      â”€â”€â–º Ã©chec â”€â”€â–º Queue retry (TTL 30s)
                                                                     â”€â”€â–º ...
                                                                     â”€â”€â–º DLQ (aprÃ¨s 3 tentatives)
```

---

<a name="durabilite"></a>
## 9. DurabilitÃ© et persistance

### ğŸ¯ Le problÃ¨me

Par dÃ©faut, si RabbitMQ redÃ©marre, **toutes les queues et messages en mÃ©moire sont perdus**.

---

### âœ… 3 niveaux de durabilitÃ©

#### Niveau 1 : Queue durable

La queue **survit au redÃ©marrage** de RabbitMQ (la dÃ©finition est sauvegardÃ©e sur disque).

```go
ch.QueueDeclare("orders", true, false, false, false, nil)
//                         ^^^^
//                         durable = true âœ…
```

#### Niveau 2 : Message persistant

Les messages sont **Ã©crits sur disque** (pas seulement en RAM).

```go
ch.Publish("orders", "order.paid", false, false, amqp.Publishing{
    DeliveryMode: amqp.Persistent, // 1 = RAM, 2 (Persistent) = disque âœ…
    ContentType:  "application/json",
    Body:         body,
})
```

#### Niveau 3 : Queue durable + Message persistant = ZÃ©ro perte

```
Queue durable + DeliveryMode=Persistent
â†’ Si RabbitMQ crashe et redÃ©marre :
  â†’ La queue est recrÃ©Ã©e âœ…
  â†’ Les messages sont relus depuis le disque âœ…
  â†’ Le traitement reprend lÃ  oÃ¹ il en Ã©tait âœ…
```

---

### ğŸ“Š Comparaison des modes

| Queue | Message | Survit au redÃ©marrage | Performance |
|-------|---------|----------------------|-------------|
| Non durable | Transient | âŒ Tout perdu | Maximum |
| Durable | Transient | Queue OK, messages perdus | Bonne |
| Durable | Persistent | âœ… Tout survit | Plus lente |

---

<a name="prefetch"></a>
## 10. Prefetch et QoS â€” ContrÃ´le de charge

### ğŸ¯ Le problÃ¨me

Par dÃ©faut, RabbitMQ envoie **tous les messages disponibles** Ã  un consommateur dÃ¨s qu'il se connecte.

```
Queue : [M1, M2, M3, ..., M1000]

Consommateur A (rapide) â”€â”€â–º reÃ§oit M1...M500 en mÃ©moire, traite M1
Consommateur B (lent)   â”€â”€â–º reÃ§oit M501...M1000 en mÃ©moire, traite M501
```

**ProblÃ¨me :** Si B est lent, les 500 messages sont bloquÃ©s en mÃ©moire et attendent.

---

### âœ… La solution : Prefetch Count

On limite le nombre de messages non-ACKÃ©s qu'un consommateur peut avoir en mÃªme temps.

```go
// RabbitMQ n'envoie le message suivant qu'aprÃ¨s rÃ©ception de l'ACK du prÃ©cÃ©dent
ch.Qos(
    1,     // prefetch count
    0,     // prefetch size (0 = illimitÃ©)
    false, // global (false = par consommateur)
)
```

```
Queue : [M1, M2, M3, M4, M5, M6]
prefetch_count=1

Consommateur A (rapide) :
  â†’ reÃ§oit M1 â†’ traite (rapide) â†’ Ack â†’ reÃ§oit M3 â†’ traite â†’ Ack â†’ reÃ§oit M5...

Consommateur B (lent) :
  â†’ reÃ§oit M2 â†’ traite (lent)... â†’ Ack â†’ reÃ§oit M4 â†’ traite...

RÃ©sultat : A fait plus de travail car il Ack plus vite âœ…
```

---

### Prefetch Count : quelle valeur choisir ?

| Valeur | Comportement | Use case |
|--------|-------------|----------|
| `0` | IllimitÃ© (dÃ©faut) | âŒ Ne jamais utiliser en prod |
| `1` | 1 message Ã  la fois | TÃ¢ches longues et lourdes |
| `10-50` | Buffer raisonnable | TÃ¢ches rapides |
| `100+` | Gros buffer | TÃ¢ches trÃ¨s rapides, haut dÃ©bit |

```go
// TÃ¢che lourde (traitement image, ML...) â†’ 1
ch.Qos(1, 0, false)

// TÃ¢che lÃ©gÃ¨re (log, email...) â†’ 20
ch.Qos(20, 0, false)
```

---

<a name="rÃ©sumÃ©"></a>
## 11. ğŸ“Š RÃ©sumÃ© et cas d'usage

### Les exchanges en un coup d'Å“il

```
Direct  â†’ 1 routing key exacte  â†’ 1 queue
Fanout  â†’ ignore routing key    â†’ toutes les queues
Topic   â†’ pattern "log.*.error" â†’ queues filtrÃ©es
Headers â†’ attributs du message  â†’ queues filtrÃ©es
```

---

### Cas d'usage classiques

| Cas d'usage | Exchange | Pattern |
|-------------|----------|---------|
| Email de confirmation commande | Direct | `order.confirmed` â†’ queue email |
| Notification multi-canal | Fanout | 1 event â†’ email + SMS + push |
| Logging centralisÃ© | Topic | `log.error.*` â†’ alertes, `log.#` â†’ Elasticsearch |
| Traitement de fichiers | Direct | upload â†’ queue processing â†’ queue done |
| Workflow e-commerce | Topic | `order.#` â†’ analytics, `order.paid` â†’ payment |

---

### Exemple complet en Go

```go
package main

import (
    "encoding/json"
    "log"

    amqp "github.com/rabbitmq/amqp091-go"
)

func main() {
    conn, _ := amqp.Dial("amqp://guest:guest@localhost:5672/")
    defer conn.Close()
    ch, _ := conn.Channel()
    defer ch.Close()

    // Exchange topic
    ch.ExchangeDeclare("orders", "topic", true, false, false, false, nil)

    // Queues
    ch.QueueDeclare("payment",   true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "",
        "x-dead-letter-routing-key": "payment.dlq",
    })
    ch.QueueDeclare("analytics", true, false, false, false, nil)
    ch.QueueDeclare("payment.dlq", true, false, false, false, nil)

    // Bindings
    ch.QueueBind("payment",   "order.paid", "orders", false, nil)
    ch.QueueBind("analytics", "order.#",    "orders", false, nil)

    // Prefetch
    ch.Qos(5, 0, false)

    // Consommateur
    msgs, _ := ch.Consume("payment", "", false, false, false, false, nil)

    for msg := range msgs {
        var order map[string]any
        json.Unmarshal(msg.Body, &order)

        if err := processPayment(order); err != nil {
            log.Printf("âŒ Ã‰chec : %v â†’ DLQ", err)
            msg.Nack(false, false) // â†’ part en DLQ
        } else {
            log.Printf("âœ… Paiement traitÃ©")
            msg.Ack(false)
        }
    }
}

func processPayment(order map[string]any) error {
    // traitement...
    return nil
}
```

---

### Architecture complÃ¨te

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producteur  â”‚
â”‚  (API REST)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Publish("order.paid")
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Exchange   â”‚ type: topic
â”‚   "orders"   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                              â”‚
  â–¼ "order.paid"                 â–¼ "order.#"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Queue        â”‚        â”‚ Queue            â”‚
â”‚ "payment"    â”‚        â”‚ "analytics"      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                   â”‚
  â–¼ prefetch=5        â–¼ prefetch=5
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 1 â”‚     â”‚ Worker 2 â”‚   â† scalabilitÃ© horizontale
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Nack (Ã©chec)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ payment.dlq  â”‚  â† Dead Letter Queue
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Concepts clÃ©s Ã  retenir

#### 1. **DÃ©couplage**
Le producteur ne connaÃ®t pas les consommateurs. Il publie dans un exchange, c'est tout.

#### 2. **DurabilitÃ© = Queue durable + DeliveryMode Persistent**
Sans ces deux options, les messages peuvent Ãªtre perdus au redÃ©marrage.

#### 3. **ACK manuel toujours**
Ne jamais utiliser `auto_ack=true`. Le message doit rester en queue jusqu'Ã  confirmation du traitement.

#### 4. **Prefetch = protection contre la surcharge**
Sans `ch.Qos()`, un consommateur lent peut recevoir tous les messages et les bloquer.

#### 5. **DLQ = filet de sÃ©curitÃ©**
Les messages qui Ã©chouent rÃ©pÃ©titivement doivent aller en DLQ pour analyse, pas boucler indÃ©finiment.

---

<a name="implementation"></a>
## 12. ImplÃ©mentation dans NWS Watermark â€” Option B

### ğŸ¯ Le problÃ¨me

L'optimizer est un microservice HTTP qui peut Ãªtre temporairement indisponible (dÃ©ploiement, crash, surcharge). Dans ce cas, l'image uploadÃ©e ne doit pas Ãªtre perdue et le traitement doit reprendre automatiquement dÃ¨s que le service est rÃ©tabli.

---

### ğŸ—ï¸ Choix architectural : Option B (HTTP sync + RabbitMQ fallback)

Deux architectures Ã©taient possibles :

| | Option A | Option B âœ… |
|---|---|---|
| Canal principal | RabbitMQ (toujours async) | HTTP direct (synchrone) |
| Canal fallback | â€” | RabbitMQ (si optimizer KO) |
| RÃ©ponse au client | Toujours 202 + polling | 200 direct si OK, 202 si KO |
| ComplexitÃ© front | Haute (polling systÃ©matique) | Faible (polling seulement si erreur) |
| Usage RabbitMQ | Principal | Filet de sÃ©curitÃ© |

**Option B** est choisie car : le comportement nominal reste simple et rapide (200 direct), RabbitMQ n'intervient que sur panne, la complexitÃ© est proportionnelle au besoin rÃ©el.

---

### ğŸ”„ Flow complet

#### Chemin nominal (optimizer disponible)

```
Front                   API                   Optimizer            Redis           MinIO
  â”‚                      â”‚                       â”‚                   â”‚               â”‚
  â”‚â”€â”€POST /upload â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                       â”‚                   â”‚               â”‚
  â”‚                      â”‚ SHA256                â”‚                   â”‚               â”‚
  â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ PUT original
  â”‚                      â”‚â”€â”€â”€â”€ HTTP POST /optimize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚               â”‚
  â”‚                      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ image watermarkÃ©e â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚
  â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Redis.Set     â”‚
  â”‚â—„â”€â”€â”€ 200 + image â”€â”€â”€â”€â”€â”€â”‚                       â”‚                   â”‚               â”‚
```

#### Chemin fallback (optimizer KO)

```
Front                   API                RabbitMQ          Worker             Redis           MinIO
  â”‚                      â”‚                    â”‚                 â”‚                 â”‚               â”‚
  â”‚â”€â”€POST /upload â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                   â”‚                 â”‚                 â”‚               â”‚
  â”‚                      â”‚â”€â”€â”€â”€ HTTP (erreur) â”€â–º                 â”‚                 â”‚               â”‚
  â”‚                      â”‚â”€â”€â”€â”€ Publish job â”€â”€â”€â–ºâ”‚                 â”‚                 â”‚               â”‚
  â”‚â—„â”€â”€â”€ 202 {"jobId"} â”€â”€â”€â”€â”‚                   â”‚                 â”‚                 â”‚               â”‚
  â”‚                      â”‚                   â”‚â”€â”€ Deliver job â”€â”€â–ºâ”‚                 â”‚               â”‚
  â”‚â”€â”€â”€ GET /status â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                   â”‚                 â”‚â”€â”€â”€â”€ MinIO.Get â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚â—„â”€â”€â”€ {pending} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚                 â”‚â—„â”€â”€â”€ original â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚                       â”‚                   â”‚                 â”‚â”€â”€â”€â”€ HTTP optimizer â”€â–º            â”‚
  â”‚  (optimizer revient)  â”‚                   â”‚                 â”‚â—„â”€â”€â”€ image â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
  â”‚                       â”‚                   â”‚                 â”‚â”€â”€â”€â”€ Redis.Set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                       â”‚                   â”‚                 â”‚â”€â”€â”€â”€ ACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚
  â”‚â”€â”€â”€ GET /status â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                   â”‚                 â”‚                   â”‚              â”‚
  â”‚â—„â”€â”€â”€ {done, url} â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚                 â”‚                   â”‚              â”‚
  â”‚â”€â”€â”€ GET /image/{hash} â”€â–ºâ”‚                   â”‚                 â”‚                   â”‚              â”‚
  â”‚â—„â”€â”€â”€ image â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Redis.Get â”€â”€â–ºâ”‚              â”‚
```

---

### âš™ï¸ Initialisation RabbitMQ dans `main()`

```go
// L'URL est injectÃ©e par Docker Compose via RABBITMQ_URL
rabbitmqURL := os.Getenv("RABBITMQ_URL")
if rabbitmqURL == "" {
    rabbitmqURL = "amqp://guest:guest@localhost:5672/"
}

// Connexion TCP + authentification
amqpConn, _ := amqp.Dial(rabbitmqURL)

// Un channel = connexion virtuelle multiplexÃ©e (lÃ©gÃ¨re Ã  crÃ©er)
amqpChan, _ = amqpConn.Channel()

// DÃ©claration de la queue durable
// durable=true : la queue survit aux redÃ©marrages de RabbitMQ
// auto-delete=false : la queue persiste mÃªme sans consommateur actif
amqpChan.QueueDeclare(
    "watermark_retry",
    true,  // durable
    false, // auto-delete
    false, // exclusive
    false, // no-wait
    nil,
)

// Lancement du worker en arriÃ¨re-plan
go retryWorker()
```

---

### ğŸ“¨ Publication dans `handleUpload()` (fallback)

```go
// RetryJob : donnÃ©es nÃ©cessaires pour retrouver l'image et la retraiter
type RetryJob struct {
    Hash        string `json:"hash"`         // clÃ© Redis / SHA256 de l'image
    OriginalKey string `json:"original_key"` // chemin dans MinIO : "original/<hash>.jpg"
    Filename    string `json:"filename"`     // nom original du fichier
}

// Dans handleUpload, si l'optimizer est KO :
result, err := sendToOptimizer(optimizerURL, header.Filename, data)
if err != nil {
    job := RetryJob{
        Hash:        cacheKey,
        OriginalKey: "original/" + cacheKey + ".jpg",
        Filename:    header.Filename,
    }
    body, _ := json.Marshal(job)

    amqpChan.PublishWithContext(ctx,
        "",                // exchange vide = exchange par dÃ©faut
        "watermark_retry", // routing key = nom de la queue (direct)
        false, false,
        amqp.Publishing{
            DeliveryMode: amqp.Persistent, // message Ã©crit sur disque dans RabbitMQ
            ContentType:  "application/json",
            Body:         body,
        },
    )

    // 202 Accepted : le traitement se fera plus tard
    w.WriteHeader(http.StatusAccepted)
    json.NewEncoder(w).Encode(map[string]string{"jobId": cacheKey})
    return
}
```

**Pourquoi `DeliveryMode: Persistent` ?** Si RabbitMQ redÃ©marre entre la publication et la consommation, le message est relu depuis le disque. Sans ce flag, il serait perdu.

**Pourquoi l'exchange vide `""` ?** L'exchange par dÃ©faut de RabbitMQ route directement vers la queue dont le nom correspond Ã  la routing key. C'est le pattern le plus simple pour un cas point-Ã -point.

---

### ğŸ” Endpoint `/status/{hash}` (polling)

```go
func handleStatus(w http.ResponseWriter, r *http.Request) {
    hash := r.PathValue("hash")
    ctx  := context.Background()

    // Redis.Exists retourne 1 si la clÃ© existe, 0 sinon
    exists, _ := redisClient.Exists(ctx, hash).Result()

    w.Header().Set("Content-Type", "application/json")
    if exists == 1 {
        // Le retryWorker a terminÃ© : le rÃ©sultat est dans Redis
        json.NewEncoder(w).Encode(map[string]string{
            "status": "done",
            "url":    "/image/" + hash,
        })
    } else {
        // Le worker traite encore (ou attend que l'optimizer revienne)
        json.NewEncoder(w).Encode(map[string]string{"status": "pending"})
    }
}
```

---

### ğŸ” Worker `retryWorker()`

```go
func retryWorker() {
    // Prefetch 1 : ne recevoir qu'un message Ã  la fois
    // â†’ garantit qu'un message non-ACKÃ© sera re-dÃ©livrÃ© si le worker crash
    amqpChan.Qos(1, 0, false)

    msgs, _ := amqpChan.Consume(
        "watermark_retry",
        "",    // consumer tag auto-gÃ©nÃ©rÃ©
        false, // auto-ack=false â†’ ACK manuel obligatoire
        false, false, false, nil,
    )

    for msg := range msgs {
        var job RetryJob
        if err := json.Unmarshal(msg.Body, &job); err != nil {
            // Poison pill : message invalide, on l'Ã©limine dÃ©finitivement
            msg.Ack(false)
            continue
        }

        // â‘  RÃ©cupÃ©rer l'original depuis MinIO
        ctx := context.Background()
        obj, err := minioClient.GetObject(ctx, minioBucket, job.OriginalKey, minio.GetObjectOptions{})
        if err != nil {
            msg.Nack(false, true) // requeue=true : sera re-dÃ©livrÃ©
            time.Sleep(5 * time.Second)
            continue
        }
        data, _ := io.ReadAll(obj)
        obj.Close()

        // â‘¡ Retenter l'optimizer
        result, err := sendToOptimizer(optimizerURL, job.Filename, data)
        if err != nil {
            msg.Nack(false, true) // requeue : l'optimizer est toujours KO
            time.Sleep(10 * time.Second)
            continue
        }

        // â‘¢ Stocker dans Redis (mÃªme clÃ© que le chemin nominal)
        redisClient.Set(ctx, job.Hash, result, 24*time.Hour)

        // â‘£ ACK : message traitÃ© avec succÃ¨s, retirÃ© de la queue
        msg.Ack(false)
    }
}
```

**Cycle de vie d'un message dans le worker :**

```
RabbitMQ deliver â”€â”€â–º json.Unmarshal
                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚MinIO.Get  â”‚ erreur â†’ NACK (requeue) + sleep 5s
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                          â”‚ OK
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚sendToOptimizer â”‚ erreur â†’ NACK (requeue) + sleep 10s
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ OK
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚Redis.Set   â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                      Ack(false) â†’ message supprimÃ© de la queue âœ…
```

**Pourquoi `sleep` avant de NACK ?** Sans dÃ©lai, le message est immÃ©diatement re-dÃ©livrÃ© â†’ boucle active qui consomme du CPU inutilement. Le sleep laisse le temps Ã  l'optimizer de redÃ©marrer.

---

### ğŸ–¥ï¸ Polling cÃ´tÃ© front-end (App.jsx)

```jsx
const handleUpload = async () => {
  const res = await fetch('http://localhost:3000/upload', {
    method: 'POST', body: formData,
  })

  // Chemin nominal (200) : image directement dans la rÃ©ponse
  if (res.status === 200) {
    const blob = await res.blob()
    const cached = res.headers.get('X-Cache') === 'HIT'
    setResult(URL.createObjectURL(blob))
    setStats({ ...stats, cached })
    return
  }

  // Fallback RabbitMQ (202) : polling jusqu'Ã  ce que le worker finisse
  if (res.status === 202) {
    const { jobId } = await res.json()
    await pollStatus(jobId, file, t0)
  }
}

const pollStatus = (jobId, file, t0) =>
  new Promise((resolve, reject) => {
    const interval = setInterval(async () => {
      const { status, url } = await fetch(`/status/${jobId}`).then(r => r.json())

      if (status === 'done') {
        clearInterval(interval)
        const blob = await fetch(`http://localhost:3000${url}`).then(r => r.blob())
        setResult(URL.createObjectURL(blob))
        setStats({ elapsed: Math.round(performance.now() - t0), retried: true, ... })
        resolve()
      }
    }, 500) // interroge toutes les 500ms
  })
```

**Badge `ğŸ‡ rabbit`** dans les stats : affichÃ© quand `stats.retried === true`, pour indiquer que le rÃ©sultat vient du fallback RabbitMQ.

---

### ğŸ³ Configuration Docker Compose

```yaml
rabbitmq:
  image: rabbitmq:3-management-alpine
  ports:
    - "5672:5672"    # AMQP (protocole messagerie)
    - "15672:15672"  # Management UI
  environment:
    - RABBITMQ_DEFAULT_USER=guest
    - RABBITMQ_DEFAULT_PASS=guest
  healthcheck:
    test: ["CMD", "rabbitmq-diagnostics", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5

api:
  environment:
    - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
  depends_on:
    - rabbitmq
```

**Management UI** : `http://localhost:15672` â€” visualiser en temps rÃ©el la queue `watermark_retry`, les messages en attente, les ACK/NACK.

---

### ğŸ§ª Tester le fallback

```bash
# 1. Lancer tous les services
docker compose up

# 2. Uploader une image (chemin nominal â†’ 200)
curl -F "image=@photo.jpg" http://localhost:3000/upload

# 3. ArrÃªter l'optimizer pour simuler une panne
docker compose stop optimizer

# 4. Uploader une image (fallback â†’ 202 + job dans RabbitMQ)
# Le front affiche "Traitement..." et poll /status/{hash}

# 5. RedÃ©marrer l'optimizer
docker compose start optimizer

# 6. Le worker dÃ©tecte la queue, rÃ©cupÃ¨re l'original depuis MinIO,
#    retente l'optimizer, stocke dans Redis â†’ ACK
# Le front affiche l'image avec le badge ğŸ‡ rabbit
```

---

### ğŸ“Š Garanties offertes par RabbitMQ dans ce setup

| ScÃ©nario | Comportement |
|----------|-------------|
| Optimizer KO au moment de l'upload | Job publiÃ© dans RabbitMQ (202) |
| API redÃ©marre avant que le worker traite | Message toujours dans RabbitMQ (durable + persistent) |
| RabbitMQ redÃ©marre | Queue et messages relus depuis le disque |
| Worker crash en cours de traitement | Message re-dÃ©livrÃ© (pas d'ACK envoyÃ© = pas supprimÃ©) |
| Optimizer revient | Worker ACK automatiquement au prochain cycle |
| MÃªme image uploadÃ©e deux fois | Redis HIT au second upload â†’ 200 direct, RabbitMQ non sollicitÃ© |

---

## ğŸ“š Pour aller plus loin

- **Management UI** : `http://localhost:15672` (guest/guest) â€” visualiser queues, exchanges, messages en temps rÃ©el
- **`github.com/rabbitmq/amqp091-go`** : client officiel Go
- **Shovel plugin** : transfÃ©rer des messages entre brokers
- **Federation plugin** : distribuer RabbitMQ sur plusieurs datacenters
- **Quorum Queues** : remplacement des mirrored queues pour la haute disponibilitÃ©
- **Streams** : log persistant immuable (comme Kafka) disponible depuis RabbitMQ 3.9

---

**ğŸ“ Fin du cours â€” RabbitMQ**
